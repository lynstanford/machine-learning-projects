{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89502158",
   "metadata": {},
   "source": [
    "# Classification Problem\n",
    "Next I will develop a Logistic Regression model to predict different classes. More specifically Logistic Regression is used to estimate the probability that an instance, element or observation belongs to a certain class. The use of one of the most popular collections of information for the purpose of classification is the Titanic dataset and the model I have developed will be submitted to Kaggle's 'Titanic - Machine Learning from Disaster' competition.\n",
    "\n",
    "The purpose of this model is to identify if these passengers 'Survived' or 'Not' which will involve creating a target output column populated with simple binary results of '1' or '0'.\n",
    "\n",
    "1. Explore and clean the data\n",
    "2. Split data into train / validation / test\n",
    "3. Fit an initial model and evaluate\n",
    "4. Tune hyper parameters\n",
    "5. Evaluate on validation set\n",
    "6. Final model selection and evaluation on test set\n",
    "\n",
    "## Import the Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863215b",
   "metadata": {},
   "source": [
    "## Ingest the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c645fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/titanic_data.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89cd1b",
   "metadata": {},
   "source": [
    "So I can determine there are a total of 183 entries in this dataset. Initial thoughts are that it might be worth using a more comprehensive dataset, one which might contain the full list of passengers (1309) rather than just a subset (183). This is the most comprehensive list available for the purpose of this exercise that I can find, although estimates for the total number of passengers and crew members are thought to be in the region of 2220. The most comprehensive datasets might be Encyclopedia Titanica and Wikipedia, both of which can be found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a793085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing once again\n",
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/titanic.csv',\n",
    "                     header=0,\n",
    "                     names = ['PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin',\n",
    "                              'Embarked','WikiId','Name_wiki','Age_wiki','Hometown','Boarded','Destination','Lifeboat','Body',\n",
    "                              'Class'])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494db4f6",
   "metadata": {},
   "source": [
    "The keys can be discovered as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ee5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd74ef1",
   "metadata": {},
   "source": [
    "This provides a list, or 1-d array of the attributes in my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4cab9",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Removing unwanted columns and rows and feature engineering is the next important step. Straight away I can see the second dataset I have imported from Kaggle which I have named 'titanic.csv' has a more comprehensive number of entries but also contains 21 columns as opposed to just 12 in the first set. Time to establish which of these columns will be kept or removed using some dimensionality reduction and combination, before establishing what is to be included in a Pandas DataFrame table and target Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ebf6b",
   "metadata": {},
   "source": [
    "I can remove 'PassengerId', 'Name', 'Age', 'Ticket', 'Embarked', 'WikiId', 'Name_wiki', 'Hometown', 'Destination', 'Lifeboat', 'Body', 'Fare' and 'Class' which will significantly reduce clutter in my table as these features provide no causal relationship with passenger Survival, some of which also represent duplicated information such as passenger class 'Pclass' and 'Class'. This initial step of reducing the size helps provide a much more useful dataset overall.\n",
    "Next, let's determine the index and column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343dee99",
   "metadata": {},
   "source": [
    "This tells me there are 1309 rows and 21 columns. Also, another way to find the number of entries or range of the index would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0088fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1db80",
   "metadata": {},
   "source": [
    "So the index starts at 0 and ends at 1308, a total of 1309 passengers (not including crew members), but in terms of the data entries in this table only 891 are labeled with target predictions. The model will be applied to the labeled data first, followed by the unlabeled data (418 entries).\n",
    "\n",
    "### Some Descriptive Stats\n",
    "Several of these values can come in handy in case I need to impute any averages for missing values later. Bear in mind this only contains data for columns with numeric values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324e658",
   "metadata": {},
   "source": [
    "If I want to visualize these relationships between independent variables themselves and between the dependent variable and independent variables as individual scatter plots, this can be achieved using Seaborn's pairplot() method and specifying the dataset as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00660177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f3f23-04f8-48aa-9260-f6bccfca79f4",
   "metadata": {},
   "source": [
    "### Dropping Columns\n",
    "Store a copy of these columns in a new variable or dataset so I don't overwrite the information. The visual scatterplot matrix above tells me that certain attributes are highly positively correlated and can be dropped immediately from the dataset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36861d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_new = titanic[['PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked',\n",
    "                       'WikiId','Name_wiki','Age_wiki','Hometown','Boarded','Destination','Lifeboat','Body','Class']]\n",
    "titanic_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7912b",
   "metadata": {},
   "source": [
    "The easiest way to drop the columns not required is to create a new subset of data (2d array) with the specified columns to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_reduced = titanic_new[['Survived','Pclass','Sex','SibSp','Parch','Cabin','Age_wiki','Boarded','Fare']]\n",
    "titanic_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838ec81",
   "metadata": {},
   "source": [
    "I am using 'Age_wiki' from the Wikipedia web site which appears to be a much more comprehensive set of data than that of the 'Age' column. The 'Boarded' column has nominal data which I will endeavour to convert to numeric values so each port a passenger embarks from will be represented by a number instead. This will help provide more uniform data types. 'Sex' can also be converted to 0's or 1's for the purpose of this exercise and the 'SibSp' and 'Parch' columns can be combined using feature extraction to concatenate the size of families into a new series. The 'Cabin' data will be converted to binary integer values for simplicity and the 'Pclass' (Passenger Class) observations are already denoted as integer values. These appear to have a significant impact on passenger survival so I'm including them.\n",
    "\n",
    "Reducing the number of features is called dimensionality reduction and is an important technique used to achieve comparable results in a much faster time frame (with little benefit to performance accuracy), but generally works better with much larger datasets. The removal of all the unwanted columns contained in the modified dataset variable helps speed the model up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fce98a-ea68-40cf-9abe-8fdd5dfcf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial or subset of titanic dataframe\n",
    "df = pd.DataFrame({\n",
    "    'Survived': pd.Series(titanic_reduced['Survived']),\n",
    "    'Pclass': pd.Series(titanic_reduced['Pclass']),\n",
    "    'Sex': pd.Series(titanic_reduced['Sex']),\n",
    "    'SibSp': pd.Series(titanic_reduced['SibSp']),\n",
    "    'Parch': pd.Series(titanic_reduced['Parch']),\n",
    "    'Cabin': pd.Series(titanic_reduced['Cabin']),\n",
    "    'Age_wiki': pd.Series(titanic_reduced['Age_wiki']),\n",
    "    'Boarded': pd.Series(titanic_reduced['Boarded']),\n",
    "    'Fare': pd.Series(titanic_reduced['Fare'])\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95088b36",
   "metadata": {},
   "source": [
    "Which columns or features are left now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2fd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d01436",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "### Missing Values\n",
    "Next it's really important to remove or impute any Null or missing values. This depends on any row values which are missing and also on the data type for each column. Calculating the total number of missing or Null values across the entire 'titanic' dataset gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_missing = pd.isnull(titanic).sum()\n",
    "print(titanic_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a98e4e",
   "metadata": {},
   "source": [
    "More specifically, to narrow my workable dataset down and find the total number of missing values from the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b4661-3a16-4ef4-8982-64fea16148cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.isnull(df).sum()\n",
    "print(df_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae186e",
   "metadata": {},
   "source": [
    "Next it becomes useful to determine if these missing values occurred because they weren't recorded or because there was no information for them? Assessing this output I can determine that the null values in 'Cabin' simply represent those who did not have a cabin for sleeping quarters and so these would not have been recorded. These passengers would have traveled in other areas of the ship so it's important not to drop these values as they represent important data and account for over three quarters of the overall number of passengers in this particular set. \n",
    "\n",
    "There are also 5 null values for the 'Boarded' column so for whatever reason these passengers did not have their boarding locations recorded. It's impossible to really know which port location these individuals departed from so I can either leave the values as NaN or remove each of these 5 entries as a value should exist if they boarded legally and other attributes were recorded, e.g. Name, Class, Cabin or even Age.\n",
    "\n",
    "### Null Values for Age\n",
    "The 'Age-wiki' feature records the ages provided by passengers when purchasing their tickets so it was likely based on the D.O.B. in their travel documents or passports. Taking a look at the total number of Null or missing values for the 'Age_wiki' column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_age_null = df['Age_wiki'].isnull().sum()\n",
    "print(num_age_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa7427",
   "metadata": {},
   "source": [
    "Identifying each row in the dataframe which contains a null value for 'Age_wiki'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84040cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Age_wiki'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831c69a",
   "metadata": {},
   "source": [
    "I can make a decision whether to include these 7 passengers and merely impute some average age for their respective 'Sex', impute an average based on the overall mean for both genders, or remove them completely. Seeing as the majority of information for each of these passengers (roughly 4/7ths to 5/7ths) is present I would prefer to keep these entries, so imputing mean values for age based on the individuals sex may be a reasonably accurate average.\n",
    "\n",
    "The mean age for everyone, regardless of sex is 29.88 according to the describe() method above. Another way to find the overall average age is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eadf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['Age_wiki'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30320c8",
   "metadata": {},
   "source": [
    "This overall mean or average may not be as accurate as calculating the average age for both male and female passengers and imputing them into the 7 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb8773",
   "metadata": {},
   "source": [
    "### Calculate Average Age\n",
    "Calculating the average age for male and female passengers in the table can be done by summing each individual age (by sex) and dividing by the total number of male or female passengers respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91befada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the total count of each of the two unique values in the Sex column (total male or female passengers)\n",
    "df['Sex'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade4a8c",
   "metadata": {},
   "source": [
    "This is based on all 1309 passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df.Survived[df.Sex == 'male'].value_counts().plot(kind='bar', alpha=0.5, color='teal')\n",
    "plt.title(\"Male Survival\")\n",
    "# create style\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Survived[df.Sex == 'female'].value_counts().plot(kind='bar', alpha=0.5, color='pink')\n",
    "plt.title(\"Female Survival\")\n",
    "# create style\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9dafa",
   "metadata": {},
   "source": [
    "So having determined the unique classes within the 'Sex' column I can further identify the number of Males and Females who survived or not. By taking the 'Survived' column and sub-dividing it according to gender it displays how women were far more likely to have survived the Titanic disaster based on the predictor variables included with this dataset.\n",
    "\n",
    "Next I want to group each category of male and female and store them in a variable called 'gender'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = df.groupby(df['Sex'])\n",
    "gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0f27d",
   "metadata": {},
   "source": [
    "Checking the first few entries for both sexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Countplot\n",
    "sns.catplot(x =\"Sex\", hue =\"Survived\",\n",
    "kind =\"count\", data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774499a",
   "metadata": {},
   "source": [
    "Now there are two variables, one with all the male and one with all the female passengers in the Titanic dataset. There are a total of 843 male and 466 female passengers.\n",
    "\n",
    "The next step is to add these totals together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_total = 843\n",
    "female_total = 466\n",
    "total_passengers = male_total + female_total\n",
    "total_passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e27187",
   "metadata": {},
   "source": [
    "Summing the total of all ages for all the passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65692b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_age = df['Age_wiki'].sum()\n",
    "print(sum_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f4be7",
   "metadata": {},
   "source": [
    "And dividing by the total number of passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ave = sum_age / total_passengers\n",
    "age_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b254b64",
   "metadata": {},
   "source": [
    "So the overall average age for all passengers calculates to just over 29 years old. Using the describe method to check this gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82928d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315be455",
   "metadata": {},
   "source": [
    "So the first item to notice is that only numeric data appears to have been captured which will need to be fixed soon, but the answer I was looking for now, the mean age found under the 'Age-wiki' column is 29.415829 which is close to the value just calculated of 29.258525, but not identical.\n",
    "\n",
    "Next, to see the average ages for both male and female classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='Sex')['Age_wiki'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f630df",
   "metadata": {},
   "source": [
    "So this produces the mean Age by Sex. \n",
    "\n",
    "What if I wanted to find an average age just for the missing values? There are a total of 7 missing age values in the entire dataset, 4 male and 3 female. Imputing a value of 29 for the missing 'male' age and 28 for 'female' would be the most accurate solution but instead, the mean age value for all passengers will be imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6a007",
   "metadata": {},
   "source": [
    "### Imputing Missing Age Values\n",
    "Using the 'impute' library rather than using fillna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use SimpleImputer function to fill in missing values\n",
    "imputer = SimpleImputer(strategy='mean', missing_values=np.nan)\n",
    "age_imputer = imputer.fit(df[['Age_wiki']])\n",
    "# now the transform method\n",
    "df['Age_wiki'] = age_imputer.transform(df[['Age_wiki']])\n",
    "df['Age_wiki'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40098b4",
   "metadata": {},
   "source": [
    "All 'Age_wiki' observations are entered as floats but the data type needs to be changed to integer (representing years) which is technically more correct as a unit of measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_wiki'] = df['Age_wiki'].astype('int')\n",
    "df['Age_wiki'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669bb3a1",
   "metadata": {},
   "source": [
    "So checking the first missing age value to see what value it contains now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age_wiki[42:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18a8b44",
   "metadata": {},
   "source": [
    "The average age of 29 has been imputed. Another of the missing values was located at index 1041:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aac89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age_wiki[1041:1042]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdf29b",
   "metadata": {},
   "source": [
    "This also appears to be correct. \n",
    "\n",
    "To check if there are any more null values now they have been replaced with the mean age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd11cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Age_wiki has any more null values\n",
    "df['Age_wiki'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357a9f7-180a-4784-b9da-e3fd6c81a82e",
   "metadata": {},
   "source": [
    "This tells me all the null values in the Age column have been replaced properly. \n",
    "\n",
    "Now the missing values have been dealt with, what about the string and categorical variables in the dataset? An important consideration to make when using visualizations would be the data types involved. For example, information can be split into numeric (quantitative) data and categorical (qualitative) data. Categorical data values could be classified as Binary (such as the target outcome 'Survived', or 'Sex'), Nominal (such as 'Cabin', or 'Boarded'), perhaps even Ordinal (such as 'Pclass'). 'Age_wiki' contains continuous values and the rest such as 'SibSp' (number of Siblings or Spouse) and 'Parch' (number of Children accompanied by Parents) are discrete integer values.\n",
    "\n",
    "Having established the different different data types the next step is to convert the string objects into numeric types, starting with the data in 'Cabin' first.\n",
    "\n",
    "### Null Values for Cabin\n",
    "Checking the total number of Null values for the 'Cabin' feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cabin_null = df['Cabin'].isnull().sum()\n",
    "print(num_cabin_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f37869",
   "metadata": {},
   "source": [
    "### Convert the Cabin Feature\n",
    "Next, I want to address the issue relating to Cabin data. Because each passenger was assigned a Cabin number which is just an alpha-numeric string type, I would prefer to convert all entries for Cabin to a straight forward integer. Assigning a value of 1 for the presence of a cabin number and 0 for someone without.\n",
    "#### Creating a Binary Indicator for Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite the Cabin values having converted them and store them in the same name\n",
    "df['Cabin'] = np.where(df['Cabin'].isnull(), 0, 1)\n",
    "df['Cabin'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e654f09",
   "metadata": {},
   "source": [
    "Now the 'Cabin' data has been converted into binary numeric values equivalent to 'cabin' or 'no cabin' and even though there are 1014 passengers who were not assigned cabins, this data will remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73789579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609bae8",
   "metadata": {},
   "source": [
    "### Convert the Sex Feature\n",
    "The male entries will be assigned a value of 1 and female, 0. Viewing the total number of Male passengers who didn't survive (0.0), or did survive (1.0), these can be switched to integer values also. This can be repeated for the Female passengers also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a074b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {'male': 1, 'female': 0}\n",
    "df['Sex'] = df['Sex'].map(gender_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e3596",
   "metadata": {},
   "source": [
    "Check the dataframe again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d264db-7859-479b-91b2-bb523d6d870d",
   "metadata": {},
   "source": [
    "### Null Values for Fare\n",
    "There is only one missing value. I could replace the missing fare with the overall mean or median value, but I have opted to adjust the strategy argument in the SimpleImputer() method with the 'most_frequent' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use SimpleImputer model to fill in missing entries with most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent', missing_values=np.nan)\n",
    "fare_imputer = imputer.fit(df[['Fare']])\n",
    "df['Fare'] = fare_imputer.transform(df[['Fare']])\n",
    "\n",
    "#imputer = fare_imputer.fit_transform(fare_imputer.values.reshape(-1,1))\n",
    "df[['Fare']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05298049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fare.fillna(df.Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162addcb",
   "metadata": {},
   "source": [
    "### Null Values for Boarded\n",
    "The last categorical feature which needs changing is the 'Boarded' column. Checking if there are null values in 'Boarded':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Boarded'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377aad39",
   "metadata": {},
   "source": [
    "Which 5 indexed rows are missing in the 'Boarded' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98924814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list index values in relation to this column which are missing\n",
    "boarded_values_null = df[df['Boarded'].isnull()]\n",
    "boarded_values_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65160eb",
   "metadata": {},
   "source": [
    "Because there are only five missing entries, it makes more sense to drop these rows from the database completely as it would be difficult to calculate or impute values for the departure port.\n",
    "\n",
    "This means when it comes to preparing the dataframe to be used for our predictors, the row index numbers for these entries should be removed completely, thus deleting the information across all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([347, 557, 1041, 1048, 1228], axis=0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b88b1b",
   "metadata": {},
   "source": [
    "So the dataframe has now been reduced from 1309 to 1304 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Boarded has any more missing values\n",
    "df['Boarded'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36a4f4",
   "metadata": {},
   "source": [
    "An alternative approach would be to replace the missing values with the most frequently occurring entries using the fillna() method. Having observed these five entries in the source dataset there doesn't appear to be much information in the other columns so they probably wouldn't add much value to our model.\n",
    "\n",
    "To identify which columns are categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical variables from df\n",
    "cat_vars = (df.dtypes == 'object')\n",
    "object_cols = list(cat_vars[cat_vars].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814b001",
   "metadata": {},
   "source": [
    "### Convert the Boarded Feature\n",
    "Because 'Boarded' values are just 'nominal', it doesn't make sense to use 'ordinal' encoding to categorize each departure location as there is no precedent regarding importance. A more appropriate way to convert the categorical entries for the Boarded column is to change its entries into numeric values using 'One-Hot Encoding'.\n",
    "\n",
    "#### Creating a One-Hot Encoding Matrix for Boarded\n",
    "There are four possible states for the 'Boarded' column including Belfast, Queenstown, Southampton and Cherbourg which were the only departure locations listed. Each of these entries can be assigned a value of 1,2 or 3. This can be achieved using a technique called one-hot encoding.\n",
    "\n",
    "Check the values in the specific series I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f755f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boarded_cat = df[['Boarded']]\n",
    "boarded_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d50ce41",
   "metadata": {},
   "source": [
    "Apply the 'One-Hot Encoder' class from the sci-kit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f04404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto', drop=None, sparse=True, dtype='int64', handle_unknown='error')\n",
    "boarded_cat_1hot = one_hot_encoder.fit_transform(boarded_cat)\n",
    "boarded_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba2c71a",
   "metadata": {},
   "source": [
    "Check to see if the Boarded column has changed to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfe1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab13f2",
   "metadata": {},
   "source": [
    "So the Boarded column doesn't appear to have changed. \n",
    "\n",
    "#### Use the Column Transformer\n",
    "This will extrapolate the existing data and extend the data into new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d07cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "transformer = make_column_transformer(\n",
    "    (OneHotEncoder(), ['Boarded', 'Sex']),\n",
    "    remainder='passthrough')\n",
    "\n",
    "transformed = transformer.fit_transform(df)\n",
    "updated_df = pd.DataFrame(transformed, columns=transformer.get_feature_names_out())\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8451229",
   "metadata": {},
   "source": [
    "Tidying up the column names in the new dataframe. Make sure you initiate the 'self' class argument by typing in the name of the dataframe itself (updated_df), or else the rename() method won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = pd.DataFrame.rename(updated_df, columns={'onehotencoder__Boarded_Belfast':'Boarded_Belfast',\n",
    "                            'onehotencoder__Boarded_Cherbourg':'Boarded_Cherbourg',\n",
    "                            'onehotencoder__Boarded_Queenstown':'Boarded_Queenstown',\n",
    "                            'onehotencoder__Boarded_Southampton':'Boarded_Southampton',\n",
    "                            'onehotencoder__Sex_0':'Female',\n",
    "                            'onehotencoder__Sex_1':'Male',\n",
    "                            'remainder__Survived':'Survived',\n",
    "                            'remainder__Pclass':'Pclass',\n",
    "                            'remainder__SibSp':'SibSp',\n",
    "                            'remainder__Parch':'Parch',\n",
    "                            'remainder__Cabin':'Cabin',\n",
    "                            'remainder__Age_wiki':'Age_wiki',\n",
    "                            'remainder__Fare':'Fare'})\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eeda6e-af95-4c6a-861d-453fa585dc1c",
   "metadata": {},
   "source": [
    "Now all the data has been converted to numeric values into a more comprehensive set the performance of the model will be improved dramatically. One interesting visual summarizing the data dispersion of all the features would be a hist plot. This provides a frequency distribution of discrete and continuous variables. \n",
    "\n",
    "For example, we can qualify discrete variables as those which occupy a specific number of states determined by 1 / k where k equals the number of possible outcomes within this universal set. Determining the likelihood of each state occurring is calculated using a probability mass function. This would include 'Survived', 'Pclass', 'Sex', 'SibSp', 'Parch' and 'Cabin' below.\n",
    "\n",
    "Continuous variables have an infinite number of possible values and act as real numbers. These values are calculated using a probability density function which does not provide the probability of a specific state, for example, 'Age_wiki' and 'Fare'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d593245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=20, figsize=(20,10))          # Boarded is not included because it contains string data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49904e-38fd-4acf-be4f-b8c2db053d6f",
   "metadata": {},
   "source": [
    "Taking a quick glance at the frequency distributions for each column reveals some interesting information. For example there are 2 distinct categories for survival, there don't appear to be any Sibling-Spouse groups larger than 8 in total, there's an average age of roughly 20-21 years, there are 3 distinct passenger classes (1st, 2nd and 3rd), an overwhelming number of People travelling without minors and much smaller numbers of Parents travelling with just 1 or 2 children. Finally, the vast majority of fares appear to be below the 25.0 mark, but there were some almost approaching 275.0. I'm not sure if these are Schillings, Guineas or Pounds Sterling, but this data can be further researched.\n",
    "\n",
    "When it comes to visualizing these different types of data it is generally better to use scatter and line plots for numeric data, but for categorical data, frequency distributions, bar charts and histograms may be a better approach for viewing different classes or sub-sets of values.\n",
    "\n",
    "The following Seaborn plots provide a breakdown of the relationship between the three categorical variables and the rate of survival in each. One thing to note is that the survival rate for passengers with a cabin approximates 0.4 (40%), so it would seem that 0.6 (60%) of those without a cabin had survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede9d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Cabin', 'Sex', 'Boarded']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=df, kind='point', aspect=2, color=\"lightseagreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de954d",
   "metadata": {},
   "source": [
    "So I have the passenger survival rates from the different locations above and the percentage number of those passengers who embarked from each port, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb147d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Boarded.value_counts(normalize=True).plot(kind=\"bar\", alpha=0.6, color=\"darkorange\")\n",
    "plt.title(\"Boarded Location\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c65455",
   "metadata": {},
   "source": [
    "Total passengers by Boarding location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:891]['Boarded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a558c0",
   "metadata": {},
   "source": [
    "Group the different Boarding locations by the column I want information returned on which is 'Survived'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aedb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:891].groupby(['Boarded'], as_index=False)['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db4238",
   "metadata": {},
   "source": [
    "To visualize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a38f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked barplot with pandas\n",
    "Survived = df.loc[df['Survived']==1, :]['Boarded'].value_counts()\n",
    "Died = df.loc[df['Survived']==0, :]['Boarded'].value_counts()\n",
    "df_plot = pd.DataFrame([Survived,Died])\n",
    "df_plot.index = ['Survived','Died']\n",
    "\n",
    "# Plot\n",
    "df_plot.plot(kind='bar',stacked=True, title='Survival Rate by Boarding Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e6954",
   "metadata": {},
   "source": [
    "This produces an interesting plot because straight away I am able to see that more people died from Southampton than the entire number of those who survived and nobody from Belfast survived at all.\n",
    "\n",
    "If I flip the x-axis variables to contain the 'Boarded' locations I can compare the number of passengers who embarked from these locations to their actual survival rate in a stacked bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked barplot with pandas\n",
    "Southampton = df.loc[df['Boarded']=='Southampton', :]['Survived'].value_counts()\n",
    "Cherbourg = df.loc[df['Boarded']=='Cherbourg', :]['Survived'].value_counts()\n",
    "Queenstown = df.loc[df['Boarded']=='Queenstown', :]['Survived'].value_counts()\n",
    "Belfast = df.loc[df['Boarded']=='Belfast', :]['Survived'].value_counts()\n",
    "\n",
    "df_plot = pd.DataFrame([Southampton,Cherbourg,Queenstown,Belfast])\n",
    "df_plot.index=['Southampton','Cherbourg','Queenstown','Belfast']\n",
    "df_plot.plot(kind='bar',stacked=True, color=['tomato','lightseagreen'], title='Survival by Boarding Port Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50feb8f0-82aa-45af-a98d-a68a7f3501ab",
   "metadata": {},
   "source": [
    "0.0 (tomato color) represents passengers who died and 1.0 (lightseagreen) those who survived in terms of the legend. It looks as if at least two-thirds to three-quarters of all passengers did not make it. At least 55% of overall passengers who survived had embarked from Cherbourg, at least 65% of passengers who were allocated a cabin survived and an overwhelming number of survivor's were Female.\n",
    "\n",
    "Another important table I like is the correlation matrix which does a great job of describing the relative relationships between all the different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de34ed-e86f-4338-9633-a3cb18c0619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = updated_df.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4df848",
   "metadata": {},
   "source": [
    "Presenting a correlation matrix in visualized form we can see the darker squares represent higher positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c80ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(correlation, annot=True, cmap='BuPu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451cc1b",
   "metadata": {},
   "source": [
    "Looking at the Survived column it's easy to see that the highest positive correlation is 'Female', so merely being a Women would have the greatest survival rate, more than any other factor. The highest negatively correlated effect belonged to the 'Male' category. This had a much greater impact on survival rates than passenger class (Pclass) or even the fare paid so those who paid more for a first class ticket weren't necessarily secured a place on a lifeboat.\n",
    "\n",
    "### Grouping Data Together\n",
    "Taking a look at the average values for each feature based on their survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9749e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.groupby('Survived').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1478d",
   "metadata": {},
   "source": [
    "### Combine SibSp and Parch\n",
    "Creating a for loop to iterate through both columns and plotting them categorically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979362ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=updated_df, kind='point', aspect=2, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a18dca",
   "metadata": {},
   "source": [
    "An extremely useful procedure when it comes to feature engineering involves combining columns, in this case 'SibSp' and 'Parch' into a new feature called 'Family_count'. It serves a similar purpose which is to provide counts or frequency of individuals traveling with their Parents or Brothers and Sisters, combining the values together and producing dimensionality reduction by reducing the number of columns and overal noise in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df['Family_Count'] = updated_df['SibSp'] + updated_df['Parch']\n",
    "sns.catplot(x='Family_Count', y='Survived', data=updated_df, kind='point', aspect=2, color=\"coral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68546c82",
   "metadata": {},
   "source": [
    "Immediately from this feature-engineered column called 'Family_Count' it's possible to see that an individual had a far greater chance of survival given a lower family count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091986d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df['Family_Count'] = updated_df['SibSp'] + updated_df['Parch']\n",
    "updated_df.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62502c",
   "metadata": {},
   "source": [
    "A plot of Age and Survival Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.Age_wiki.value_counts(normalize=True).plot(kind=\"kde\", color=\"turquoise\")\n",
    "plt.title(\"Age and the Probability of Survival\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d129a",
   "metadata": {},
   "source": [
    "This shows a meaningful relationship across the Age spectrum. The older ages were less likely to survive and as the age diminishes, the likelihood goes up to between 20% and 60% for those less than the age of about 13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebcbf2",
   "metadata": {},
   "source": [
    "The next step is to prepare the dataset with the correct number of total labeled entries. I can either change the data at source and slice it using Excel, or alternatively slice the data in Python to only include the first 891 passengers in the training data because these are the only results which are labeled. The reason this needs to be done is because of the risk of feeding inaccurate and unlabeled data back into the model (i.e. entries from 892 to 1304). Using un-labeled data will introduce bias into the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a157b",
   "metadata": {},
   "source": [
    "## Plot Continuous Features\n",
    "These are separate from discrete values and deserve some attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Fare','Age_wiki']:\n",
    "    died = list(updated_df[updated_df['Survived'] == 0][i].dropna())\n",
    "    survived = list(updated_df[updated_df['Survived'] == 1][i].dropna())\n",
    "    xmin = min(min(died), min(survived))\n",
    "    xmax = max(max(died), max(survived))\n",
    "    width = (xmax - xmin) / 40\n",
    "    sns.distplot(died, color='lightseagreen', kde=False, bins=np.arange(xmin, xmax, width))\n",
    "    sns.distplot(survived, color='orange', kde=False, bins=np.arange(xmin, xmax, width))\n",
    "    plt.legend(['Did not survive', 'Survived'])\n",
    "    plt.title('Histogram Showing Survival Rate v {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ff1f9",
   "metadata": {},
   "source": [
    "This tells me that a far greater number of passengers in the 20-30 year age category did not survive relative to other age groups. Also, it appears that those who paid a lot more had better chances of survival.\n",
    "\n",
    "What's the relationship between the continuous variables? A scatter plot can be used to describe this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = sns.scatterplot(data=updated_df, x=updated_df['Age_wiki'], y=updated_df['Fare'], color=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62aefd0",
   "metadata": {},
   "source": [
    "This explains the range of fares paid by passengers according to age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8d0cc",
   "metadata": {},
   "source": [
    "## Row Selection\n",
    "This is where I determine the number of instances to train for model selection and at this stage it's best to employ the use of a Train, Test, Split algorithm using the labeled data (rows 1 to 889) which contains values for the target feature entitled 'Survived'. The model will fit to and learn from this data, then I can evaluate the efficiency of the chosen model against the unseen (un-labeled) data, rows 892 to 1304 which don't contain target values for the 'Survived' column. It's important to note that because I have already pre-processed the entire dataset from titanic.csv, I will have to split the data into subsets for 'labeled' and 'unlabeled' portions and apply the LogisticRegression() model to each separately.\n",
    "### Nature of the Data\n",
    "Change all features to integer values except for the 'Fare' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values to integers except for Fare and Survived columns\n",
    "updated_df['Boarded_Belfast'] = updated_df['Boarded_Belfast'].astype('int')\n",
    "updated_df['Boarded_Cherbourg'] = updated_df['Boarded_Cherbourg'].astype('int')\n",
    "updated_df['Boarded_Queenstown'] = updated_df['Boarded_Queenstown'].astype('int')\n",
    "updated_df['Boarded_Southampton'] = updated_df['Boarded_Southampton'].astype('int')\n",
    "updated_df['Female'] = updated_df['Female'].astype('int')\n",
    "updated_df['Male'] = updated_df['Male'].astype('int')\n",
    "updated_df['Pclass'] = updated_df['Pclass'].astype('int')\n",
    "updated_df['Cabin'] = updated_df['Cabin'].astype('int')\n",
    "updated_df['Age_wiki'] = updated_df['Age_wiki'].astype('int')\n",
    "updated_df['Family_Count'] = updated_df['Family_Count'].astype('int')\n",
    "\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e4f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a9923",
   "metadata": {},
   "source": [
    "### Labeled Dataset Only\n",
    "This set is reduced in size. It only contains instances where the target response was labeled which means only supervised learning algorithms can be applied before evaluating the result. An important point to remember here is that two 'Boarded' entries were removed between the index values of 0 and 891 (giving a total of 889 instances), so the new range of labeled entries will be between 0 and 889. The unlabeled entries span from index locations 889 to 1304.\n",
    "\n",
    "The unlabeled portion of data residing between index locations 889 and 1304 would require a different type of machine learning model, or un-supervised algorithms such as visualization through clustering techniques, dimensionality reduction or associative rule modeling. See my k_means_clustering.ipynb model... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the 'Survived' column from the predictors DataFrame variable X\n",
    "X = updated_df[:889].drop('Survived', axis=1).copy()\n",
    "# assigning this dropped column to the target Series variable y\n",
    "y = updated_df[:889]['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ed30e",
   "metadata": {},
   "source": [
    "To clean up the dependent variable information, convert the y values to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(y).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea9e8a5",
   "metadata": {},
   "source": [
    "Checking the first few instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679c0fd",
   "metadata": {},
   "source": [
    "This is correct! The first Null value should appear at index location 889, so there are a total of 888 labeled entries. Converting these dataframes to separate csv files so they can be viewed in Microsoft Excel if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_csv = X.to_csv(r'C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/X.csv', index=False, header=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98821878",
   "metadata": {},
   "source": [
    "And the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_to_csv = y.to_csv(r'C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/y.csv', index=False, header=True)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399473a1",
   "metadata": {},
   "source": [
    "Looking at the new shape of the predictor dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b214038",
   "metadata": {},
   "source": [
    "This is better! Now I have the labeled instances for my independent variables, it's time to train and fit the data which means it needs to be split into training and validation sets before evaluating the model's accuracy.\n",
    "\n",
    "### Split the Data\n",
    "\n",
    "Having looked at the source data file, it hasn't been split into training or test data yet.\n",
    "\n",
    "#### Single Holdout Set\n",
    "Start with a single holdout validation, or test set to evaluate how well the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef823643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ec52f",
   "metadata": {},
   "source": [
    "So 889 labels (y) are split into training (533 entries), validation (178 entries) and test sets (178 entries). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y), len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087343f",
   "metadata": {},
   "source": [
    "Next I would like to convert my cleaned, split data into separate train, validation and test set CSV files for preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c165c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/train_features.csv', index=False)\n",
    "X_val.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/val_features.csv', index=False)\n",
    "X_test.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/train_labels.csv', index=False)\n",
    "y_val.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/val_labels.csv', index=False)\n",
    "y_test.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out cleaned data\n",
    "updated_df.to_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/titanic_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfb9f8",
   "metadata": {},
   "source": [
    "#### Scale the Different Ranges of Values\n",
    "To improve accuracy before modeling by removing unecessary scale or unit measurement differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf700c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf0238",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "#### Train the Data First\n",
    "This is the stage where I get to fit a model to the data (fit a regression line to the datapoints). Applying a Logistic Regression model to the labeled set and setting the 'multi_class' parameter equal to 'auto' because this will select a binary classifier automatically for the output array. Setting 'multi_class' equal to 'auto' is another way for the model to identify a binary problem to be fit to each label. If it had been a multi-class output then 'auto' would detect that also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library then I can try different models\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression = LogisticRegression(multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd53d4b",
   "metadata": {},
   "source": [
    "Once the classification has been fit predictions can be made. The predict() method predicts the actual class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg_clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6707872",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Now I can evaluate the training set using the score method, which is the coefficient of determination (R-squared) and determines how accurate the regression line is compared to the overall mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d27f7f-686a-4f43-8cda-3e3f5607a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b79b9d5",
   "metadata": {},
   "source": [
    "This indicates that having trained a Logistic Regression model on my prepared dataset and having made the predictions above, it's safe to assume it's correct 78.8% of the time. Having calculated all the individual probabilities the score method finds the mean overall probability. \n",
    "\n",
    "I can apply this 'score()' method and measure the performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc9c4f",
   "metadata": {},
   "source": [
    "The score for the validation set data can be improved upon. Try removing the \"Cabin\" feature to see how much information is captured by the model this time. The model obviously needs some fine-tuning before applying it to the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68cf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = updated_df[['Boarded_Belfast', 'Boarded_Cherbourg', 'Boarded_Queenstown', 'Boarded_Southampton', 'Female', 'Male', 'Pclass',\n",
    "       'Age_wiki', 'Fare', 'Family_Count']].copy()\n",
    "X = X[0:889]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a4893",
   "metadata": {},
   "source": [
    "Train the same model after re-scaling the values using some normalization algorithm first, then re-apply the logistic regression.\n",
    "\n",
    "#### Re-Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a36da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "logistic_regression = LogisticRegression(multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "log_reg_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700bec8b",
   "metadata": {},
   "source": [
    "Having dropped the Cabin feature there is a negligable improvement so the model captures a small incremental change in the score having removed the information from this feature. Moving on to preprocessing, it may help to train a Polynomial function to fit the curve more accurately to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9010640",
   "metadata": {},
   "source": [
    "### Polynomial Features\n",
    "Checking the parameters or attributes which can be adjusted using the PolynomialFeatures() model I will first try changing the 'degree' parameter to include a tuple for the 'min_degree' and 'max_degree' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "logistic_regression = LogisticRegression(multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "polynomial_regression = preprocessing.PolynomialFeatures(degree=(2,4))\n",
    "poly_features = polynomial_regression.fit_transform(X_train)\n",
    "\n",
    "log_reg_clf = logistic_regression.fit(poly_features, y_train)\n",
    "\n",
    "log_reg_clf.score(poly_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6889087",
   "metadata": {},
   "source": [
    "Again, the polynomal features model is nudging the score in the right direction by attempting to fit the Sigmoid curve more accurately to the values and reducing the overall error. Next, try an ensemble learning classifier model.\n",
    "\n",
    "Adding some of the parameters such as penalty and solver provides a slight improvement. L2 regularization or ridge regression which will reduce the individual weights for each observation as close to zero as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "logistic_regression = LogisticRegression(penalty='l2', solver='newton-cg', multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "polynomial_regression = preprocessing.PolynomialFeatures(degree=(2,4))\n",
    "poly_features = polynomial_regression.fit_transform(X_train)\n",
    "\n",
    "log_reg_clf = logistic_regression.fit(poly_features, y_train)\n",
    "\n",
    "log_reg_clf.score(poly_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad533f",
   "metadata": {},
   "source": [
    "A slight improvement!\n",
    "\n",
    "### Leave 1-Out\n",
    "This should only really be used for really small datasets when I could leave one value or observation out for validation after each training iteration but it would take too long for 889 instances.\n",
    "\n",
    "### Confusion Matrix\n",
    "Using a Confusion Matrix is a much better approach to measuring accuracy for a Classifier model such as Logistic Regression. This will display 'Actual' v 'Predicted' values. The left hand rows display 'Actual' negative and positive classes, and the colums display 'Predicted' negative and positive classes. It's important to make sure the length of the target series' are exactly the same for actual (y_test) and predicted (y_pred) values. \n",
    "\n",
    "It won't work by testing training data (y_train) because these account for 533 total instances, rather than 178 instances in the test set. It's good to play around with the train-test set size hyperparameters in the 'train_test_split' module. Start with test_size=0.2, followed by 0.3 and 0.4.\n",
    "\n",
    "The same goes for the split between the validation and test set sizes. Try different percentage splits to derive more accurate outcomes in the accuracy score (R-squared) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae704cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a classifier model by fitting logistic regression to the data points\n",
    "logistic_regression = LogisticRegression(penalty='l2', solver='newton-cg', multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train,y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = log_reg_clf.predict(X_train)\n",
    "y_train_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87216e9",
   "metadata": {},
   "source": [
    "### Introducing Evaluation Metrics\n",
    "Taking a look at a Confusion Martix, Accuracy Score and Receiver Operating Characteristics (Area Under Curve)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4596c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "conf = confusion_matrix(y_train, y_train_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eff1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e6fb4",
   "metadata": {},
   "source": [
    "None of these scores are particularly great for prediction purposes! These are all predictions based on the training data, but shouldn't accuracy scores be applied to test data (target class y_test, and predicted class y_pred? What happens if I change the arguments for the confusion_matrix() function to contain the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_train, y_train_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row:\n",
    "TN = 293\n",
    "FP = 40\n",
    "# second row:\n",
    "FN = 67\n",
    "TP = 133"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ecd7d",
   "metadata": {},
   "source": [
    "Find the Precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of positive predictions\n",
    "precision = TP / (TP + FP)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1c0b6",
   "metadata": {},
   "source": [
    "Find the recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio of correctly predicted instances\n",
    "recall = TP / (TP + FN)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd0186",
   "metadata": {},
   "source": [
    "Plotting the Actual versus Predicted survival classes using the results from the Confusion Matrix above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce638a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# plotting actual v predicted values\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(\"Actual v Predicted Survival Rates\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "sns.heatmap(confusion_matrix(y_train, y_train_pred), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856fd2d",
   "metadata": {},
   "source": [
    "Rather than using the confusion_matrix() function, importing separate precision and recall score functions may provide different accuracy results. Let's try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440cea5f",
   "metadata": {},
   "source": [
    "So it's apparent that these methods provide the same scores as the manual calculations in the previous cells. The Accuracy Score measures the proportion of all predictions that were correct.\n",
    "\n",
    "Precision is the degree to which positive and negative predictions are made accurately, the ratio of true to false positives, or quite simply, the proportion of positive predictions that are correctly classified. Those values which remain represent the values which are incorrectly classified, or the Negative Predicted values. \n",
    "\n",
    "The Recall Score relates to the percentage of correctly classified Positive Predictions for each class, or the number of times a particular value (or class) was correctly classified.\n",
    "\n",
    "Combining both together can be achieved using something called an F1 score for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c756554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6e09b",
   "metadata": {},
   "source": [
    "This provides a mean value somewhere between the Precision and Recall scores.  Another way to achieve this is by using the predict_proba() method which predicts the probability that each element falls within that particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2103a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abac0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb80c7c",
   "metadata": {},
   "source": [
    "This conveys the probability of correctly classifying each individual observation, or simply, the proportion of total predictions that are correct.\n",
    "\n",
    "There is no direct way to fine-tune or control the 'decision threshold' which is the boundary between the different classifications, but the decision scores can be accessed using the SGDClassifier() model's 'decision_function(). Then it becomes possible to move the decision plane to the left or right in the list of instances to improve the accuracy score's probability.\n",
    "\n",
    "#### Changing the Test Set Sizes\n",
    "Repeat the process of train-test-split function by adjusting the test size and other parameters before using different training models each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bdb357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a classifier model by fitting logistic regression to the data points\n",
    "logistic_regression = LogisticRegression(penalty='l2', solver='newton-cg', multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = log_reg_clf.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d94252",
   "metadata": {},
   "source": [
    "This has improved the accuracy of the model for all scores.\n",
    "\n",
    "Changing the test_size=0.2 gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a classifier model by fitting logistic regression to the data points\n",
    "logistic_regression = LogisticRegression(penalty='l2', solver='newton-cg', multi_class='auto')\n",
    "log_reg_clf = logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = log_reg_clf.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f12176",
   "metadata": {},
   "source": [
    "The recall_score has improved but not the others. Let's try some more classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0e64c",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "There are a few different ways to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344db643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a model by fitting stochastic gradient descent learning to the data points\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier(random_state=42)\n",
    "dtc = decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = dtc.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010dbd8c",
   "metadata": {},
   "source": [
    "Interesting scores but they all appear to be overfitting so the best way to evaluate this result is to apply a cross validation technique and if all the scores are still high then regularization should be applied. It's probably important to note here that cross validation should probably be applied to our model each time when it comes to evaluating scores and is a useful tool for measuring or evaluating estimator performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08835bbf",
   "metadata": {},
   "source": [
    "#### Cross-Validation\n",
    "Fit and evaluate a basic model using K-Fold Cross Validation. The data will be divided into k subsets and the holdout set will be repeated k number of times until all the data points are used in the model. In this example I am setting k equal to 5 folds, or cv=5. Also I will change the scoring hyperparameter to check for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390df7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# train the cross validation model using the decision_tree as the first argument, X and y values and iterations\n",
    "scores = cross_val_score(dtc, X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"K Fold Scores are: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc263127",
   "metadata": {},
   "source": [
    "This is extremely useful as cross-validation will output a score based on K number of folds, in this example 5 folds, which is directly controlled by the parameter cv=5 (5 splits is also the default number and is the same as specifying 'cv=None'). When using K-Folds CV the average score is taken so inputing the 5 scores above and calculating the mean gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b7184",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.768 + 0.728 + 0.76612903 + 0.80645161 + 0.73387097) / 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d7960",
   "metadata": {},
   "source": [
    "Which can also be achieved by using the mean method():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean score is %0.4f with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef47707",
   "metadata": {},
   "source": [
    "So I can see that 76.05% is slightly worse than the previous score from the 'PolynomialFeatures', but is probably a more accurate reflection of the score() function. The overfitting in the DecisionTree is a result of low bias and high variance so this needs to reach some kind of equilibrium and the only way optimize the solution is to fine-tune hyperparameters in this algorithm such as max_depth, max_features or random_state.\n",
    "\n",
    "#### Fine-Tuning the Decision Tree and CV\n",
    "Adjustments to fine-tune include:\n",
    "\n",
    "train_test_split - 'test_size',\n",
    "\n",
    "DecisionTreeClassifier - 'criterion', 'splitter', 'max_depth' and 'random_state',\n",
    "\n",
    "cross_val_score - 'n_jobs', 'scoring' (which includes accuracy, balanced_accuracy, roc_auc, f1 as options for Classification) and 'cv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee057ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a model by fitting stochastic gradient descent learning to the data points\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=None, random_state=None)\n",
    "dtc = decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = dtc.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# train the cross validation model using the decision_tree as the first argument, X and y values and iterations\n",
    "scores = cross_val_score(dtc, X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(\"Mean score of %0.2f with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4cafd",
   "metadata": {},
   "source": [
    "Having run the model by manually adjusting the hyper-parameters each time it takes far too long and there are too many combinations of scores to contemplate an optimal solution based on the chosen model. An automated search for the optimal combination of hyper-parameters is definitely the way to go and the best ones to use include GridSearchCV, RandomizedSearchCV, BayesSearchCV, SGDClassifier and differential_evolution.\n",
    "\n",
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# initialize the algorithm you want to fine-tune\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=None, random_state=None)\n",
    "\n",
    "grid = {'criterion': ['gini','entropy','log_loss'],\n",
    "        'splitter': ['best','random'],\n",
    "        'max_depth': [1,2,3,4],\n",
    "        'max_features': ['auto','sqrt','log2']}\n",
    "\n",
    "print('Number of tested models: %i'\n",
    "     % np.prod([len(grid[element]) for element in grid]))\n",
    "\n",
    "score_metric = 'accuracy'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dtc = decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# create \n",
    "'''\n",
    "dtc_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('dtc', DecisionTreeClassifier())])\n",
    "dtc_pipe.fit(X_train, y_train)\n",
    "dtc_pipe.score(X_train, y_train)\n",
    "'''\n",
    "\n",
    "# create a parameter grid\n",
    "'''\n",
    "param_grid = [{'criterion': ['gini','entropy','log_loss'],\n",
    "                   'splitter': ['best','random'],\n",
    "                   'max_depth': [0,2,3,4],\n",
    "                   'random_state': [0,1,42],\n",
    "                   'max_features': [None,'sqrt','log2']}]\n",
    "'''\n",
    "\n",
    "gs_dtc = GridSearchCV(dtc_pipe,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring='accuracy',\n",
    "                      cv=5)\n",
    "gs_dtc.fit(X_train, y_train)\n",
    "gs_dtc.best_params_\n",
    "gs_dtc.best_score_\n",
    "\n",
    "# initialize the grid search cv function\n",
    "#grid = GridSearchCV(estimator=dtc, param_grid=param_grid, cv=5)\n",
    "# fit the grid to our training set\n",
    "#grid.fit(X_train, y_train)\n",
    "\n",
    "# to check the best parameters selected by the GridSearchCV function:\n",
    "print(\"Optimal parameters %s accuracy score of %0.2f\"\n",
    "      % (gs_dtc.best_params_, gs_dtc.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f51ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# initialize the algorithm you want to fine-tune\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=None, random_state=None)\n",
    "\n",
    "grid = {'criterion': ['gini','entropy','log_loss'],\n",
    "        'splitter': ['best','random'],\n",
    "        'max_depth': [1,2,3,4],\n",
    "        'max_features': ['auto','sqrt','log2']}\n",
    "\n",
    "print('Number of tested models: %i'\n",
    "     % np.prod([len(grid[element]) for element in grid]))\n",
    "\n",
    "score_metric = 'accuracy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29555d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print('Baseline with default parameters: %.3f'\n",
    "     % np.mean(cross_val_score(decision_tree_classifier, X, y\n",
    "                              cv=5, scoring=score_metric, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5815a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "search = GridSearchCV(estimator=decision_tree_classifier,\n",
    "                      param_grid=grid,\n",
    "                      scoring=score_metric,\n",
    "                      n_jobs=-1,\n",
    "                      refit=True,\n",
    "                      return_train_score=True,\n",
    "                      cv=5)\n",
    "\n",
    "search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3c1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e92bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca2491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec684643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727016c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ff849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, Y = make_classification(n_samples=889, n_classes=2, n_features=11, n_redundant=0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ddd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751db2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(max_features=5, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8597a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566535b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "max_features_range = np.arange(1,11,1)\n",
    "n_estimators_range = np.arange(1,889,10)\n",
    "param_grid = dict(max_features=max_features_range, n_estimators=n_estimators_range)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50171a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89730f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f24ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e417395c",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a model by fitting stochastic gradient descent learning to the data points\n",
    "random_forest_classifier = RandomForestClassifier(max_features=10, n_estimators=100)\n",
    "rfc = random_forest__classifier.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea57849",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# creating a model by fitting stochastic gradient descent learning to the data points\n",
    "sgd_classifier = SGDClassifier(alpha=0.001, n_jobs=-1)\n",
    "sgd = sgd_classifier.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = sgd.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a40fc",
   "metadata": {},
   "source": [
    "This seems to produce about as high an f1 score as I can get.\n",
    "\n",
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "k_nearest_neighbors = KNeighborsClassifier(n_neighbors=3)\n",
    "knc = k_nearest_neighbors.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = knc.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02b946",
   "metadata": {},
   "source": [
    "These scores are consistently higher.\n",
    "\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d25e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "support_vector_machine = SVC(gamma='scale')\n",
    "svc = support_vector_machine.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = svc.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd31e8f",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e2789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# training the model using the standard scaler algorithm\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(X_train, y_train)\n",
    "\n",
    "# creating y_train_pred variable and predicting the first 5 values:\n",
    "y_train_pred = nbc.predict(X_train)\n",
    "\n",
    "# summarizing the scores\n",
    "prec = precision_score(y_train, y_train_pred)\n",
    "print(f\"The Precision Accuracy Score is: \", prec)\n",
    "rec = recall_score(y_train, y_train_pred)\n",
    "print(f\"The Recall Accuracy Score is: \", rec)\n",
    "roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)\n",
    "f1 = f1_score(y_train, y_train_pred)\n",
    "print(f\"The F1 Accuracy Score is: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0225f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier\n",
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fdd48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494329d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier\n",
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21390a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convoluted Neural Networks\n",
    "CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759ec4e",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "Looking at the Receiver-Operating-Characteristics will plot the True Positive rate of classification (Sensitivity) against the True Negative, or False-Positive rate (Specificity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"The Receiver Operation Characteristic-Area Under Curve Score is: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009fbb47-6d22-4eec-b894-39ca1d58c158",
   "metadata": {},
   "source": [
    "The best score is in the range of 0.9 to 1.0. The score of 0.77 is fair, or average with respect to this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "\n",
    "# plot the true-positive rate v false-positive rate\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlabel(\"fpr\")\n",
    "    plt.ylabel(\"tpr\")\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd3ca6",
   "metadata": {},
   "source": [
    "The blue curve should be pushed as far to the top left-hand corner as possible for a more accurate model. This can be improved upon by applying a different model such as a Random Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec5f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "y_prob_rf = cross_val_predict(rf, X_train, y_train, cv=3, method=\"predict_proba\")\n",
    "\n",
    "y_scores_rf = y_prob_rf[:, :1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_train, y_scores_rf)\n",
    "\n",
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(tpr_rf, fpr_rf, \"Random Forest Model\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da7584",
   "metadata": {},
   "source": [
    "So the Random Forest Classifier model has improved the Area Under the Curve because it is better at predicting the target values, or survival rate in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4e971",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "How does the score from the LogisticRegression() model generalize to the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125da1f4",
   "metadata": {},
   "source": [
    "The model is generalizing reasonably well to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de99ac7-40b5-4103-95f8-58afc11aac20",
   "metadata": {},
   "source": [
    "## Improving Evaluation Metrics\n",
    "Iterating the process with new algorithms and improving the evaluation scores. I will repeat this process by trying out iterations changing Parameters and Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56395a-de5f-4c9d-94e5-42cd15f7b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the features and labels data subsets from earlier\n",
    "train_features = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/X.csv')\n",
    "train_labels = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/supervised-learning/regression/logistic-regression/y.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1adb7",
   "metadata": {},
   "source": [
    "Try importing the 'cross_val_score' library and reproducing a variety of validation scores through selection and division of the dataset into 5 equal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d038036-8cc6-4c53-b27a-503ce73d2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rfc, train_features, train_labels.values.ravel(), cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268177b6-5393-4d07-bc9e-5f95f9aa1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aa756-80c6-4102-8830-34f03c0f0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 100],\n",
    "    'max_depth': [2, 10, 20, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6c8af-1d64-4902-bcbf-d6735fa3f51f",
   "metadata": {},
   "source": [
    "## Pipeline: Evaluate results on validation set\n",
    "Using the Titanic dataset from this Kaggle competition.\n",
    "\n",
    "In this section, we will use what we learned in last section to fit the best few models on the full training set and then evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0e800-f383-43e2-92fc-8969ace1d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "tr_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv')\n",
    "tr_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', header=None)\n",
    "\n",
    "val_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_features.csv')\n",
    "val_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_labels.csv', header=None)\n",
    "\n",
    "te_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_features.csv')\n",
    "te_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd697c-e9d6-40e1-b261-754b8a3aba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=5, max_depth=10)\n",
    "rf1.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rf2.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "rf3.fit(tr_features, tr_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc87d7-5416-4d3d-9be7-0cc38b4912ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in [rf1, rf2, rf3]:\n",
    "    y_pred = mdl.predict(val_features)\n",
    "    accuracy = round(accuracy_score(val_labels, y_pred), 3)\n",
    "    precision = round(precision_score(val_labels, y_pred), 3)\n",
    "    recall = round(recall_score(val_labels, y_pred), 3)\n",
    "    print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(mdl.max_depth,\n",
    "                                                                         mdl.n_estimators,\n",
    "                                                                         accuracy,\n",
    "                                                                         precision,\n",
    "                                                                         recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6802853-f217-4000-84a7-c22f04e83499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf2.predict(te_features)\n",
    "accuracy = round(accuracy_score(te_labels, y_pred), 3)\n",
    "precision = round(precision_score(te_labels, y_pred), 3)\n",
    "recall = round(recall_score(te_labels, y_pred), 3)\n",
    "print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(rf2.max_depth,\n",
    "                                                                     rf2.n_estimators,\n",
    "                                                                     accuracy,\n",
    "                                                                     precision,\n",
    "                                                                     recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08247c-6081-4914-b26d-34d8fb6f5955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f9ccf-524d-4339-9815-25fd6a8189dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0898438",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p wget,pandas,numpy,watermark,matplotlib,seaborn,sklearn,warnings\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c26972402dce5166fbc873f625c08651cf8cab8ad67af055bc25543d79ffa73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
