{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f5154e",
   "metadata": {},
   "source": [
    "# XGBoost Model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "XGBoost is an ensemble learning method which is based on a collection of ensemble tree models. Aggregate the predictions from either a group of classifiers, or regressors. In this example I have chosen to classify the results from the 'Telco Customer Churn' dataset providing a Boolean result of True or False with respect to Churn.\n",
    "\n",
    "The model is trained on a group of Decision Tree Classifiers first, with each classifier being trained on a random subset of the overall training data set. Then the predictions from all individual trees are then aggregated to predict the overall class that gets the most votes.\n",
    "\n",
    "In terms of the sequence of events, XGBoost is normally applied at the last stage of a prediction or classification model. The other prediction/classification models are all aggregated to predict the prediction/class with the most votes - known as a 'hard voting predictor/classifier'.\n",
    "\n",
    "This is all achieved using a series of 'boosting', 'bagging' and 'stacking' applications but first, I need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce53cbc6-ebf1-4553-8042-9e71d907f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xgboost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split and train the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# I will construct a pipeline containing my chosen models\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# I need to score predicted versus actual values\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "\n",
    "# I need to cross-validate and evaluate results\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2c257",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "What is apparent about the data at first glance? How can I shape the data? Can I perform dimensionality reduction? Can I perform feature engineering to improve the data quality? What relationships and insights can I gain from the information and does it require cleaning, re-scaling or pre-processing of any sort?\n",
    "\n",
    "Which are the columns to be used in the feature subset and target column? At this stage I know that the 'Churn' column will be my target vector, but the predictor feature subset may require some work so it's best to try and understand each and every one of these columns in their entirety.\n",
    "\n",
    "### Summarize the Data\n",
    "\n",
    "I extracted this dataset from the Kaggle web site. In the Dataset option in the Navigation menu on the left hand side, I am provided with a Search option. Requesting 'Telco-Customer-Churn' using search provides me with a list of options ranked according to 'Hotness' which is some measure of popularity. So the data sources on this page are all in flat file format such as XLSX or CSV which makes it easier to read the tabular structured data into Pandas, or a SQL DBMS.\n",
    "\n",
    "I have decided to check a couple of variations of this IBM Telco Customer Churn dataset; the file provided by 'BlastChar' entitled 'Telco Customer Churn' and that of 'Jack Chang' entitled 'Telco customer churn (11.1.3+)'. Taking a look at any differences I have to decide which file would be more suitable for the purpose of this classification algorithm and where I can find the most comprehensive information summarizing the dataset? The reason I like using Kaggle is because they categorize their datasets according to popularity\n",
    "\n",
    "Understanding how churn works is key to this project. It is a measure of whether or not customers are leaving, (the rate of loss, the attrition rate) or their dropout rate compared to the entire set of customers. This particular dataset is based on a fictional telecom company but discovering the rate of churn in general can be extremely useful if it's compared to that of other companies within the same industry. It can be used as a tool to monitor fluctuating consumer tastes and the effectiveness of competing companies. Ultimately the churn rate can be used to try and retain customers by predicting their behaviour.\n",
    "\n",
    "List of Columns in 'BlastChar' CSV file:\n",
    " - CustomerID\n",
    " - Gender\n",
    " - SeniorCitizen\n",
    " - Partner\n",
    " - Dependents\n",
    " - Tenure\n",
    " - PhoneService\n",
    " - MultipleLines\n",
    " - InternetService\n",
    " - OnlineSecurity\n",
    " - OnlineBackup\n",
    " - DeviceProtection\n",
    " - TechSupport\n",
    " - StreamingTV\n",
    " - StreamingMovies\n",
    " - Contract\n",
    " - PaperlessBilling\n",
    " - PaymentMethod\n",
    " - MonthlyCharges\n",
    " - TotalCharges\n",
    " - Churn\n",
    " \n",
    " List of Columns in 'Jack Chang' XLSX file:\n",
    " - CustomerID\n",
    " - Count\n",
    " - Country\n",
    " - State\n",
    " - City\n",
    " - Zip Code\n",
    " - Lat Long\n",
    " - Latitude\n",
    " - Longitude\n",
    " - Gender\n",
    " - Senior Citizen\n",
    " - Partner\n",
    " - Dependents\n",
    " - Tenure Months\n",
    " - Phone Service\n",
    " - Multiple Lines\n",
    " - Internet Service\n",
    " - Online Security\n",
    " - Online Backup\n",
    " - Device Protection\n",
    " - Tech Support\n",
    " - Streaming TV\n",
    " - Streaming Movies\n",
    " - Contract\n",
    " - Paperless Billing\n",
    " - Payment Method\n",
    " - Monthly Charges\n",
    " - Total Charges\n",
    " - Churn Label\n",
    " - Churn Value\n",
    " - Churn Score\n",
    " - CLTV\n",
    " - Churn Reason\n",
    " \n",
    "The 'BlastChar' list of columns is much shorter indicating some of the data has been pre-processed already. Let's see which columns might have been removed from the 'BlastChar' dataset and why? Read the dataset from 'Jack Chang' called 'telco_churn.csv'. This file was in XLSX format when I extracted it from Kaggle, but I loaded it into my Bronze Zone storage (my local drive) and saved it as a CSV file ready to be pushed to the Silver Zone for the transformation process to begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cb06cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Count</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Lat Long</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Paperless Billing</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Monthly Charges</th>\n",
       "      <th>Total Charges</th>\n",
       "      <th>Churn Label</th>\n",
       "      <th>Churn Value</th>\n",
       "      <th>Churn Score</th>\n",
       "      <th>CLTV</th>\n",
       "      <th>Churn Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90003</td>\n",
       "      <td>33.964131, -118.272783</td>\n",
       "      <td>33.964131</td>\n",
       "      <td>-118.272783</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>3239</td>\n",
       "      <td>Competitor made better offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90005</td>\n",
       "      <td>34.059281, -118.30742</td>\n",
       "      <td>34.059281</td>\n",
       "      <td>-118.307420</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>2701</td>\n",
       "      <td>Moved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9305-CDSKC</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90006</td>\n",
       "      <td>34.048013, -118.293953</td>\n",
       "      <td>34.048013</td>\n",
       "      <td>-118.293953</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>99.65</td>\n",
       "      <td>820.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>5372</td>\n",
       "      <td>Moved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7892-POOKP</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90010</td>\n",
       "      <td>34.062125, -118.315709</td>\n",
       "      <td>34.062125</td>\n",
       "      <td>-118.315709</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>104.80</td>\n",
       "      <td>3046.05</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>5003</td>\n",
       "      <td>Moved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0280-XJGEX</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90015</td>\n",
       "      <td>34.039224, -118.266293</td>\n",
       "      <td>34.039224</td>\n",
       "      <td>-118.266293</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>103.70</td>\n",
       "      <td>5036.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>5340</td>\n",
       "      <td>Competitor had better devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Count        Country       State         City  Zip Code  \\\n",
       "0  3668-QPYBK      1  United States  California  Los Angeles     90003   \n",
       "1  9237-HQITU      1  United States  California  Los Angeles     90005   \n",
       "2  9305-CDSKC      1  United States  California  Los Angeles     90006   \n",
       "3  7892-POOKP      1  United States  California  Los Angeles     90010   \n",
       "4  0280-XJGEX      1  United States  California  Los Angeles     90015   \n",
       "\n",
       "                 Lat Long   Latitude   Longitude  Gender  ...        Contract  \\\n",
       "0  33.964131, -118.272783  33.964131 -118.272783    Male  ...  Month-to-month   \n",
       "1   34.059281, -118.30742  34.059281 -118.307420  Female  ...  Month-to-month   \n",
       "2  34.048013, -118.293953  34.048013 -118.293953  Female  ...  Month-to-month   \n",
       "3  34.062125, -118.315709  34.062125 -118.315709  Female  ...  Month-to-month   \n",
       "4  34.039224, -118.266293  34.039224 -118.266293    Male  ...  Month-to-month   \n",
       "\n",
       "  Paperless Billing             Payment Method  Monthly Charges Total Charges  \\\n",
       "0               Yes               Mailed check            53.85        108.15   \n",
       "1               Yes           Electronic check            70.70        151.65   \n",
       "2               Yes           Electronic check            99.65         820.5   \n",
       "3               Yes           Electronic check           104.80       3046.05   \n",
       "4               Yes  Bank transfer (automatic)           103.70        5036.3   \n",
       "\n",
       "  Churn Label Churn Value Churn Score  CLTV                   Churn Reason  \n",
       "0         Yes           1          86  3239   Competitor made better offer  \n",
       "1         Yes           1          67  2701                          Moved  \n",
       "2         Yes           1          86  5372                          Moved  \n",
       "3         Yes           1          84  5003                          Moved  \n",
       "4         Yes           1          89  5340  Competitor had better devices  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_churn = pd.read_csv(\"C:/Users/lynst/Documents/Datasets/Kaggle/Jack Chang/telco_churn.csv\")\n",
    "telco_churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197d8b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'Count', 'Country', 'State', 'City', 'Zip Code',\n",
       "       'Lat Long', 'Latitude', 'Longitude', 'Gender', 'Senior Citizen',\n",
       "       'Partner', 'Dependents', 'Tenure Months', 'Phone Service',\n",
       "       'Multiple Lines', 'Internet Service', 'Online Security',\n",
       "       'Online Backup', 'Device Protection', 'Tech Support', 'Streaming TV',\n",
       "       'Streaming Movies', 'Contract', 'Paperless Billing', 'Payment Method',\n",
       "       'Monthly Charges', 'Total Charges', 'Churn Label', 'Churn Value',\n",
       "       'Churn Score', 'CLTV', 'Churn Reason'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_churn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d059c0d",
   "metadata": {},
   "source": [
    "'CustomerID' is the very first column which appears to contain unique identifiers for all Customers. This can be useful, especially if the dataset is loaded into a SQL Database. \n",
    "\n",
    "'Count' is the next column and contains the value '1' in every single instance. This merely just counts the entry for that particular row and is of no significance to the table.\n",
    " \n",
    "'Country' is the next column. These entries are all the same with the value: 'United States'. Again, this information carries no real value if all rows are identical.\n",
    " \n",
    "'State' contains identical values: 'California'. Again, this doesn't add any value to our dataset.\n",
    "\n",
    "'City' does actually contain a lot of different values, but in this case there are hundreds or thousands of different Cities in California. This data column can be removed also.\n",
    "\n",
    "'Zip Code' isn't that dissimilar to the City attribute. This can go!\n",
    "\n",
    "'Lat Long' is just the Latitude and Longitude values combined into a co-ordinate. Geographical location or GPS co-ordinates are unlikely to have any effect on a customers churn rate unless there is an issue with network capacity shortfalls and signal outages.\n",
    "\n",
    "'Latitude' should also be removed as these co-ordinates have no relationship with the overall dependent target vector.\n",
    "\n",
    "'Longitude' as well.\n",
    "\n",
    "'Gender' may provide some insight but it's unlikely. I will convert these entries into binary values to see.\n",
    "\n",
    "'Senior Citizen' is similar. I believe that senior's are more likely to keep a phone, internet service or TV contract going so long as they're not moving location all the time. Is the customer a senior citizen, perhaps someone of pensionable age, or someone who is no longer a part of the labour force in a full-time capacity. The value is binary.\n",
    "\n",
    "'Partner' I don't believe will bring any additional information to the model, however it may be more likely for a couple to retain services if they combine their income so I'll keep it in. This value would also be binary in nature.\n",
    "\n",
    "'Dependents' should be included. This data explains if a customer has any children or co-habitant dependents who are reliant on them.\n",
    "\n",
    "'Tenure Months' must relate to the number of months the individual has already been a customer. This could have an effect on why someone decides to cancel or not. Perhaps prices have increased or the customer has been with the same Telecomm's company for too long. Sometimes the competition have better offers so maybe the longer the tenure, the more likely they are to cancel.\n",
    "\n",
    "'Phone Service' is quite simply a landline or cell phone contract. This is a simple Yes or No value so I'll convert these to binary.\n",
    "\n",
    "'Multiple Lines' just means the customer may have had more than one phone line installed. This is a binary value.\n",
    "\n",
    "'Internet Service' is a connection to the world wide web. This is binary in nature.\n",
    "\n",
    "'Online Security' indicates if a customer has antivirus and other safeguards. This is also a 'Yes' or 'No' answer.\n",
    "\n",
    "'Device Protection' would include an insurance policy for any damage or faulty manufacture of the product. This is another binary value.\n",
    "\n",
    "'Tech Support' means the customer may have purchased additional help for any technical issues.\n",
    "\n",
    "'Streaming TV' is a basic binary choice. Do the customers have a TV streaming package?\n",
    "\n",
    "'Streaming Movies' is the same.\n",
    "\n",
    "'Contract' is one fixed term which usually involves a monthly fee to purchase the cost of the phone, any cell phone charges and possibly data usage for accessing the cell phone network when no internet is available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873a2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a27716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943d1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cebf03a",
   "metadata": {},
   "source": [
    "Having assessed both the files I have decided to use the source file provided by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b84d64",
   "metadata": {},
   "source": [
    "## Import the Dataset\n",
    "\n",
    "Read the data in using Pandas having selected the source and perform some EDA before cleaning or pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6426a8-55ef-4817-89fd-be1fc5e0e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing a Classification dataset and defining my X and y values\n",
    "df = pd.read_csv(\"C:/Users/lynst/Documents/Datasets/Kaggle/BlastChar/Telco-Customer-Churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d216317",
   "metadata": {},
   "source": [
    "There are 21 columns but how many rows are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3bf65",
   "metadata": {},
   "source": [
    "This gives me the total number of instances (or rows) and columns. To list the names of the columns and their data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6ee54",
   "metadata": {},
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "Exploring the dataset further I can produce a summary of mean values and their variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58eaf9",
   "metadata": {},
   "source": [
    "So immediately I realize that this 'describe( )' method will only summarize numeric data. I need to figure out which columns to use and whether or not the data can be converted into numeric values to improve the data quality and provide a more comprehensive prediction subset. Currently there are only 3 columns with numeric data which means I am limited in terms of the number of mathematical operations I can perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d130a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd3d98a9",
   "metadata": {},
   "source": [
    "I want to ascertain if there's any correlation between any of the attributes from the very beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a61d6a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynst\\AppData\\Local\\Temp\\ipykernel_15336\\1833137714.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  telco_churn.corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Tenure Months</th>\n",
       "      <th>Monthly Charges</th>\n",
       "      <th>Churn Value</th>\n",
       "      <th>Churn Score</th>\n",
       "      <th>CLTV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zip Code</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895743</td>\n",
       "      <td>-0.784271</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>-0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895743</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.876779</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>-0.019899</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.007684</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.784271</td>\n",
       "      <td>-0.876779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure Months</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>-0.224987</td>\n",
       "      <td>0.396406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monthly Charges</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>-0.019899</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193356</td>\n",
       "      <td>0.133754</td>\n",
       "      <td>0.098693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn Value</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>-0.352229</td>\n",
       "      <td>0.193356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.664897</td>\n",
       "      <td>-0.127463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn Score</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002769</td>\n",
       "      <td>-0.007684</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>-0.224987</td>\n",
       "      <td>0.133754</td>\n",
       "      <td>0.664897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.079782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLTV</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003562</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.396406</td>\n",
       "      <td>0.098693</td>\n",
       "      <td>-0.127463</td>\n",
       "      <td>-0.079782</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Count  Zip Code  Latitude  Longitude  Tenure Months  \\\n",
       "Count              NaN       NaN       NaN        NaN            NaN   \n",
       "Zip Code           NaN  1.000000  0.895743  -0.784271       0.001041   \n",
       "Latitude           NaN  0.895743  1.000000  -0.876779      -0.001631   \n",
       "Longitude          NaN -0.784271 -0.876779   1.000000      -0.001678   \n",
       "Tenure Months      NaN  0.001041 -0.001631  -0.001678       1.000000   \n",
       "Monthly Charges    NaN -0.004596 -0.019899   0.024098       0.247900   \n",
       "Churn Value        NaN  0.003346 -0.003384   0.004594      -0.352229   \n",
       "Churn Score        NaN -0.002769 -0.007684   0.004260      -0.224987   \n",
       "CLTV               NaN -0.003562  0.000886   0.000485       0.396406   \n",
       "\n",
       "                 Monthly Charges  Churn Value  Churn Score      CLTV  \n",
       "Count                        NaN          NaN          NaN       NaN  \n",
       "Zip Code               -0.004596     0.003346    -0.002769 -0.003562  \n",
       "Latitude               -0.019899    -0.003384    -0.007684  0.000886  \n",
       "Longitude               0.024098     0.004594     0.004260  0.000485  \n",
       "Tenure Months           0.247900    -0.352229    -0.224987  0.396406  \n",
       "Monthly Charges         1.000000     0.193356     0.133754  0.098693  \n",
       "Churn Value             0.193356     1.000000     0.664897 -0.127463  \n",
       "Churn Score             0.133754     0.664897     1.000000 -0.079782  \n",
       "CLTV                    0.098693    -0.127463    -0.079782  1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_churn.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c375d8f",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "A visual summary of the dispersion of data about its mean using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=20, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e67a82",
   "metadata": {},
   "source": [
    "This provides a histogram splitting the data into separate buckets, or intervals, then counting the frequency distribution within them. It also provides a nice display of the dispersion of data, but now I want to see how it's distributed around the average values and the degree to which it's distributed around the average (fat, thin, or bell-shaped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1250a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2840d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
