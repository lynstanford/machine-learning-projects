{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    }
   ],
   "source": [
    "# check xgboost version\n",
    "import xgboost\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost for Classification\n",
    "Using the 'make_classification()' function to create a set of random binary values and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925 (0.028)\n"
     ]
    }
   ],
   "source": [
    "# evaluate xgboost algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make predictions using xgboost for classification\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_classification\n",
    "from xgboost import XGBClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [0.2929949,-4.21223056,-1.288332,-2.17849815,-0.64527665,2.58097719,0.28422388,-7.1827928,-1.91211104,2.73729512,0.81395695,3.96973717,-2.66939799,3.34692332,4.19791821,0.99990998,-0.30201875,-4.43170633,-2.82646737,0.44916808]\n",
    "row = asarray([row])\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Ensemble for Regression\n",
    "This time, using the 'make_regression()' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -76.447 (3.859)\n"
     ]
    }
   ],
   "source": [
    "# evaluate xgboost ensemble for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n",
    "# define the model\n",
    "model = XGBRegressor()\n",
    "# evaluate the model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 50\n"
     ]
    }
   ],
   "source": [
    "# gradient xgboost for making predictions for regression\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n",
    "# define the model\n",
    "model = XGBRegressor()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [0.20543991,-0.97049844,-0.81403429,-0.23842689,-0.60704084,-0.48541492,0.53113006,2.01834338,-0.90745243,-1.85859731,-1.02334791,-0.6877744,0.60984819,-0.70630121,-1.29161497,1.32385441,1.42150747,1.26567231,2.56569098,-0.11154792]\n",
    "row = asarray([row])\n",
    "yhat = model.predict(row)\n",
    "print('Prediction: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Hyperparameters\n",
    "Taking a look at hyperparameters and how they can be fine-tuned.\n",
    "### Number of Trees in Ensemble\n",
    "Exploring the number of decision trees using the 'n_estimators' argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.885 (0.029)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore xgboost number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    trees = [10, 50, 100, 500, 1000, 5000]\n",
    "    for n in trees:\n",
    "         models[str(n)] = XGBClassifier(n_estimators=n)\n",
    "         return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Tree Depth\n",
    "Varying the depth of each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost tree depth effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in range(1,11):\n",
    "        models[str(i)] = XGBClassifier(max_depth=i)\n",
    "    return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost learning rate effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    " X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    " return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    " models = dict()\n",
    " rates = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    " for r in rates:\n",
    " key = '%.4f' % r\n",
    " models[key] = XGBClassifier(eta=r)\n",
    " return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    " cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    " return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    " scores = evaluate_model(model)\n",
    " results.append(scores)\n",
    " names.append(name)\n",
    " print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Number of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost subsample ratio effect on performance\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    " X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    " return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    " models = dict()\n",
    " for i in arange(0.1, 1.1, 0.1):\n",
    " key = '%.1f' % i\n",
    " models[key] = XGBClassifier(subsample=i)\n",
    " return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    " cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    " return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    " scores = evaluate_model(model)\n",
    " results.append(scores)\n",
    " names.append(name)\n",
    " print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore xgboost column ratio per tree effect on performance\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    " X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    " return X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    " models = dict()\n",
    " for i in arange(0.1, 1.1, 0.1):\n",
    " key = '%.1f' % i\n",
    " models[key] = XGBClassifier(colsample_bytree=i)\n",
    " return models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    " cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    " scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    " return scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    " scores = evaluate_model(model)\n",
    " results.append(scores)\n",
    " names.append(name)\n",
    " print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
