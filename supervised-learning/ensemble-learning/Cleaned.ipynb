{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cce0b2a-adeb-4b90-836b-c07ff40f072b",
   "metadata": {},
   "source": [
    "# XGBoost Model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "XGBoost is an ensemble learning method which is based on a collection of ensemble tree models. Aggregate the predictions from either a group of classifiers, or regressors. In this example I have chosen to classify the results from the 'Telco Customer Churn' dataset providing a Boolean result of True or False with respect to Churn.\n",
    "\n",
    "The model is trained on a group of Decision Tree Classifiers first, with each classifier being trained on a random subset of the overall training data set. Then the predictions from all individual trees are then aggregated to predict the overall class that gets the most votes.\n",
    "\n",
    "In terms of the sequence of events, XGBoost is normally applied at the last stage of a prediction or classification model. The other prediction/classification models are all aggregated to predict the prediction/class with the most votes - known as a 'hard voting predictor/classifier'.\n",
    "\n",
    "This is all achieved using a series of 'boosting', 'bagging' and 'stacking' applications but first, I need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb4ba8-bcb3-4429-94f0-a67052fa0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split and train the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# I will construct a pipeline containing my chosen models\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594d04b-4836-4ee9-a3d5-81bc025e1ffd",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "What is apparent about the data at first glance? How can I shape the data? Can I perform dimensionality reduction? Can I perform feature engineering to improve the data quality? What relationships and insights can I gain from the information and does it require cleaning, re-scaling or pre-processing of any sort?\n",
    "\n",
    "Which are the columns to be used in the feature subset and target column? At this stage I know that the 'Churn' column will be my target vector, but the predictor feature subset may require some work so it's best to try and understand each and every one of these columns in their entirety.\n",
    "\n",
    "### Summarize the Data\n",
    "\n",
    "I extracted this dataset from the Kaggle web site. In the Dataset option in the Navigation menu on the left hand side, I am provided with a Search option. Requesting 'Telco-Customer-Churn' using search provides me with a list of options ranked according to 'Hotness' which is some measure of popularity. So the data sources on this page are all in flat file format such as XLSX or CSV which makes it easier to read the tabular structured data into Pandas, or a SQL DBMS.\n",
    "\n",
    "I have decided to check a couple of variations of this IBM Telco Customer Churn dataset; the file provided by 'BlastChar' entitled 'Telco Customer Churn' and that of 'Jack Chang' entitled 'Telco customer churn (11.1.3+)'. Taking a look at any differences I have to decide which file would be more suitable for the purpose of this classification algorithm and where I can find the most comprehensive information summarizing the dataset? The reason I like using Kaggle is because they categorize their datasets according to popularity\n",
    "\n",
    "Understanding how churn works is key to this project. It is a measure of whether or not customers are leaving, (the rate of loss, the attrition rate) or their dropout rate compared to the entire set of customers. This particular dataset is based on a fictional telecom company but discovering the rate of churn in general can be extremely useful if it's compared to that of other companies within the same industry. It can be used as a tool to monitor fluctuating consumer tastes and the effectiveness of competing companies. Ultimately the churn rate can be used to try and retain customers by predicting their behaviour.\n",
    "\n",
    "List of Columns in 'BlastChar' CSV file:\n",
    " - CustomerID\n",
    " - Gender\n",
    " - SeniorCitizen\n",
    " - Partner\n",
    " - Dependents\n",
    " - Tenure\n",
    " - PhoneService\n",
    " - MultipleLines\n",
    " - InternetService\n",
    " - OnlineSecurity\n",
    " - OnlineBackup\n",
    " - DeviceProtection\n",
    " - TechSupport\n",
    " - StreamingTV\n",
    " - StreamingMovies\n",
    " - Contract\n",
    " - PaperlessBilling\n",
    " - PaymentMethod\n",
    " - MonthlyCharges\n",
    " - TotalCharges\n",
    " - Churn\n",
    " \n",
    " List of Columns in 'Jack Chang' XLSX file:\n",
    " - CustomerID\n",
    " - Count\n",
    " - Country\n",
    " - State\n",
    " - City\n",
    " - Zip Code\n",
    " - Lat Long\n",
    " - Latitude\n",
    " - Longitude\n",
    " - Gender\n",
    " - Senior Citizen\n",
    " - Partner\n",
    " - Dependents\n",
    " - Tenure Months\n",
    " - Phone Service\n",
    " - Multiple Lines\n",
    " - Internet Service\n",
    " - Online Security\n",
    " - Online Backup\n",
    " - Device Protection\n",
    " - Tech Support\n",
    " - Streaming TV\n",
    " - Streaming Movies\n",
    " - Contract\n",
    " - Paperless Billing\n",
    " - Payment Method\n",
    " - Monthly Charges\n",
    " - Total Charges\n",
    " - Churn Label\n",
    " - Churn Value\n",
    " - Churn Score\n",
    " - CLTV\n",
    " - Churn Reason\n",
    " \n",
    "The 'BlastChar' list of columns is much shorter indicating some of the data has been pre-processed already. Let's see which columns might have been removed from the 'BlastChar' dataset and why? Read the dataset from 'Jack Chang' called 'telco_churn.csv'. This file was in XLSX format when I extracted it from Kaggle, but I loaded it into my Bronze Zone storage (my local drive) and saved it as a CSV file ready to be pushed to the Silver Zone for the transformation process to begin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b223b9-4002-4b84-9c57-2be86bbbfa5d",
   "metadata": {},
   "source": [
    "### Import the Dataset\n",
    "\n",
    "Having assessed both the files I have decided to use the source file provided by Jack Chang in Kaggle entitled 'telco_churn.csv'. Read the data in using Pandas having selected the source and perform some EDA before cleaning or pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b22c0-466b-4b87-84c0-9bfc1c2685f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn = pd.read_csv(\"C:/Users/lynst/Documents/Datasets/Kaggle/Jack Chang/telco_churn.csv\")\n",
    "telco_churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de00d68-3dcf-46cb-a5e0-a08839d6b40c",
   "metadata": {},
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "Exploring the dataset further I can produce a summary of mean values and their variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6c6cd-8af4-4c02-a021-681eafcf0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8db99-1f39-4e96-b234-6f9fd5528b7b",
   "metadata": {},
   "source": [
    "So immediately I realize that this 'describe( )' method will only summarize numeric data. I need to figure out which columns to use and whether or not the data can be converted into numeric values to improve the data quality and provide a more comprehensive prediction subset. Currently there are only 3 columns with numeric data which means I am limited in terms of the number of mathematical operations I can perform.\n",
    "\n",
    "I can achieve a more data friendly and comprehensive dataset by removing the columns I don't need and converting more of the remaining columns into numeric data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e5c78-7535-43a7-8518-ca93564e5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de41702-4f12-4fbc-8306-d5a88d8f575d",
   "metadata": {},
   "source": [
    "'CustomerID' is the very first column which appears to contain unique identifiers for all Customers. This can be useful, especially if the dataset is loaded into a SQL Database. \n",
    "\n",
    "'Count' is the next column and contains the value '1' in every single instance. This merely just counts the entry for that particular row and is of no significance to the table.\n",
    " \n",
    "'Country' is the next column. These entries are all the same with the value: 'United States'. Again, this information carries no real value if all rows are identical.\n",
    " \n",
    "'State' contains identical values: 'California'. Again, this doesn't add any value to our dataset.\n",
    "\n",
    "'City' does actually contain a lot of different values, but in this case there are hundreds or thousands of different Cities in California. This data column can be kept as it will be useful for drawing a decision tree.\n",
    "\n",
    "'Zip Code' isn't that dissimilar to the City attribute. This can go!\n",
    "\n",
    "'Lat Long' is just the Latitude and Longitude values combined into a co-ordinate. Geographical location or GPS co-ordinates are unlikely to have any effect on a customers churn rate unless there is an issue with network capacity shortfalls and signal outages.\n",
    "\n",
    "'Latitude' should also be removed as these co-ordinates have no relationship with the overall dependent target vector.\n",
    "\n",
    "'Longitude' as well.\n",
    "\n",
    "'Gender' may provide some insight but it's unlikely. I will convert these entries into binary values to see.\n",
    "\n",
    "'Senior Citizen' is similar. I believe that senior's are more likely to keep a phone, internet service or TV contract going so long as they're not moving location all the time. Is the customer a senior citizen, perhaps someone of pensionable age, or someone who is no longer a part of the labour force in a full-time capacity. The value is binary.\n",
    "\n",
    "'Partner' I don't believe will bring any additional information to the model, however it may be more likely for a couple to retain services if they combine their income so I'll keep it in. This value would also be binary in nature.\n",
    "\n",
    "'Dependents' should be included. This data explains if a customer has any children or co-habitant dependents who are reliant on them, but also because their preferences with respect to different services may be a big factor.\n",
    "\n",
    "'Tenure Months' must relate to the number of months the individual has already been a customer. This could have an effect on why someone decides to cancel or not. Perhaps prices have increased or the customer has been with the same Telecomm's company for too long. Sometimes the competition have better offers so maybe the longer the tenure, the more likely they are to cancel.\n",
    "\n",
    "'Phone Service' is quite simply a landline or cell phone contract. This is a simple Yes or No value so I'll convert these to binary.\n",
    "\n",
    "'Multiple Lines' just means the customer may have had more than one phone line installed. This is a binary value.\n",
    "\n",
    "'Internet Service' is a connection to the world wide web. This is binary in nature and may be a good factor in deciding if a customer wants to retain their service.\n",
    "\n",
    "'Online Security' indicates if a customer has antivirus and other safeguards. This is also a 'Yes' or 'No' answer.\n",
    "\n",
    "'Device Protection' would include an insurance policy for any damage or faulty manufacture of the product. This is another binary value.\n",
    "\n",
    "'Tech Support' means the customer may have purchased additional help for any technical issues.\n",
    "\n",
    "'Streaming TV' is a basic binary choice. Do the customers have a TV streaming package?\n",
    "\n",
    "'Streaming Movies' is the same.\n",
    "\n",
    "'Contract' is one fixed term which usually involves a monthly fee to purchase the cost of the phone, any cell phone charges and possibly data usage for accessing the cell phone network when no internet is available.\n",
    "\n",
    "'Paperless Billing' means electronic only but this is just a yes or no answer once again. It's not clear that this would necessarily have any effect on the overall churn rate for customers.\n",
    "\n",
    "'Payment Method' includes information about the customers' payment preference such as checks, credit card or bank transfers.\n",
    "\n",
    "'Monthly Charges' are the monthly bill. These are float datatype and should be included.\n",
    "\n",
    "'Total Charges' include all charges since the beginning of the respective agreement or contract. These are float datatype and should also be included.\n",
    "\n",
    "'Churn Label' is either yes or no and indicates if the customer left in the last month or not. This can be removed so I can just use the 'Churn Value' instead, otherwise information is just being duplicated and will introduce deliberate bias.\n",
    "\n",
    "'Churn Value' is merely a binary representation of the churn label, using 1 for yes and 0 for no.\n",
    "\n",
    "'Churn Score' is a numeric value representing the churn rate. The higher the number, the more like that customer is to cancel so this should be included. According to the information provided in Kaggle, it's a value from 0-100 that is calculated using the predictive tool IBM SPSS Modeler. The model includes several reasons known to cause churn.\n",
    "\n",
    "'CLTV' is Customer Lifetime Value. A predicted CLTV is calculated using corporate formulas and existing data. The higher the value, the more valuable the customer. High value customers should be monitored for churn.\n",
    "\n",
    "'Churn Reason' is the customers explanation for leaving the service. This is directly related to the churn score, but I am dropping this column which is a string object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be54507-6dba-422c-ac8d-de38a84d18bf",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "\n",
    "First I need to remove the columns I don't want using the drop( ) method. Be careful here as any attempt to assign this operation to the existing 'telco_churn' variable name will result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7543e-e25e-4f2f-95ca-d10c7d6af6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.drop(['CustomerID','Count','Country','Latitude','Longitude','State','Churn Label'], axis=1, inplace=True)\n",
    "\n",
    "telco_churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7eafb-262b-422a-9670-7097f2080c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95faf35a-14ef-4e80-a660-52815069f14c",
   "metadata": {},
   "source": [
    "So there are a total of 7043 row entries or instances and 26 columns or features.\n",
    "\n",
    "To list the names of the columns and their data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0b8bd-6733-4770-99c4-3eb9d2e32f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f285e-1a71-4302-b7c7-34a282bbf6ef",
   "metadata": {},
   "source": [
    "To remove any white space in the column names using the replace method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150d371-0c81-4ebc-bc06-23813e079717",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.columns = telco_churn.columns.str.replace(' ','_')\n",
    "telco_churn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e309ba-ecef-4b03-8f16-0fc1c54fa98b",
   "metadata": {},
   "source": [
    "Although the purpose of having unique identifiers to label each entry or customer id becomes useful when manipulating data in SQL, it will not provide any insight or potential relationships if included in a machine learning model so it was more prudent to drop the 'CustomerID' column. (In structured relational databases a unique identifier column of values becomes useful for establishing relationships in a Schema table object)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f0532-7299-4828-92ce-a05e073b271c",
   "metadata": {},
   "source": [
    "### Remove White Space\n",
    "This can be achieved using the 'replace( )' method on a DataFrame.\n",
    "\n",
    "Counting the number of unique values in the 'City' column as first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdf361-76b7-4848-9ee0-6511bb15dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['City'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256b22d-e550-4d27-904b-fcf2db6210ef",
   "metadata": {},
   "source": [
    "Later on a Decision Tree will be created using GraphViz but in order to draw a tree properly it is not preferable to have any whitespace in the column values for 'City', so these should be replaced with an underscore character. Looking at the first five values for 'City' using slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20418c37-fc45-48b1-ba7f-123b45994660",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['City'].unique()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dcd28-ef8b-4be0-9c09-45b1379d56fe",
   "metadata": {},
   "source": [
    "Now check the first 5 rows of the 'City' column using the 'head( )' method having replaced whitespaces with underscore characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cbe94-9d42-475c-8aa5-a4c054ae0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['City'].replace(' ', '_', regex=True, inplace=True)\n",
    "telco_churn['City'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892532c-993b-412a-af76-bf1019a004f7",
   "metadata": {},
   "source": [
    "### Converting Data Types\n",
    "\n",
    "Next I would like to convert any columns with string object datatypes into numeric values, all except for the 'City' column.\n",
    "\n",
    "Gender needs converting to '1' for Male and '0' for Female for simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc399252-3702-4883-bc02-8225a499956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {'Male': 1, 'Female': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7e62f-08d6-4a1c-bc89-45aea4aeb24d",
   "metadata": {},
   "source": [
    "Now map the gender dictionary to the 'Gender' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb6feb-a6c9-4269-a1a6-7c365d172998",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['Gender'] = telco_churn['Gender'].map(gender_dict)\n",
    "telco_churn['Gender'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5630b36-0b64-45c7-8181-a04e71a39411",
   "metadata": {},
   "source": [
    "'Senior Citizen' values can be converted to '1' for yes and '0' for no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8845d0-36fd-4da1-98e3-514e0d4222b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Senior_Citizen'] = telco_churn['Senior_Citizen'].map(senior_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137a5107-8c9a-4f24-8a1f-c7b754be5167",
   "metadata": {},
   "source": [
    "Same for 'Partner':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ceb4cd-4c4b-45c2-8bd6-eb3e5f2f4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "partner_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Partner'] = telco_churn['Partner'].map(partner_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c4995-094f-4f43-9edc-23e4949077b4",
   "metadata": {},
   "source": [
    "And 'Dependents':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62f68f-e713-4b4b-8eca-33bc467b0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependents_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Dependents'] = telco_churn['Dependents'].map(dependents_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b339a65-a696-49e3-9538-eae3e3685c6e",
   "metadata": {},
   "source": [
    "'Tenure Months' are already numeric integers so this is fine. 'Phone Service' can be converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ba578-2a04-4044-b99e-2726ab391e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Phone_Service'] = telco_churn['Phone_Service'].map(phone_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b35fd-bbe5-47af-8f0e-b3d35d63b8c2",
   "metadata": {},
   "source": [
    "And 'Multiple Lines':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acca1c5-e99c-4d03-a81d-f2fb354b6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Multiple_Lines'] = telco_churn['Multiple_Lines'].map(multi_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c71713-a302-42ef-a535-e1eb2b9a35ed",
   "metadata": {},
   "source": [
    "'Internet Service' has categorical values so categorical or 'one-hot' encoding will be used here to assign different numeric values for each option. I will assign the 'DSL' value as 1, 'Fibre optic' as 2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4eadc3-c734-4350-afcc-6af18e4b0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_internet = telco_churn['Internet_Service']\n",
    "values_internet = array(data_internet)\n",
    "print(values_internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f64abf-8ec5-4c6d-903c-67bd360df19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_internet = label_encoder.fit_transform(values_internet)\n",
    "print(integer_encoded_internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb3627-9936-4f6c-8215-43c88dd4b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the values from internet service to numbers\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_internet = integer_encoded_internet.reshape(len(integer_encoded_internet), 1)\n",
    "onehot_encoded_internet_service = onehot_encoder.fit_transform(integer_encoded_internet)\n",
    "print(onehot_encoded_internet_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6f10b-7e34-43e1-940a-1b4e038521be",
   "metadata": {},
   "source": [
    "Test the first value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a01cda-cde7-4c0f-a9d3-81c5467a0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded_internet_service[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae90c3-a529-4e77-8de0-9b4606ac9e0d",
   "metadata": {},
   "source": [
    "Repeating for the 'Contract' column which is also a categorical feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133bb58-dcb2-4327-a558-ede0b5320db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_contract = telco_churn['Contract']\n",
    "values_contract = array(data_contract)\n",
    "print(values_contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba33e57-e643-40ab-9cc2-d3a0d7a39a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_contract = label_encoder.fit_transform(values_contract)\n",
    "print(integer_encoded_contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983fcb5a-9fe6-415c-b10c-b7fbded9d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the values from internet service to numbers\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_contract = integer_encoded_contract.reshape(len(integer_encoded_contract), 1)\n",
    "onehot_encoded_contract = onehot_encoder.fit_transform(integer_encoded_contract)\n",
    "print(onehot_encoded_contract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f9c5d-e291-4c56-ac6c-de701b2557de",
   "metadata": {},
   "source": [
    "Test the first value again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a01032-bea2-464d-9c5d-aa62340f649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert first example\n",
    "inverted = label_encoder.inverse_transform([argmax(onehot_encoded_internet_service[0, :])])\n",
    "print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae463e-b175-455d-90e1-c946f6d87230",
   "metadata": {},
   "outputs": [],
   "source": [
    "security_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Online_Security'] = telco_churn['Online_Security'].map(security_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe47bd-1d69-4b74-91c8-b1d5487ecaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_dict = {'Yes':1, 'No':0}\n",
    "telco_churn['Online_Backup'] = telco_churn['Online_Backup'].map(backup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409fcf5-6266-43dc-84ea-fc3a3dae9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_protection_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Device_Protection'] = telco_churn['Device_Protection'].map(device_protection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aeb13a-f5cd-4493-8c4c-04c3579fd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_support_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Tech_Support'] = telco_churn['Tech_Support'].map(tech_support_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36f617-b636-47f2-b1e9-9a93a5eb3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_tv_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Streaming_TV'] = telco_churn['Streaming_TV'].map(stream_tv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ef39c-7d50-4d3b-9010-2181a95ca3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_movies_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Streaming_Movies'] = telco_churn['Streaming_Movies'].map(stream_movies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817912e-d4f8-48b1-be21-1e4ee8915f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = telco_churn['Contract']\n",
    "values = array(data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a6068-6989-4625-b97e-25369ddc1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperless_bill_dict = {'Yes': 1, 'No': 0}\n",
    "telco_churn['Paperless_Billing'] = telco_churn['Paperless_Billing'].map(paperless_bill_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa2140-87f7-48b3-8d9e-c2d64e5a973b",
   "metadata": {},
   "source": [
    "'Payment_Method' also has categorical features which can be converted using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46407b1-839a-4bd0-9470-134d59410f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = telco_churn['Payment_Method']\n",
    "values = array(data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566b1bb-ec85-46d7-9884-52779458a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_payment = label_encoder.fit_transform(values)\n",
    "print(integer_encoded_payment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace96d3c-7ea7-43d8-bc3d-391cd24bb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded_payment = integer_encoded_payment.reshape(len(integer_encoded_payment), 1)\n",
    "onehot_encoded_payment = onehot_encoder.fit_transform(integer_encoded_payment)\n",
    "print(onehot_encoded_payment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39883ebf-8ac2-48de-bde1-addc9dea4932",
   "metadata": {},
   "source": [
    "'Monthly_Charges' are already of float64 datatype, but 'Total_Charges' aren't so they need to be converted from string object to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf571e-15d1-498a-b910-003cc822f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['Total_Charges'] = pd.to_numeric(telco_churn['Total_Charges'], errors='coerce')\n",
    "telco_churn['Total_Charges'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12003d76-9eb6-428f-a07c-5607cdaf83af",
   "metadata": {},
   "source": [
    "The 'Churn_Value' will be designated as the target vector for the purpose of my model and it currently has a simple integer datatype labeled as '1' for churn and '0' for no churn. I can already use these labels.\n",
    "\n",
    "'Churn_Score' remains as an integer. It should be highly correlated with 'Churn_Value' so I will check for this next.\n",
    "\n",
    "Finally, 'CLTV' which is the Customer Lifetime Value is an indicator of the customers importance during this period. This value should be compared to 'Churn_Value' or 'Churn_Score' for any association.\n",
    "\n",
    "In addition to converting all the binary decision outcomes for certain columns above, it may be more prudent to create a for loop to iterate through these columns in a subset to speed up the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5edb2ff-9b58-4f28-9ad4-e63ed980a0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only include all columns with binary outcomes to be converted to integer values\n",
    "# telco_subset = telco_churn['Gender','Senior_Citizen','Partner','Dependents', 'Phone_Service','Multiple_Lines','Online_Security','Online_Backup','Device_Protection','Tech_Support','Streaming_TV','Streaming_Movies','Paperless_Billing']\n",
    "# i=0\n",
    "# define a new function to iterate through the data values and change them\n",
    "# for i in telco_subset:\n",
    "    # dict = {'Yes': 1, 'No': 0}\n",
    "    # telco_subset = telco_subset.map(dict)\n",
    "    # i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece802f5-d982-4de7-af73-762cfc88e066",
   "metadata": {},
   "source": [
    "### Identify Missing Values\n",
    "Looking for missing values and removing them is the next phase, although it may be better to replace them with 0, or impute average values. First I want to calculate the number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e46c5-0786-4bb7-bae1-93e8b9fde993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "telco_churn.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486f1df-b228-40dd-904d-e3ad51b54fd6",
   "metadata": {},
   "source": [
    "There are a total of 7043 rows in the dataset. Having removed the 'CustomerID' column I want to view all the columns in the dataframe once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad30f4-5bfe-4969-a8a4-ed239c08b2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "telco_churn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d6d07-06a8-4ac5-9650-1897b23bb857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "telco_missing = pd.isnull(telco_churn).sum()\n",
    "print(telco_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7aaa3-091b-44c4-9873-961d51cf13cb",
   "metadata": {},
   "source": [
    "Within the dataframe I need to count the location of the rows where the 'Total_Charges' column which have no entry is identical to 'True'. This counts the number of blank spaces in the particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f67ce8-c424-4038-9b22-a97839121034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(telco_churn.loc[telco_churn['Total_Charges'] == ' '])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76124d4-373e-4c44-8ac2-5e80df764d6c",
   "metadata": {},
   "source": [
    "So this means that none of the entries have any blank spaces. Try printing these entries out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88332b-b903-43c3-b38f-10dd5525990e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print these rows\n",
    "telco_churn.loc[telco_churn['Total_Charges'] == ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5540901-a3e0-4604-b4b6-687caecd54b1",
   "metadata": {},
   "source": [
    "Perhaps they contain another value such as NaN, or 0 already. \n",
    "\n",
    "Using the isnull( ) method I may be able to find the sum of these entries and print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db728c-d1e4-44da-8f3d-b6242669b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['Total_Charges'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de391-ebda-4035-90d1-3c4446022e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "telco_churn[telco_churn['Total_Charges'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c844faf-a931-44bb-9b7d-2462fad055a4",
   "metadata": {},
   "source": [
    "I can see all eleven Null values and decide whether to remove these rows from the dataframe completely, or impute some kind of average value or a 0. In this case they've been assigned values of 'NaN', or 'Not a Number'.\n",
    "\n",
    "I've decided to set these missing values to 0 for now. I can always remove the values later and try running the model again to see if there is any difference to the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4d789-a8b4-46c5-a4b1-58ff41e06c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.loc[(telco_churn['Total_Charges'] == 'NaN'), 'Total_Charges'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09d26d-b0d4-4f42-a354-e0de9b214030",
   "metadata": {},
   "source": [
    "Let me see if this has worked and the 'Total_Charges' column with NaN values have been converted to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22d6d2-45a8-4b2d-8572-db20c459e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn[telco_churn['Total_Charges'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2648d-984a-4e38-86d9-b5ac14bcee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn['Total_Charges'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858744e3-cde4-41ca-a4b3-54ef162be294",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_churn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe736831-fcc1-49b5-82b3-45388e9c6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in telco_churn.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (telco_churn[column].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e35d1-208a-4933-985a-8b1182f9748d",
   "metadata": {},
   "source": [
    "Print the cleaned dataset which has undergone the first part of the Transformation phase in the ETL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709c7b6-d4f2-4fca-bb29-4392e6af393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(telco_churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcff34-ef66-4202-b034-2b367ec12a78",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
