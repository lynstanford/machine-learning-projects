{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression\n",
    "The first question I needed to ask myself is why decide to use Polynomial Regression and what does it do exactly? So according to the visualizations from the <a href=\"https://github.com/lynstanford/machine-learning-projects/machine-learning/multiple_regression.ipynb\">Linear Regression</a> notebook, the connection between the dependent and independent variables appear to be strongly linear in relationship although the connection between the 'Volume' of daily bitcoin bought and sold has less association with the daily 'Close' price. \n",
    "\n",
    "Fitting a Linear Regression line to the data may be accurate in this case, with an R-squared value of 0.9991392014437468 and RMSE of 689.1925598643533. However, out of curiosity I decided to see if a Polynomial function could fit the line slightly better by employing a regularization technique to try and improve the bias term by decreasing the Mean Squared Error.\n",
    "\n",
    "The r-squared value is used to represent the overall accuracy score and directly measures the degree of variability associated between the predictors and target variable. The root mean squared value is represented as a loss function and my aim is to reduce its overall value as much as possible using regularization.\n",
    "\n",
    "I know that Polynomial Regression is useful in determining non-linear relationships between multiple independent variables and the dependent variable, so it can be classified as a type of multiple linear regression. I can try to improve the fit of a prediction line to the data and improve estimates by changing the 'degree of fit' parameter, or by utilizing regularization.\n",
    "\n",
    "## Import Data\n",
    "Keeping the data loading simple this time will reduce the overall time it takes to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import data from filepath\n",
    "btc_cad = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "# storing dataset from filepath into new dataframe\n",
    "bitcoin = pd.DataFrame(btc_cad).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads the entire dataset and then stores all the values in a single dataframe object.\n",
    "\n",
    "## Feature Selection and Scaling\n",
    "Checking to see what features are present within the current dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all column names\n",
    "bitcoin.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to remove the columns I don't need including 'Date' and 'Adj Close', selecting only the remaining ones to include in the X variable such as 'Open', 'High', 'Low' and 'Volume'. The remaining column of 'Close' in the same dataframe will be used as the target variable output, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove feature with string values - Date\n",
    "del bitcoin['Date']\n",
    "\n",
    "# remove adj close as I will not be using this\n",
    "del bitcoin['Adj Close']\n",
    "\n",
    "# see the remaining features\n",
    "bitcoin.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning features to X gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features as X dataframe\n",
    "X = bitcoin[['Open','High','Low','Volume']]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the shape of the overall dataset before polynomial regression and before splitting gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select target as y series\n",
    "y = bitcoin['Close']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to select the right column vectors is using indexation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:,0:5].values\n",
    "print(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.iloc[:, ].values\n",
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the dataset need re-scaling? In this particular case the (X) predictors include 3 price variables and 1 volume variable which is scaled differently. The (y) target variable is another price variable, so the data would benefit from re-scaling. The transformation I have chosen will shift the values to a range between 0 and 1 for each column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy of the dataframe first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin = bitcoin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import preprocessing from sci-kit learn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# define min max scaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# transform data\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "\n",
    "bitcoin_features = pd.DataFrame(X_scaled)\n",
    "\n",
    "bitcoin_features.to_csv(r'C:\\Users\\lynst\\Documents\\GitHub\\machine-learning-projects\\machine-learning\\bitcoin_features.csv', index = False, header = True)\n",
    "\n",
    "print(bitcoin_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating this process for the y values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "x = bitcoin_features.iloc[0:362,:1]\n",
    "y = bitcoin_features.iloc[0:362,-1:]\n",
    "z = bitcoin_features.iloc[0:362,3:4]\n",
    "\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x, y, z, c='r', marker='o')\n",
    "ax.set_xlabel(\"Open\")\n",
    "ax.set_ylabel(\"Close\")\n",
    "ax.set_zlabel(\"Volume\")\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for this particular comparison between the open and close prices and volume of Bitcoin transactions I can see a positive linear relationship between 'Open' and 'Close' prices. As one increases in value, so does the other. The relationship they have with 'Volume' appears somewhat linear also except for and outlier when volume spiked on Feb 26th, 2021. This was apparently due to bets by Tesla and Mastercard and stood out significantly compared to anything seen previously this year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the outliers in the 'Volume' feature I've decided to use a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = bitcoin_features.iloc[0:362,3:4]\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "vol = z\n",
    "vol.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interquartile Range Method\n",
    "To determine the outliers using an Interquartile range and remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the percentile package from numpy\n",
    "from numpy import percentile\n",
    "\n",
    "# convert the Series to a one-dimensional array\n",
    "vol = np.array(z)\n",
    "\n",
    "# calculate interquartile range\n",
    "q25, q75 = percentile(vol, 25), percentile(vol, 75)\n",
    "iqr = q75 - q25\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
    "\n",
    "# calculate the outlier cutoff\n",
    "cut_off = iqr * 1.5\n",
    "lower, upper = q25 - cut_off, q75 + cut_off\n",
    "\n",
    "# identify outliers\n",
    "outliers = [v for v in vol if v < lower or v > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "\n",
    "# remove outliers\n",
    "non_outliers = [v for v in vol if v >= lower and v <= upper]\n",
    "print('Non-outlier observations: %d' % len(non_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation Method\n",
    "To determine outliers using the mean and standard deviation and removing any values which are outside 3 standard deviations from the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers with standard deviation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "# convert the Series to a one-dimensional array\n",
    "vol = np.array(z)\n",
    "\n",
    "# calculate summary statistics\n",
    "vol_mean, vol_std = mean(vol), std(vol)\n",
    "\n",
    "# identify outliers\n",
    "cut_off = vol_std * 3\n",
    "lower, upper = vol_mean - cut_off, vol_mean + cut_off\n",
    "\n",
    "# identify outliers\n",
    "outliers = [v for v in vol if v < lower or v > upper]\n",
    "print('Identified outliers: %d' % len(outliers))\n",
    "\n",
    "# remove outliers\n",
    "non_outliers = [v for v in vol if v >= lower and v <= upper]\n",
    "print('Non-outlier observations: %d' % len(non_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Outlier Detection Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# retrieve the arrays\n",
    "X = bitcoin[['Open','High','Low','Volume']].values\n",
    "y = bitcoin['Close'].values\n",
    "\n",
    "# split into input and output elements\n",
    "X, y = bitcoin_features.iloc[0:362, 0:4], bitcoin_features.iloc[0:362, 4:5]\n",
    "\n",
    "# summarize the shape of the dataset\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on training dataset with outliers removed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# retrieve the arrays\n",
    "X = bitcoin[['Open','High','Low','Volume']].values\n",
    "y = bitcoin['Close'].values\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# summarize the shape of the training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# identify outliers in the training dataset\n",
    "lof = LocalOutlierFactor()\n",
    "y_pred = lof.fit_predict(X_train)\n",
    "\n",
    "# select all rows that are not outliers\n",
    "mask = y_pred != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# fit the model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed the outliers which fall outside the boundaries set by the LocalOutlierFactor( ) function, there appear to be 12 entries removed from the updated training set giving a total of 241 rows. It should be important to remember to use the LocalOutlierFactor( ) function and fit the data to the training set. \n",
    "\n",
    "The Root Mean Squared Error metric is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mae)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will perform both linear regression and polynomial regression to display prediction lines of best fit. I will only display the 'Close' price vs 'Date', so just two variables. I have chosen to manipulate data for price and time and store them in a new array called 'btc_new'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from filepath\n",
    "btc_cad = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "# storing dataset from filepath into new dataframe\n",
    "bitcoin = pd.DataFrame(btc_cad).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have decided to create a new data array containing the variables for date and the daily close price, having converted the dates to straight forward number of days (ranging from 1 to 362), the same as the total number of 'non-null' entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Linear Regression results\n",
    "figure = plt.figure(figsize=(14,8))\n",
    "\n",
    "x = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,\n",
    "              42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,\n",
    "              80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,\n",
    "              113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,\n",
    "              141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,\n",
    "              169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,\n",
    "              197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,\n",
    "              225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,\n",
    "              253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,\n",
    "              281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,\n",
    "              309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,\n",
    "              337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362])\n",
    "y = np.array([9763.94,10096.28,10451.16,10642.81,10669.64,10836.68,10941.6,10917.12,12211.47,12083.24,12644.26,12820.88,12576.13,\n",
    "              12551.25,12642.56,13128.23,13904.59,13795.97,13448.25,12194.49,12061.87,12397.94,13062.2,13659.96,13162.55,\n",
    "              13228.95,13627.94,13559.83,13560.94,13241.13,12666.33,12857.9,12895.3,12293.22,12445.06,12177.47,12630.37,13121.03,\n",
    "              13000.03,13359.9,13034.29,13812.49,12873.86,13031.1,13233.33,12972.79,12956.88,13071.93,13063.21,13147.35,13253.52,\n",
    "              12711.01,12883.57,12876.0,12803.02,12791.0,12907.76,12871.53,12793.94,12640.25,12700.57,12668.61,13028.33,13041.35,\n",
    "              12707.97,12634.47,12541.29,12380.43,12506.51,12552.25,12404.78,12543.14,12380.24,12313.75,12374.98,12296.15,\n",
    "              12693.78,12588.0,12745.56,12599.85,12614.86,12556.24,12613.8,12580.1,12571.09,12417.11,12394.21,12428.28,12437.98,\n",
    "              12469.29,12395.2,12604.21,12781.59,12843.04,12796.08,12982.28,13288.45,14662.38,14600.23,14809.4,14902.15,15186.41,\n",
    "              15771.32,14809.83,15064.88,14900.92,15582.92,15690.25,15529.15,15733.03,15633.23,15862.41,15187.81,15342.8,\n",
    "              15581.58,15614.35,15742.82,15761.58,16203.14,15775.92,15535.99,15648.99,15273.86,15391.56,15375.86,15563.07,\n",
    "              14964.79,15097.17,14859.35,15119.23,15072.56,15319.24,15230.27,15626.5,14891.18,13462.52,13731.63,13284.56,\n",
    "              13442.84,13579.41,13413.77,13471.4,13668.72,13705.81,13760.17,13609.86,14073.93,14244.94,14466.7,14398.2,14452.49,\n",
    "              14650.47,14436.9,13916.7,14013.41,13690.02,14346.23,14325.02,14397.66,14417.81,14322.13,14520.83,14357.78,14115.09,\n",
    "              14089.38,14063.2,14203.03,14325.21,14149.28,14160.03,14410.83,14818.74,14949.65,15031.95,15206.57,14936.71,\n",
    "              14984.18,15137.27,15487.81,15634.23,16869.5,17032.64,16973.62,17205.31,17133.71,17267.45,18012.41,17666.01,\n",
    "              17893.39,18045.32,18357.66,18364.88,17915.13,18279.6,18553.15,20383.97,20332.17,19375.87,20159.37,19945.73,\n",
    "              19926.42,20504.46,21384.43,21423.16,21095.38,20937.96,21858.82,23126.07,23303.57,23320.17,24380.23,24407.62,\n",
    "              24036.96,24010.26,24836.84,24356.4,22332.26,22226.46,23017.67,23600.83,25498.36,24319.8,24803.39,25023.04,23905.97,\n",
    "              24486.96,24726.68,24572.39,23481.02,23800.7,23272.47,23059.65,24014.9,24409.37,24561.12,24658.5,27166.03,29036.47,\n",
    "              29589.87,30525.81,30075.87,29308.0,30662.86,29851.39,30529.54,31754.68,34036.36,33737.04,34786.05,35085.89,\n",
    "              36777.84,36919.19,37393.09,40898.17,41711.19,40865.06,43089.99,46641.22,49945.91,51769.03,51079.4,48817.74,45432.6,\n",
    "              43108.25,47383.3,49563.35,46905.54,46081.14,45711.01,46701.33,45888.95,44892.29,38992.07,42028.71,40834.13,\n",
    "              41094.11,41229.38,41341.23,39009.81,40608.72,43844.33,43794.73,42390.85,43093.59,45408.61,47908.07,47359.34,\n",
    "              48683.77,50115.41,49642.27,58850.14,59023.47,57035.0,60845.81,60319.29,59816.94,61818.59,60583.38,62545.24,\n",
    "              66229.13,65537.27,70533.62,70772.35,72505.56,68363.29,61493.78,62195.54,59404.52,59028.47,58830.69,57312.2,62739.6,\n",
    "              61132.9,64055.45,61573.38,61913.1,61894.22,64684.29,66138.41,69333.05,70691.19,72463.92,71526.08,76406.88,73947.62,\n",
    "              69760.45,70684.33,72931.8,72297.91,73079.59,73038.24,72043.42,68277.85,68917.98,66392.34,65160.43,69541.94,\n",
    "              70596.59,70416.7,72713.56,74365.91,74029.63,74156.38,74675.77,72436.89,73827.42,73942.95,73156.52,70708.54,\n",
    "              73273.84,72978.66,74918.53,75463.91,75243.42,79598.41,78995.98,79437.88,77018.32,75906.36,70374.91,69788.23,\n",
    "              71477.76])\n",
    "\n",
    "# The array of x values\n",
    "reg_line = np.linspace(1, 362)\n",
    "\n",
    "# Applying a linear fit\n",
    "polymodel = np.poly1d(np.polyfit(x, y, deg=1))\n",
    "\n",
    "plt.scatter(x, y, color = 'turquoise')\n",
    "plt.plot(reg_line, polymodel(reg_line))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would represent a highly positive linear relationship between price and time over the last year, specifically a high bias and low variance regression line, or an 'under-fitted' model. \n",
    "\n",
    "Making sure the values work printing out the first 10 values of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a polynomial degree of 2 this time provides an exponential curve. With a degree=2, the highest order value would be an exponent of 2, or x squared. The line used to capture these estimates are of low bias and low variance which is more suitable for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(14,8))\n",
    "\n",
    "polymodel = np.poly1d(np.polyfit(x, y, deg=2))\n",
    "\n",
    "reg_line = np.linspace(1, 362)\n",
    "\n",
    "plt.scatter(x, y, color = 'turquoise')\n",
    "plt.plot(reg_line, polymodel(reg_line))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a polyfit method with a degree of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(14,8))\n",
    "\n",
    "polymodel = np.poly1d(np.polyfit(x, y, deg=50, rcond=None, full=False, w=None, cov=False))\n",
    "\n",
    "reg_line = np.linspace(1, 362, 362)\n",
    "\n",
    "plt.scatter(x, y, color = 'turquoise')\n",
    "plt.plot(reg_line, polymodel(reg_line))\n",
    "plt.show()\n",
    "\n",
    "# to eliminate the rank warning run this cell twice\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence this represents 'over-fitting' and a low bias / high variance model.\n",
    "\n",
    "## Select and Train a Model\n",
    "Having introduced a pipeline to clean the data and apply machine learning algorithms automatically I've chosen to apply a Linear Regression model first. Once again, selecting the data to model for each variable, but this time using four independent variables as input predictors so the polynomial algorithm can be applied to try and fit the model slightly better than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from filepath\n",
    "btc_cad = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "# storing dataset from filepath into new dataframe\n",
    "bitcoin = pd.DataFrame(btc_cad).dropna(axis=0)\n",
    "\n",
    "# remove feature with string values - Date\n",
    "del bitcoin['Date']\n",
    "\n",
    "# remove adj close as I will not be using this\n",
    "del bitcoin['Adj Close']\n",
    "\n",
    "# select features as X dataframe\n",
    "X = bitcoin[['Open','High','Low','Volume']]\n",
    "print(X)\n",
    "\n",
    "# select target as y series\n",
    "y = bitcoin['Close']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "Remember to apply the scaling because 'Volume' has different units of measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the dataset\n",
    "bitcoin = bitcoin.copy()\n",
    "\n",
    "# import preprocessing from sci-kit learn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# define min max scaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# transform data\n",
    "X_scaled = min_max_scaler.fit_transform(X)\n",
    "coin_features = pd.DataFrame(X_scaled)\n",
    "coin_features.to_csv(r'C:\\Users\\lynst\\Documents\\GitHub\\machine-learning-projects\\machine-learning\\bitcoin_features.csv', index = False, header = True)\n",
    "\n",
    "print(coin_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having established a more comparible set of values for the entire dataset, I can proceed with application of my Polynomial model.\n",
    "\n",
    "Before using the polynomial model I will train and fit a Linear Regression algorithm to learn from the entire dataset before the prediction or validation phase.\n",
    "\n",
    "## Fit the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Linear Regression to the dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the r2 score\n",
    "print(lin_reg.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically the dataset should be split into training and test sets so I can fit the model to the training set and learn from it, before validating the accuracy metric against the test set. If I fit the linear regression model to all data points, then split them into two different sets for training or testing, I would be introducing bias into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-running the r-squared score metric I get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2: %0.8f' %r2_score(y_test, lin_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the model is generalizing well as the validation score is higher for the test set than the training set. This is a good sign! It could indicate a degree of data leakage because the score is so high, meaning it may not be the best representation of the correlation measure between the target and predictors because they're all extremely highly correlated.\n",
    "\n",
    "To obtain a descriptive statistical summary I use the describe( ) function which provides figures I can use to calculate the R-squared manually....not just relying on the sklearn.metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can check the R-squared value and plug in the inputs manually to see if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the intercept and coefficient values for x1, x2 ... xn from the linear regression before plugging in their values to the linear regression equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the X values from the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this is linear regression and there are no polynomial terms I can calculate a prediction based on the following:\n",
    "\n",
    "y = a + b1x1 + b2x2 + b3x3 + b4x4\n",
    "\n",
    "Then, this will form the basis for my predictive model so I assign the values to a new variable called 'y_pred'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression terms for intercept and coefficients for row 1 values:\n",
    "a = lin_reg.intercept_ = 104.15\n",
    "b1 = lin_reg.coef_[0] = -0.43\n",
    "b2 = lin_reg.coef_[1] = 0.92\n",
    "b3 = lin_reg.coef_[2] = 0.51\n",
    "b4 = lin_reg.coef_[3] = -0.0000000016\n",
    "x1 = X['Open'] # = 9718.07\n",
    "x2 = X['High'] # = 9838.33\n",
    "x3 = X['Low'] # = 9728.25\n",
    "x4 = X['Volume'] # = 46248330000.0\n",
    "y = 9763.94\n",
    "y_mean = 29864.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the actual values, inetercept and coefficients (slopes), I can calculate predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = a + (b1*x1) + (b2*x2) + (b3*x3) + (b4*x4)\n",
    "y_pred = 104.15 + (-0.43 * 9718.07) + (0.92 * 9838.33) + (0.51 * 9728.25) + (-0.0000000016 * 46248330000.0)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual y value for the first row in the table was 9763.94. To calculate the R-squared score using the definitive statistical formula gives the following result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((np.sum(y_pred - y)**2) / (np.sum(y_mean - y)**2))\n",
    "print(\"The r-squared value is:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to the above score for the entire dataset but remember this is only for the first row in the table. Repeating this process for the entire dataset this time may require a little more thought as I need to iterate through all the values and integrate these inputs and define them as part of a new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 104.15\n",
    "b1 = -0.43\n",
    "b2 = 0.92\n",
    "b3 = 0.51\n",
    "b4 = -0.0000000016\n",
    "x1 = X['Open']\n",
    "x2 = X['High']\n",
    "x3 = X['Low']\n",
    "x4 = X['Volume']\n",
    "\n",
    "# obtaining the predicted values for y\n",
    "def prediction():\n",
    "    for i in range(len(X)):\n",
    "        i = i + 1\n",
    "        y_pred = a + (b1*x1) + (b2*x2) + (b3*x3) + (b4*x4)\n",
    "    print(y_pred)\n",
    "prediction()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# create actual and predicted values\n",
    "y = bitcoin['Close']\n",
    "actual = y\n",
    "\n",
    "y_pred = a + (b1*x1) + (b2*x2) + (b3*x3) + (b4*x4)\n",
    "predicted = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create error values\n",
    "error = actual - predicted\n",
    "error = y - y_pred\n",
    "errors = np.sum(error)\n",
    "errors = list()\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "def summary_stats():\n",
    "    for i in range(len(actual)):\n",
    "        error = actual - predicted\n",
    "        error = y - y_pred\n",
    "        errors = np.sum(error)\n",
    "        errors = np.sum(y - y_pred)\n",
    "        errors = list()\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "summary_stats()\n",
    "\n",
    "print(\"Mean Squared Error is:\", mse)\n",
    "print(\"Root Mean Squared Error is:\", rmse)\n",
    "print(\"\\n\")\n",
    "\n",
    "# plot errors\n",
    "fig = pyplot.figure(figsize=(10,10))\n",
    "pyplot.plot(errors)\n",
    "pyplot.scatter(y, y_pred, color = 'coral')\n",
    "pyplot.xlabel('Predicted Value')\n",
    "pyplot.ylabel('Actual Value')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained my model on predictor inputs, labeled targets and establishing a measure for the root mean squared error or the 'Loss Function', this can be used to compare the predictions to the targets. An important point to note is that it's better to better to perform scores on unseen test data that isn't used in the training phase. I can assess this measure as the level of risk or the degree of the dispersion of data observations about their mean. The r-squared score is the degree of accuracy of the linear relationship.\n",
    "\n",
    "## Fit the Polynomial Model\n",
    "Using the 'Open', 'High', 'Low' and 'Volume' input features and 'Close' as the output target can be modeled using the following Polynomial Regression formula for predicting y values:\n",
    "\n",
    "\n",
    "$$  y = a + b1x1 + b2x2 + b3x3 + b4x4 + {(b5x1)^2} + {(b6x2)^2} + {(b7x3)^2} + {(b8x4)^2} + b9x1x2 + b10x1x3 + b11x1x4 + b12x2x3 + b13x2x4 + b14x3x4  $$\n",
    "\n",
    "\n",
    "So I can see there are a total of 15 terms in this polynomial function which includes an intercept value (a) and several coefficients for each value of X, X-squared and the cross-multiplied combinations, cross-product, or vector-product of all features (x1, x2, x3, x4 etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Polynomial Regression followed by Linear Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "poly.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no r-squared score for the polynomial model because the resultant training set (which is non-linear) has a different number of features than original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset\n",
    "First I've decided to import the train_test_split function to split the dataset into respective training and test sets (for both X and y values in each set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Regularization to the Model\n",
    "In this particular instance I have chosen L2 regularization which will penalize the Loss (or cost) function by summing the coefficients and equalizing features which exhibit strong colinearity, while simultaneously reducing the effect of redundant coefficients. (See the colinearity matrix in the previous <a href=\"https://github.com/lynstanford/machine-learning-projects/machine-learning/multiple_regression.ipynb\">Linear Regression</a> model). For the purpose of this exercise the Root Mean Squared Error is used as the loss function.\n",
    "\n",
    "Note, I have two hyperparameters I can adjust here including 'alpha' and 'normalize'. The 'alpha' value is the learning rate which controls the size of the incremental steps for the learning rate and the 'normalize' adjustment will re-scale the feature values between 0 and 1 for each observation in the dataset. An r-squared score will be used to determine its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Accuracy Score for the Ridge Regression Fit\n",
    "Using (L2) Ridge Regression first to see how close the relationship between X_train and y_train is, then validating against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.1, normalize=True)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "print('R2: %0.8f' %r2_score(y_test, ridge_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=0.01, normalize=True)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "print('R2: %0.8f' %r2_score(y_test, ridge_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So changing the alpha learning rate from 0.1 to 0.01 implies I am increasing the number of steps it will take to reach the global minimum which means that convergence is slower, but also less likely to over-shoot the optimal solution. The accuracy score has dropped slightly as a result of lowering the alpha hyperparameter.\n",
    "\n",
    "Having expanded the dataset using degree=2, a Polynomial Regression model does not have a score method so the dataset first has to be standardized using a linear model of some description. In this instance I am going to apply RidgeRegression( ) rather than straight forward LinearRegression( ) because the next important step is to standardize data using a regularization technique and reducing the scale of the units of measurement somewhere between -1 and +1, or between 0 and 1 depending on the scale I've chosen. Then the accuracy score can be applied after standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-scaling the Polynomial Dataset\n",
    "Some of the values in this table would be far too large and exacerbate the effects of the model, so once again I have to scale the values and save the result as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new copy of the dataset\n",
    "X_poly = X_poly.copy()\n",
    "\n",
    "# import preprocessing from sci-kit learn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# define min max scaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# transform data\n",
    "X_poly_scaled = min_max_scaler.fit_transform(X_poly)\n",
    "X_poly_features = pd.DataFrame(X_poly_scaled)\n",
    "X_poly_features.to_csv(r'C:\\Users\\lynst\\Documents\\GitHub\\machine-learning-projects\\machine-learning\\X_poly_features.csv', index = False, header = True)\n",
    "\n",
    "print(X_poly_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the new dataset with all the extended features is much larger and I can see a distinctive change in dimensions. Printing out the shape of the training set from the polynomial data gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the training sets for X and y, 70% of the total values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the shape of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=0.1, solver=\"auto\")\n",
    "ridge_reg.fit(X_poly, y)\n",
    "print('R2: %0.8f' %r2_score(y_test, ridge_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha=0.01, solver=\"auto\")\n",
    "ridge_reg.fit(X_poly, y)\n",
    "print('R2: %0.8f' %r2_score(y_test, ridge_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_features[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looking into the first entry of a DataFrame object after applying regularization (L2, Ridge Regression) I can see that where a high degree of multi-colinearity exists between the features, the coefficients of those particular features are given a 'zero' value negating their effect on the model. It's the same as removing them completely. Any remaining coefficients which are positive in value (albeit negligable) stand out and obviously contribute more toward the calculation of the cost function, error calculation accuracy and optimization through iterative single-step gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial regression terms for intercept and coefficients for row 1 values:\n",
    "a = ridge_reg.intercept_ = 11252.62\n",
    "b1 = ridge_reg.coef_[0] = 0.00000000e+00\n",
    "b2 = ridge_reg.coef_[1] = 2.20274036e-08\n",
    "b3 = ridge_reg.coef_[2] = 1.01935648e-10\n",
    "b4 = ridge_reg.coef_[3] = 9.51892565e-11\n",
    "b5 = ridge_reg.coef_[4] = 3.60723223e-08\n",
    "b6 = ridge_reg.coef_[5] = -7.32977764e-06\n",
    "b7 = ridge_reg.coef_[6] = -7.82330374e-07\n",
    "b8 = ridge_reg.coef_[7] = -9.48440941e-07\n",
    "b9 = ridge_reg.coef_[8] = -2.11819215e-13\n",
    "b10 = ridge_reg.coef_[9] = 5.91877653e-06\n",
    "b11 = ridge_reg.coef_[10] = 5.75005955e-06\n",
    "b12 = ridge_reg.coef_[11] = 2.53097632e-12\n",
    "b13 = ridge_reg.coef_[12] = 5.46672010e-06\n",
    "b14 = ridge_reg.coef_[13] = 1.44524432e-12\n",
    "b15 = ridge_reg.coef_[14] = -4.88291757e-19\n",
    "x1 = 1.0\n",
    "x2 = X['Open']         # = 9718.07\n",
    "x3 = X['High']         # = 9838.33\n",
    "x4 = X['Low']          # = 9728.25\n",
    "x5 = X['Volume']       # = 46248330000.0\n",
    "x6 = (X['Open'])**2    # = (9.44408845e+07)**2\n",
    "x7 = (X['High'])**2    # = (9.56095796e+07)**2\n",
    "x8 = (X['Low'])**2     # = (9.45398145e+07)**2\n",
    "x9 = (X['Volume'])**2  # = (4.49445461e+14)**2\n",
    "x10 = x1 * x2          # = 9.67927372e+07\n",
    "x11 = x1 * x3          # = 9.57097338e+07\n",
    "x12 = x1 * x4          # = 4.55007297e+14\n",
    "x13 = x2 * x3          # = 9.46388481e+07\n",
    "x14 = x2 * x4          # = 4.49916270e+14\n",
    "x15 = x3 * x4          # = 2.13891710e+21\n",
    "\n",
    "y = 9763.94\n",
    "y_mean = 29864.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = a + (b1*x1) + (b2*x2) + (b3*x3) + (b4*x4) + (b5*x5) + (b6*x6) + (b7*x7) + (b8*x8) + (b9*x9) + (b10*x10) + (b11*x11) + (b12*x12) + (b13*x13) + (b14*x14)\n",
    "y_pred = 11252.62 + (0.0 * 1.0) + (2.20274036e-08 * 9.71807000e+03) + (1.01935648e-10 * 9.83833000e+03) + (9.51892565e-11 * 9.72825000e+03) + (3.60723223e-08 * 4.62484281e+10) + (-7.32977764e-06 * 9.44408845e+07) + (-7.82330374e-07 * 9.56095796e+07) + (-9.48440941e-07 * 9.45398145e+07) + (-2.11819215e-13 * 4.49445461e+14) + (5.91877653e-06 * 9.67927372e+07) + (5.75005955e-06 * 9.57097338e+07) + (2.53097632e-12 * 4.55007297e+14) + (5.46672010e-06 * 9.46388481e+07) + (1.44524432e-12 * 4.49916270e+14) + (-4.88291757e-19 * 2.13891710e+21)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, comparing this predicted value against the actual y value for the first row in the table of 9763.94, there is quite a difference. To calculate the R-squared score using the definitive statistical formula gives the following result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((np.sum(y_pred - y)**2) / (np.sum(y_mean - y)**2))\n",
    "print(\"The r-squared value is:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create actual and predicted values\n",
    "y = bitcoin['Close']\n",
    "actual = y\n",
    "\n",
    "y_pred = a + (b1*x1) + (b2*x2) + (b3*x3) + (b4*x4) + (b5*x5) + (b6*x6) + (b7*x7) + (b8*x8) + (b9*x9) + (b10*x10) + (b11*x11) + (b12*x12) + (b13*x13) + (b14*x14)\n",
    "predicted = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative effects of the coefficients and their small values have significantly reduced the squared-terms and the cross-product terms making them negligable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# create error values\n",
    "error = actual - predicted\n",
    "error = y - y_pred\n",
    "errors = np.sum(error)\n",
    "errors = list()\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "def summary_stats():\n",
    "    for i in range(len(actual)):\n",
    "        error = actual - predicted\n",
    "        error = y - y_pred\n",
    "        errors = np.sum(error)\n",
    "        errors = list()\n",
    "        mse = mean_squared_error(y, y_pred, squared=True)\n",
    "        rmse = np.sqrt(mse)\n",
    "    print(error)\n",
    "    print('\\n')\n",
    "    print(mse)\n",
    "    print(rmse)\n",
    "    \n",
    "summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error is:\", mse)\n",
    "print(\"Root Mean Squared Error is:\", rmse)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot errors\n",
    "fig = pyplot.figure(figsize=(10,10))\n",
    "pyplot.plot(errors)\n",
    "pyplot.scatter(y, y_pred, color = 'blue')\n",
    "pyplot.xlabel('Predicted Value')\n",
    "pyplot.ylabel('Actual Value')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first note I can make about actual vs predicted daily closing prices leaves me to believe the errors have been reduced significantly about their mean, but I'm not entirely happy with the large value for the Cost function (RMSE) as this implies considerable over-fitting. One way to combat this challenge would be to introduce cross-validation which will take any outliers into account and remove some of the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "print(cross_val_score(ridge, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score = (0.97503778 + 0.87973022 + 0.98669072 + 0.96474476 + 0.98429722 + 0.99525415 + 0.99115778 + 0.89504007 + 0.94847447 + 0.90033073) / 10\n",
    "print(X_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(ridge, X_poly, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_score = (0.97006818 + 0.85076677 + 0.99061033 + 0.97345638 + 0.98865061 + 0.99535352 + 0.99329041 + 0.79100498 + 0.79524206 + 0.87280349) / 10\n",
    "print(X_poly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(ridge, X_train, y_train, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_score = (0.99859545 + 0.9982508 + 0.99873121 + 0.99971355 + 0.97387001 + 0.99905469 + 0.99721033 + 0.99879823 + 0.99922155 + 0.99974627) / 10\n",
    "print(X_train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first important detail to note is that the average cross-validation score is higher for the training set than the entire dataset from ridge regression, or the polynomial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "mse = mean_squared_error(y_test, ridge.predict(X_test), squared=True)\n",
    "mse_scores = cross_val_score(ridge, X_train, y_train, scoring=\"explained_variance\", cv=10)\n",
    "mse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mse = (0.99859549 + 0.99826071 + 0.99876091 + 0.9997251 + 0.97460254 + 0.99909548 + 0.99725663 + 0.99898202 + 0.99922302 + 0.99974633) / 10\n",
    "print(average_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the root mean squared error values, finding the average rmse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rmse = (0.9992975 + 0.99912998 + 0.99938027 + 0.99986254 + 0.9872196 + 0.99954764 + 0.99862737 + 0.99949088 + 0.99961143 + 0.99987316) / 10\n",
    "print(average_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to evaluate the r-squared scores by cross-validating ten different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores_train = cross_val_score(ridge, X_train, y_train, scoring=\"r2\", cv=10)\n",
    "r2_scores_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from r-squared scores first I can determine the average r2 value from 10 different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_r2_train = (0.99859545 + 0.9982508 + 0.99873121 + 0.99971355 + 0.97387 + 0.99905469 + 0.99721033 + 0.99879823 + 0.99922155 + 0.99974627) / 10\n",
    "print(average_r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how this model generalizes to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_test = cross_val_score(ridge, X_test, y_test, scoring=\"r2\", cv=10)\n",
    "r2_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_r2_test = (0.99984803 + 0.99985311 + 0.99813416 + 0.99927484 + 0.99985759 + 0.99957481 + 0.99982543 + 0.99799085 + 0.96522031 + 0.99736867) / 10\n",
    "print(average_r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores seem to drop slightly for the test data but are approximately the same which is a good sign for the model because it means the fit, training and prediction phases will translate well to unseen data (generally) with at least 99.57% accuracy.\n",
    "\n",
    "Another thing to notice is how the 'explained_variance_score' score between the X training values and y training values are similar to the 'r-squared' scores.\n",
    "\n",
    "This particular 'cross_val_predict' metric is actually derived from the 'model_selection' model validation API and then, using indexing to return the first 5 values I get the following predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(ridge, X, y, cv=10)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is meant to determine the performance of different machine learning algorithms so they can be compared and contrasted. It's not meant for training a model, but for checking different models. I will apply the cross-validation on the dataset with all 4 different features (Open, High, Low and Volume) and a target column (Close). Starting from the beginning I will attempt to find the optimal value for K, or that which provides the highest accuracy, or the lowest MSE score.\n",
    "\n",
    "The code below is used to formulate Stochastic Gradient Descent using the Learning Rate and Number of Iterations as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "n_iterations = 1000\n",
    "n = 100\n",
    "n_epochs = 50\n",
    "t0, t1 = 5, 50          # learning schedule hyperparameters\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1)          # random initilaization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(n):\n",
    "        random_index = np.random.randint(n)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        alpha = learning_schedule(epoch * m + i)\n",
    "        theta = theta - alpha * gradients\n",
    "    \n",
    "'''\n",
    "# learning rate\n",
    "alpha = 0.1\n",
    "# parameter with default number of iterations in gradient descent\n",
    "n_iterations = 1000\n",
    "m = eta * n_iterations\n",
    "X_T = np.transpose(X)\n",
    "X_theta = X.dot(theta)\n",
    "\n",
    "gradients = (2 / m) * X_T.dot(X_theta - y)\n",
    "theta = theta - alpha * gradients\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(gradient, start, learn_rate, n_iter):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(\n",
    "    gradient, start, learn_rate, n_iter=50, tolerance=1e-06\n",
    "):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssr_gradient(x, y, b):\n",
    "    res = b[0] + b[1] * x - y\n",
    "    return res.mean(), (res * x).mean()  # .mean() is a method of np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(\n",
    "    gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06\n",
    "):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * np.array(gradient(x, y, vector))\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55])\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\n",
    "\n",
    "gradient_descent(ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008, n_iter=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(\n",
    "    gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06,\n",
    "    dtype=\"float64\"\n",
    "):\n",
    "    # Checking if the gradient is callable\n",
    "    if not callable(gradient):\n",
    "        raise TypeError(\"'gradient' must be callable\")\n",
    "\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "\n",
    "    # Converting x and y to NumPy arrays\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    if x.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "\n",
    "    # Initializing the values of the variables\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "\n",
    "    # Setting up and checking the learning rate\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    if np.any(learn_rate <= 0):\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the maximal number of iterations\n",
    "    n_iter = int(n_iter)\n",
    "    if n_iter <= 0:\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the tolerance\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    if np.any(tolerance <= 0):\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
    "\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Recalculating the difference\n",
    "        diff = -learn_rate * np.array(gradient(x, y, vector), dtype_)\n",
    "\n",
    "        # Checking if the absolute difference is small enough\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "\n",
    "        # Updating the values of the variables\n",
    "        vector += diff\n",
    "\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to considering data types, the code above introduces a few modifications related to type checking and ensuring the use of NumPy capabilities:\n",
    "\n",
    "Lines 8 and 9 check if gradient is a Python callable object and whether it can be used as a function. If not, then the function will raise a TypeError.\n",
    "\n",
    "Line 12 sets an instance of numpy.dtype, which will be used as the data type for all arrays throughout the function.\n",
    "\n",
    "Line 15 takes the arguments x and y and produces NumPy arrays with the desired data type. The arguments x and y can be lists, tuples, arrays, or other sequences.\n",
    "\n",
    "Lines 16 and 17 compare the sizes of x and y. This is useful because you want to be sure that both arrays have the same number of observations. If they dont, then the function will raise a ValueError.\n",
    "\n",
    "Line 20 converts the argument start to a NumPy array. This is an interesting trick: if start is a Python scalar, then itll be transformed into a corresponding NumPy object (an array with one item and zero dimensions). If you pass a sequence, then itll become a regular NumPy array with the same number of elements.\n",
    "\n",
    "Line 23 does the same thing with the learning rate. This can be very useful because it enables you to specify different learning rates for each decision variable by passing a list, tuple, or NumPy array to gradient_descent().\n",
    "\n",
    "Lines 24 and 25 check if the learning rate value (or values for all variables) is greater than zero.\n",
    "\n",
    "Lines 28 to 35 similarly set n_iter and tolerance and check that they are greater than zero.\n",
    "\n",
    "Lines 38 to 47 are almost the same as before. The only difference is the type of the gradient array on line 40.\n",
    "\n",
    "Line 49 conveniently returns the resulting array if you have several decision variables or a Python scalar if you have a single variable.\n",
    "\n",
    "Your gradient_descent() is now finished. Feel free to add some additional capabilities or polishing. The next step of this tutorial is to use what youve learned so far to implement the stochastic version of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sgd(\n",
    "    gradient, x, y, start, learn_rate=0.1, batch_size=1, n_iter=50,\n",
    "    tolerance=1e-06, dtype=\"float64\", random_state=None\n",
    "):\n",
    "    # Checking if the gradient is callable\n",
    "    if not callable(gradient):\n",
    "        raise TypeError(\"'gradient' must be callable\")\n",
    "\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "\n",
    "    # Converting x and y to NumPy arrays\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    n_obs = x.shape[0]\n",
    "    if n_obs != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
    "\n",
    "    # Initializing the random number generator\n",
    "    seed = None if random_state is None else int(random_state)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # Initializing the values of the variables\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "\n",
    "    # Setting up and checking the learning rate\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    if np.any(learn_rate <= 0):\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the size of minibatches\n",
    "    batch_size = int(batch_size)\n",
    "    if not 0 < batch_size <= n_obs:\n",
    "        raise ValueError(\n",
    "            \"'batch_size' must be greater than zero and less than \"\n",
    "            \"or equal to the number of observations\"\n",
    "        )\n",
    "\n",
    "    # Setting up and checking the maximal number of iterations\n",
    "    n_iter = int(n_iter)\n",
    "    if n_iter <= 0:\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the tolerance\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    if np.any(tolerance <= 0):\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
    "\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Shuffle x and y\n",
    "        rng.shuffle(xy)\n",
    "\n",
    "        # Performing minibatch moves\n",
    "        for start in range(0, n_obs, batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
    "\n",
    "            # Recalculating the difference\n",
    "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
    "            diff = -learn_rate * grad\n",
    "\n",
    "            # Checking if the absolute difference is small enough\n",
    "            if np.all(np.abs(diff) <= tolerance):\n",
    "                break\n",
    "\n",
    "            # Updating the values of the variables\n",
    "            vector += diff\n",
    "\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd(\n",
    "...     ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008,\n",
    "...     batch_size=3, n_iter=100_000, random_state=0\n",
    "... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sgd(\n",
    "    gradient, x, y, start, learn_rate=0.1, decay_rate=0.0, batch_size=1,\n",
    "    n_iter=50, tolerance=1e-06, dtype=\"float64\", random_state=None\n",
    "):\n",
    "    # Checking if the gradient is callable\n",
    "    if not callable(gradient):\n",
    "        raise TypeError(\"'gradient' must be callable\")\n",
    "\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "\n",
    "    # Converting x and y to NumPy arrays\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    n_obs = x.shape[0]\n",
    "    if n_obs != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
    "\n",
    "    # Initializing the random number generator\n",
    "    seed = None if random_state is None else int(random_state)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # Initializing the values of the variables\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "\n",
    "    # Setting up and checking the learning rate\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    if np.any(learn_rate <= 0):\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the decay rate\n",
    "    decay_rate = np.array(decay_rate, dtype=dtype_)\n",
    "    if np.any(decay_rate < 0) or np.any(decay_rate > 1):\n",
    "        raise ValueError(\"'decay_rate' must be between zero and one\")\n",
    "\n",
    "    # Setting up and checking the size of minibatches\n",
    "    batch_size = int(batch_size)\n",
    "    if not 0 < batch_size <= n_obs:\n",
    "        raise ValueError(\n",
    "            \"'batch_size' must be greater than zero and less than \"\n",
    "            \"or equal to the number of observations\"\n",
    "        )\n",
    "\n",
    "    # Setting up and checking the maximal number of iterations\n",
    "    n_iter = int(n_iter)\n",
    "    if n_iter <= 0:\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the tolerance\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    if np.any(tolerance <= 0):\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
    "\n",
    "    # Setting the difference to zero for the first iteration\n",
    "    diff = 0\n",
    "\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Shuffle x and y\n",
    "        rng.shuffle(xy)\n",
    "\n",
    "        # Performing minibatch moves\n",
    "        for start in range(0, n_obs, batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
    "\n",
    "            # Recalculating the difference\n",
    "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
    "            diff = decay_rate * diff - learn_rate * grad\n",
    "\n",
    "            # Checking if the absolute difference is small enough\n",
    "            if np.all(np.abs(diff) <= tolerance):\n",
    "                break\n",
    "\n",
    "            # Updating the values of the variables\n",
    "            vector += diff\n",
    "\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the loss function (RMSE) and the accuracy score (R-squared) can be improved upon, the next phase involves using an 'Optimization Function' to re-balance the coefficients of each data point reiterating through the data in an attempt to reduce the loss function. This will involve the adoption of optimization techniques such as 'Gradient Descent', particularly the SGDRegressor( ) algorithm.\n",
    "\n",
    "## Stochastic Gradient Descent\n",
    "Gradient descent provides an alternative way to measure 'Loss' which can be described as an iterative process of adjusting the parameters of a model, fine-tuning the gradient coefficients or using approximation to minimize the overall loss. SGD Regression is meant to be the same as Ridge Regression but perform slightly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import data from filepath\n",
    "btc_cad = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "# storing dataset from filepath into new dataframe\n",
    "bitcoin = pd.DataFrame(btc_cad).dropna(axis=0)\n",
    "\n",
    "# select features as X dataframe\n",
    "X = bitcoin[['Open','High','Low','Volume']]\n",
    "\n",
    "# select target as y series\n",
    "y = bitcoin['Close']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Store model in a variable\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.01)\n",
    "sgd_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 1 - ((np.sum(y_pred - y)**2) / (np.sum(y_mean - y)**2))\n",
    "print(\"The r-squared value is:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sgd_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "print(sgd_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the learning rate in the SGDRegressor has increased the score minimally but they're incredibly low. It would be best to introduce cross-validation to find the best achievable score for a pre-determined number of folds in the dataset.\n",
    "\n",
    "First let's see the effect on Theta, the intercept and coefficient values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Prediction\n",
    "Comparing predictions for training set and test set values. I am continuing to use the RMSE as the score measure to see if it can be optimized as far as possible for the purpose of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "\n",
    "# set the width and height of the plot\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# visualizing the relationship between actual and predicted values for y\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(\"Actual Prices vs Predicted Prices\")\n",
    "\n",
    "# fit a regression line between high and low values to show linear nature\n",
    "sns.regplot(x=y_test, y=y_test_pred)\n",
    "\n",
    "# evaluating the model on train dataset\n",
    "y_train = lin_reg.fit(y_train)\n",
    "y_train_pred = lin_reg.predict(y_train)\n",
    "y_test_pred = lin_reg.predict(y_test)\n",
    "\n",
    "# evaluating the model on test dataset\n",
    "mse_train = np.sum(y_train - y_train_pred)\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "  \n",
    "print(\"\\n\")\n",
    "  \n",
    "print(\"The model performance for the test set\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "print(\"MSE of the train set is {}\".format(mse_train))\n",
    "print(\"RMSE of train set is {}\".format(rmse_train))\n",
    "print(\"R2 score of train set is {}\".format(r2_train))\n",
    "\n",
    "print(\"MSE of the test set is {}\".format(mse_test))\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can deduce that the accuracy for determining predictions appears to be highest for plain linear regression, before any polynomial modeling is applied. This is probably due to the strong nature of the association between the price variables, or their degree of co-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Against Test Set\n",
    "Now to predict the test set results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# to see the first ten results\n",
    "y_test_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the first row of X values to predict the y value by copying from the dataset output from cell 1. Remember only to use the 'Open', 'High', 'Low' and 'Volume' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.predict([[9718.07, 9838.33, 9728.25, 4.624843e+10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the predicted y value is 9792.45 and the actual y value (from output of the first value for 'Close' price) is 9763.94, which is reasonably accurate.\n",
    "\n",
    "## Model Evaluation\n",
    "This is where I need to look into the root mean squared error and R-squared values to see how well the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the score measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual vs Predicted Prices\n",
    "Plotting the actual and predicted results for the 'Close' price provides a nice visual display of the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(y_test, y_test_pred, color=\"orange\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs. Predicted Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Storing the actual and predicted values and their difference in a dictionary object becomes useful. The larger the error, the greater the variance and subsequent standard deviation which translates to less accurate predictions and a less reliable model. \n",
    "\n",
    "Why does this become important? The main purpose of this exercise is to see how useful my model would be in predicting the daily closing price so the first information I can derive from the scatter plot above shows the relationship between independent and dependent variables is strong, but also incredibly linear. It may not pay off to apply Polynomial Regression in such circumstances but may improve the linear fit to the data points with increasing degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_test_pred, \"Error\": y_test - y_test_pred})\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the entire dataset (all the X and y values) and the degree of accuracy by fitting a linear regression predictive line once more, but this time calling Seaborn's regression plot function (regplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# set the width and height of the plot\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# visualizing the relationship between actual and predicted values for y\n",
    "plt.scatter(y_test, y_test_pred, color=\"orange\")\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(\"Actual Prices vs Predicted Prices\")\n",
    "\n",
    "# fit a regression line between high and low values to show linear nature\n",
    "sns.regplot(x=y_test, y=y_test_pred, color=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the RMSE tells me the results seem too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# actual values\n",
    "y_train = lin_reg.fit(y_train)\n",
    "\n",
    "# predicted values\n",
    "y_train_pred = lin_reg.predict(y_train)\n",
    "\n",
    "# calculate errors\n",
    "err = (y_train[i] - y_train_pred[i])**2\n",
    "errors = list()\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    # calculate error\n",
    "    err = (y_train[i] - y_train_pred[i])**2\n",
    "    # store error\n",
    "    errors.append(err)\n",
    "    # report error\n",
    "    print('>%.1f, %.1f = %.3f' % (y_train[i], y_train_pred[i], err))\n",
    "# plot errors\n",
    "plt.plot(errors)\n",
    "plt.xticks(ticks=[i for i in range(len(errors))], labels=predicted)\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ridge_regression.predict(X_test)\n",
    "print(\"Predictions: \", ridge_regression.predict(X_test.iloc[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization term should only be added to the cost function during the training phase. Now the 'training' data has been fit, it becomes important to discover the performance measure on the unregularized test set. Making a prediction on the first 5 values in the test set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lin_reg.predict([[363]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lin_reg2.predict(poly.fit_transform([[363]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "To better capture the different features I have used in my multiple regression I will employ the use of a Pipeline to include the different types of regression models, re-scaling of the features with different units of measurement, regularization techniques to improve the degree of overall fit before validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('poly_reg', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('lin_reg', LinearRegression(normalize=True)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('scores', cross_val_score(pipeline, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    ])\n",
    "\n",
    "'''\n",
    "scores = cross_val_score\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "y_pred = pipeline.predict(X)\n",
    "print(y_pred)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
