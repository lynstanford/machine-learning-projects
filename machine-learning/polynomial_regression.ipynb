{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression\n",
    "So the relationship between the dependent and independent variables appear to be strongly linear in relationship although the connection between the 'Volume' of daily bitcoin bought and sold has less association with the daily 'Close' price. Fitting a Linear Regression line to the data may be accurate in this case, with an R2 value of 0.9991392014437468 and RMSE of 689.1925598643533. However, out of curiosity I decided to see if a Polynomial function could fit the line slightly better to capture some of the variance in this seemingly linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import data\n",
    "bitcoin = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "df = pd.DataFrame(bitcoin).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all column data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Model Selection\n",
    "Assign the (dependant) y variable and (independent) X variables for the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data for modeling\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "Using this data for the Polynomial Features model and splitting it into training and test sets with a 70-30 split. Make a copy of the dataframe first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The following method is one way for training and testing the polynomial function, but first import the relevant libraries and instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# initialize the model for a given degree\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "  \n",
    "# transforms the existing features to higher degree features.\n",
    "X_train_poly = poly_features.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using indexation to return any value in X, say the 1st value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeating for the data contained in the 'X_train_poly' set and we can see that there are 14 values returned so it has created an array with 10 new features for a total of 14 features. This includes element-wise dot product values and some squared values (without going into too much detail). Both the original feature values for 'X1' to 'Xn' and the feature squared value from 'X_train_poly' are returned in this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the current dataframe to a CSV formatted file (or an Excel file) for preservation to view the degree of newly expanded features in a fresh table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/X_train_poly.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new data matrix containing the additional features with the squared values has been created by expanding the number of features and the parameter weights (or coefficients) which represent a quadratic equation. The linear regression model should now be applied again to this newly expanded dataframe containing the polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the transformed features to Linear Regression\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "  \n",
    "# predicting on training data-set\n",
    "y_train_pred = poly_model.predict(X_train_poly)\n",
    "  \n",
    "# predicting on test data-set\n",
    "y_test_pred = poly_model.predict(poly_features.fit_transform(X_test))\n",
    "  \n",
    "# evaluating the model on training dataset\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "  \n",
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "  \n",
    "print(\"The model performance for the training set\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))\n",
    "  \n",
    "print(\"\\n\")\n",
    "  \n",
    "print(\"The model performance for the test set\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the bias term (intercept) and coefficients are both attributes of the LinearRegression() model so I can examine these from the independent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model.intercept_\n",
    "poly_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Pipeline\n",
    "The next method involves placing the expanded polynomial features and linear regression of these within a pipeline which can be trained and used to predict the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "print(y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I wanted to find the shape of the matrices involved and now these datasets have been expanded by the polynomial model I want to make sure they have the same dimensions (m.n) otherwise the polynomial regression won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model on training dataset\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics from using the quadratic equation with 2nd order coefficients and terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "print(y_train_pred)\n",
    "\n",
    "# evaluating the model on training dataset\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_test, y_test)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics from using the quadratic equation with 2nd order coefficients and terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_test, y_test)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(y_test_pred)\n",
    "\n",
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "So the fit of the regression forecast line to the data has increased in its accuracy marginally, but increased nonetheless.\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "1st polynomial r-squared degree:2 = 0.9789579480392447 ?\n",
    "\n",
    "2nd polynomial r-squared degree:3 = 0.9356356818314693 ?\n",
    "\n",
    "This causes a significant drop in the R-squared value or the degree of fit to the line, so may not be the most accurate model to use. I have decided to see if I can improve the model's predictive power by electing to use a Decision Tree Regression model: \"https://github.com/lynstanford/machine-learning-projects/tree/master/machine-learning/decision_tree.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
