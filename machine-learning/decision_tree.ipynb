{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Models\n",
    "The Decision Tree model can be used to discover complex linear relationships between variables for either prediction, binary classification or multi-output classification. Obviously in this case I am looking for price prediction given a relatively small number of features.\n",
    "\n",
    "Importing the dataset and dependancies is the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import data\n",
    "bitcoin = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "# select data subset\n",
    "df = pd.DataFrame(bitcoin).dropna(axis=0)\n",
    "\n",
    "# select data for modeling\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the linear model and fitting the regression line to the entire dataset based on predictors and labelled data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "\n",
    "# fit model\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the entire dataset needs to be split and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = lin_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model (first 5 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14398.87824859 23615.43973771 43221.96880896 30312.88923232\n",
      " 14945.24131451]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model (based on training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model (first 5 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14398.87824859 23615.43973771 43221.96880896 30312.88923232\n",
      " 14945.24131451]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model (based on training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677.2239361854425\n",
      "0.9990817412202545\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_reg.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again finding the RMSE and r-squared for the linear model (based on the test set) this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455.4471597043939\n",
      "0.9994954639778587\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "    \n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this linear model appears to generalize well to the unseen (test) data having reduced the overall variance improving accuracy.\n",
    "\n",
    "# Decision Tree Model Selection\n",
    "Next, it's time to apply a Decision Tree model to the entire dataset before seeking further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = tree_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model (first 5 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14452.49 23303.57 43794.73 30525.81 14984.18]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model (based on training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_reg.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "    \n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This definitely appears to be overfitting with perfect scores for both RMSE and r-squared. Let's see if there is a different outcome for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "    \n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears unlikely also. In order to establish a more likely outcome I will try dividing the dataframe into several smaller training and validation sets and perform the decision tree analysis on each. This is done using K-Fold Cross Validation.\n",
    "\n",
    "## Cross Validation\n",
    "This method will evaluate the Decsion Tree model by splitting the training set into several smaller training and validation sets for training and evaluation separately. This is achieved by using the K-fold cross validation technique and I have split the data into 10 separate folds, cv=10 (which can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [1632.34178217 2576.43835781 1179.73439576 1327.10807347 1038.38290389\n",
      " 1608.54411368 1624.67770866 1672.65698066 1042.90466061 1081.41410478]\n",
      "Mean 1478.4203081498893\n",
      "Standard Deviation 442.5399601154709\n",
      "R-Squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "                         \n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean\", scores.mean())\n",
    "    print(\"Standard Deviation\", scores.std())\n",
    "    print(\"R-Squared:\", r2_test)\n",
    "          \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the scores from cross validation to those from the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [873.89562772 978.49089723 708.25187258 389.29477414 908.56488605\n",
      " 505.32560637 741.94581029 766.55343858 671.3117333  507.85427655]\n",
      "Mean 705.1488922789055\n",
      "Standard Deviation 181.51221092233794\n",
      "R-Squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model Selection\n",
    "Next I will try the Random Forest Regressor model to try and improve on these scores and their accuracy. Using a Random Forest model should provide a more accurate prediction because it's an aggregate of several individual decision tree models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = forest_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model (first 5 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14421.8195 23459.939  43544.2968 30478.4002 15015.1844]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model (based on training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401.0368526738507\n",
      "0.9996779902240511\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_reg.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235.68164177245325\n",
      "0.9998648961601764\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generalizes well with the test set data but I aim to use the cross-validation method one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 938.17362663 1321.49445757  929.87085945  625.46036564  878.25550382\n",
      " 1043.35416649 1543.07519308  834.44839068 1507.62039414  990.03364801]\n",
      "Mean 1061.1786605513507\n",
      "Standard Deviation 284.9154322249237\n",
      "R-Squared: 0.9998648961601764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(forest_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean\", scores.mean())\n",
    "    print(\"Standard Deviation\", scores.std())\n",
    "    print(\"R-Squared:\", r2_test)\n",
    "          \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the cross validation appears to have reduced the standard deviation considerably using the random forest ensemble method. Once again, I am comparing the scores from cross validation to those from the linear regression model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [873.89562772 978.49089723 708.25187258 389.29477414 908.56488605\n",
      " 505.32560637 741.94581029 766.55343858 671.3117333  507.85427655]\n",
      "Mean 705.1488922789055\n",
      "Standard Deviation 181.51221092233794\n",
      "R-Squared: 0.9998648961601764\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So evaluating each of the 10 subsets using K-Folds Cross Validation has produced the most accurate score and lowest margin of error so far.\n",
    "\n",
    "Saving the file as a pickle file will ensure some consistency when comparing scores, parameters and hyperparameters and enable me to start where I left off!\n",
    "\n",
    "I first need import pickle and joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('decision_tree.pickle','wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "pickle_in = open('decision_tree.pickle','rb')\n",
    "clf = pickle.load(pickle_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
