{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Models\n",
    "The Decision Tree model can be used to discover complex linear relationships between variables for either prediction, binary classification or multi-output classification. Obviously in this case I am looking for price prediction given a relatively small number of features.\n",
    "\n",
    "Importing the dataset and dependancies is the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import data\n",
    "bitcoin = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "# select data subset\n",
    "df = pd.DataFrame(bitcoin).dropna(axis=0)\n",
    "\n",
    "# select data for modeling\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the linear model and fitting the regression line to the entire first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "\n",
    "# fit model\n",
    "lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the data needs to be split and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14397.48984    23621.11524338 43241.201114   30343.12275151\n",
      " 14950.27576399 59976.83742331 68718.53704518 69597.91104639\n",
      " 12562.80258658 10030.31754586 14054.52712612 12036.87270379\n",
      " 44255.96407877 75935.65528688 24762.6096622  46736.8240224\n",
      " 13649.27255236 68557.2749307  46667.70067986 36549.10052378\n",
      " 12602.85520768 74172.13480586 12385.4637041  43387.52205204\n",
      " 14901.11879612 12498.95446154 23645.66665522 22685.16554083\n",
      " 79092.8460428  60830.22346878 72379.85762814 15589.84243587\n",
      " 13019.08559787 72398.5429078  62788.0781389  12408.21959286\n",
      " 13320.93295561 73903.73304631 14015.72470178 26907.09443059\n",
      " 13351.3857297  50155.91974286 73059.88957928 59842.92951805\n",
      " 64360.38872615 13732.84304359 50901.26559416 15011.20598847\n",
      " 14266.52506071 14141.0128721  13354.72074968 46823.93739954\n",
      " 14998.72570254 29848.98178711 35596.25176114 12258.61370432\n",
      " 24490.02301387 23977.17966753 23461.87571172 23919.11165705\n",
      " 13171.65527712 76950.21736567 15059.17014179 12765.92136064\n",
      " 16010.79527868 14159.60279605 31353.71339242 24637.25039285\n",
      " 13581.49518325 41367.16242245 12616.05824063 19936.95114771\n",
      " 12585.78993958 24867.28879805 66374.41374224 71839.18906113\n",
      " 78879.59563147 14522.47811261 33894.32088636 14467.35947894\n",
      " 12568.90442142 17888.92190689 70562.68439555 16141.92203882\n",
      " 20934.59040138 23992.55070093 70232.44307718 15621.98792235\n",
      " 14364.30090248 14266.99998028 14402.00363346 13644.95666082\n",
      " 24551.19112923 12296.0143111  15702.86924574 60545.88362964\n",
      " 20899.50517868 34789.34607005 13288.48146102 79469.72595268\n",
      " 10680.14600475 13356.82717877 43448.80250007 12748.52352574\n",
      " 12449.69541508 48311.44330558 18394.24536546 13961.58824211\n",
      " 25234.63573258 75326.5696228  29561.58901573 68763.7884768\n",
      " 13110.02518898 15327.01496065 12316.2095476  15653.77707431\n",
      " 40991.03905284 10596.30102723 58390.74571308 15445.03337183\n",
      " 13254.40712332 12739.85000034 12558.59024886 17816.30767155\n",
      " 17275.62279054 69868.1568868  44102.26079881 74285.82397254\n",
      " 12396.71900776 60227.68699076 62146.86235134 16863.72364707\n",
      " 71165.65285621 12507.75898386 12922.68859658 10362.22844964\n",
      " 12696.3546879  15240.4480347  44961.70839801 12367.33640383\n",
      " 12540.41730595 12578.5789842  73285.16715707 12747.76879361\n",
      " 13599.29514713 12574.60617297 13910.32239208 13159.28344442\n",
      " 23296.47965424 71347.94059831 45449.2027755  62457.37437909\n",
      " 15251.63127806 24503.71410522 12992.0515996  41001.73170257\n",
      " 15084.13086613 17708.94076029 13585.37154135 12957.46353948\n",
      "  9777.86415056 20627.4913251  61862.33331331 14624.63618246\n",
      " 15380.06949022 41897.80903369 12812.15621263 70377.98742843\n",
      " 12971.00939795 60768.32346163 14122.03051555 12519.28055868\n",
      " 13006.39268951 22962.56996096 40202.18595947 24447.67308568\n",
      " 14438.03921986 13476.43520418 17084.67555529 15261.78230588\n",
      " 70594.37381714 70089.62573572 43116.66337904 21367.6094752\n",
      " 12564.73895858 15605.4754694  57116.60017039 71653.98474666\n",
      " 12603.96082711 12606.30727219 47034.9004889  15973.69387108\n",
      " 59807.05779779 12749.914368   45770.90901469 70769.08947904\n",
      " 13102.81286866 15097.65605059 41151.76326748 64744.59875368\n",
      " 12993.16969598 12811.02864674 61335.84008606 14904.7858159\n",
      " 57174.77885673 13447.22555102 17137.9984551  14219.70524005\n",
      " 14619.24023719 30055.01415255 21136.75544499 12823.4122608\n",
      " 12906.68969655 15038.13432197 17261.46136215 65431.99320917\n",
      " 51535.73669254 71102.6678616  14267.95429891 47370.63301041\n",
      " 74096.28402923 15082.59344185 14943.13106219 19635.80554071\n",
      " 30006.82320955 15966.65838345 49699.29210805 12424.31538788\n",
      " 69175.02488282 13329.78009381 14055.31135498 70245.93417694\n",
      " 73092.1039933  15161.85565906 72566.04973659 13213.69850481\n",
      " 18053.60254526 63056.96433211 12480.07137888 12505.22442344\n",
      " 12418.67116534 57662.14460819 30174.94390242 40375.55182717\n",
      " 24502.4327139  12708.76979743 20228.86698043 36570.69409194\n",
      " 75379.47125828 17945.21063244 15673.47488703 12901.07540856\n",
      " 14933.59952679]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675.1045771626677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again finding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the model it needs to be evaluated on the training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_predictions = tree_reg.predict(X_train)\n",
    "tree_mse = mean_squared_error(y_train, price_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(tree_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a perfect error score, but it's more likely the model will have overfitted the data. I will use cross-validation before evaluating on my hold-out set or test set to try and get a more accurate determination of the root mean squared error.\n",
    "\n",
    "### Cross Validation\n",
    "This method will evaluate the Decsion Tree model by splitting the training set into several smaller training and validation sets for training and evaluation separately. This is achieved by using the K-fold cross validation technique and I have split the data into 10 separate folds, cv=10 (which can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean\", scores.mean())\n",
    "    print(\"Standard Deviation\", scores.std())\n",
    "    \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the scores from cross validation to those from the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will try the Random Forest Regressor model to try and improve on these scores and their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)\n",
    "\n",
    "forest_mse = mean_squared_error(y_train, price_predictions)\n",
    "forest_rmse_scores = np.sqrt(forest_mse)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this score appears perfect with a value of zero we need to approach this with some scepticism and try out some alternative models, starting with Grid Search CV. Saving the file as a pickle file will ensure some consistency when comparing scores, parameters and hyperparameters and enable me to start where I left off!\n",
    "\n",
    "I first need import pickle and joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import joblib\n",
    "import pickle\n",
    "\n",
    "joblib.dump(decision_tree, \"my_model.pkl\")\n",
    "# and later...\n",
    "my_model_loaded = joblib.load(\"decision_tree.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
