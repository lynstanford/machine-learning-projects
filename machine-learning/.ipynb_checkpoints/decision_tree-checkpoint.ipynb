{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Models\n",
    "The Decision Tree model can be used to discover complex linear relationships between variables for either prediction, binary classification or multi-output classification. In the first example of a decision tree algorithm I have opted to examine a commonly used dataset which is freely available in Sci-kit Learn called the 'wine' dataset.\n",
    "\n",
    "## Classification\n",
    "The first step involves importing the relevant packages from the Python and SciKit-Learn libraries as well as the Wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df['quality'] = wine.target\n",
    "\n",
    "# showing the first 5 entries\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating this table will help me decide which features to use for the Root Node position for the Decision Tree. Switching out different features in this position can have several deterministic consequences on the overall result. First I have decided to save it as a csv file which enables me to review the dataset in its entirety using spreadsheet analysis but also for preprocessing. It can be useful in case I decide to perform additional feature engineering by creating new data columns which may provide additional insight into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/load_wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at some of the common statistics for the dataset using the describe() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data[:, 0:13]\n",
    "y = wine.target\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(max_depth=None)\n",
    "dtc = dtc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the plot_tree() method within the DecisionTreeClassifier model and setting the 'filled' attribute to 'True' will color the tree nodes explaining the majority class at each decision point in the tree.\n",
    "\n",
    "One important idea to note is that the root node which appears at the very top of each decision tree can be changed in order to arrive at the lowest Gini Impurity calculation path. This is done to compare outcomes based on causation associated with different features and the goal is to reduce the Gini Impurity value to that with the lowest impurity, in this case separating the 'Good' and 'Bad' quality wines in the best possible way.\n",
    "\n",
    "The DecisionTreeClassifier is designed to choose the best split point overall (at the root node) and does a really good job at selecting the next best split points at each decision node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(dtc, filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization of this tree plot can be tidied up using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# important to adjust the size of the plot otherwise it ends up being too small\n",
    "plt.figure(figsize=(16,9))\n",
    "dtc = tree.DecisionTreeClassifier().fit(wine.data, wine.target)\n",
    "plot_tree(dtc, filled=True)\n",
    "plt.title(\"Decision Tree Trained on Red Wine Quality Features\\n\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the training process but only displaying the 'max_depth' in the classifier to a value of 2 (a depth of 2 levels from the root node), or Tree depth as it's known, is a measure of how many splits a tree can make before it must arrive at a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data[:, 0:13]\n",
    "y = wine.target\n",
    "\n",
    "# resizing plot\n",
    "plt.figure(figsize=(16,7))\n",
    "dtc = tree.DecisionTreeClassifier(max_depth=None)\n",
    "dtc = dtc.fit(X, y)\n",
    "tree.plot_tree(dtc, max_depth=2, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Graphviz\n",
    "This method can be used as an alternative way to display the decision tree and is derived from the SciKit Learn 'tree' model set. It's worth noting I encountered some issues when installing graphviz using Conda (which took considerable time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install python-graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing with pip may be a better option to get dot file conversion to png format to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in order to create a graphviz export tree diagram 'export_graphviz' must be imported first and then a filepath must be established for the 'dot' file. Then I can derive a graphviz object from this path with a few defining attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#image_path='C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/wine_tree.dot'\n",
    "\n",
    "dot_data = tree.export_graphviz(dtc, \n",
    "                        out_file=None,\n",
    "                        feature_names=wine.feature_names,\n",
    "                        class_names=wine.target_names,\n",
    "                        rounded=True,\n",
    "                        special_characters=True,\n",
    "                        filled=True\n",
    "                       )\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png('original_tree.png')\n",
    "graph.set_size('\"2,2!\"')\n",
    "graph.write_png('resized_tree.png')\n",
    "\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the dot file to a png file requires a stand-alone installation of graphviz, or a pip installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dot -Tpng wine_tree.dot -o wine_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next in order to try and predict unseen target data based on the labels already used, I can categorize ranked estimates for the quality of wine using a four stage model. Splitting the data first into training and test sets, fitting the DecisionTreeClassifier to the training set and using it to predict the test set to make estimates.\n",
    "\n",
    "It's worth noting that once the predictions are made they will need to be validated using some measure of accuracy. This is determined by the Gini Impurity attribute and the degree to which all the training instances at a node belong to a particular class. A Gini value of 0.0 is completely pure meaning all the instances belong to one class only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[wine.feature_names], df['quality'], random_state=0, test_size=0.25)\n",
    "\n",
    "# Initiate a 4 step modeling pattern\n",
    "# Step 1: import the model to use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Step 2: Make an instance of the Model and set criterion parameter to gini\n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth = 2, random_state = 0)\n",
    "\n",
    "# Step 3: Train the model on the data\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Predict labels of unseen (test) data\n",
    "dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of entries in the 'wine' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have 178 entries in total and 14 columns, including thirteen features and one target column. The training set is represented by 75% of the total values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the size of the test set is 25% of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action of using the predict function provides 45 estimates (25%) for the test set values based on the training data (75%). Let's see if there's any improvement if I were to change the train-test-split test size to 0.2, or 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[wine.feature_names], df['quality'], random_state=0, test_size=0.2)\n",
    "dtc = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=0)\n",
    "dtc.fit(X_train, y_train)\n",
    "predictions = dtc.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    "The score used is from the metrics library and is specifically for multi-class classification measuring the success rate for subset accuracy. Essentially the accuracy score measures the number of times the y predictions are correct given the actual y target values, for example using a 1-d array to list the values in 'y_pred' and 'y_true', then applying the accuracy score as below.\n",
    "Assume there are only 4 values, the code would look a little like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test can be re-named to represent the actual y_true values:\n",
    "y_true = y_test\n",
    "\n",
    "y_true = [0,2,1,0,1,1,0,2,1,1,2,2,0,1,2,1,0,0,1,0,1,0,0,1,1,1,1,1,1,2,0,0,1,0,0,0]\n",
    "y_pred = [0,2,0,0,1,0,0,2,1,1,2,2,0,0,2,1,0,0,2,0,0,0,0,1,1,1,0,1,2,2,0,0,1,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to calculate the total number of accurately predicted observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = 36\n",
    "y_pred_correct = 30\n",
    "\n",
    "accuracy = (y_pred_correct / y_total) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same measurement can be achieved by applying the 'accuracy_score' function after training the decision tree model and fitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "y_test = dtc.predict(X_test)\n",
    "# rounding to 5 decimal places\n",
    "acc_dtc = round(accuracy_score(predictions, y_test) * 100, 5)\n",
    "print(acc_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in terms of evaluation, this model does not inspire a terrific amount of confidence in predicting unseen data correctly which is where parameter tuning will be required to improve upon this score.\n",
    "\n",
    "## Feature Engineering\n",
    "Taking a look at the correlation between various features may help to establish some ideas for engineering better optimization solutions. Then I can try fine-tuning the chosen model afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df.corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the target column entitled 'quality' the highest positive correlation is with 'alcalinity_of_ash' at 0.517859. The highest negative correlated feature is 'flavanoids' at -0.847498."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the width and height of the figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Plot the chosen variables, labels and color\n",
    "plt.scatter(df['quality'], df['alcalinity_of_ash'], marker='o', color='purple')\n",
    "plt.title('Alcalinity of Ash vs Quality\\n')\n",
    "plt.xlabel('Quality')\n",
    "plt.ylabel('Alcalinity of Ash')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the concentration of values centres around the three classes, or categories of quality which are 0, 1 and 2 with successively higher alcalinity of ash from 0 through 2. It's important to note that the range of values generally start at slightly higher minimums for each quality type.\n",
    "\n",
    "I think this data would be more beneficial if I could tell the average 'Alcalinity of Ash' for each grade or 'Quality' of wine, so the average for 0, 1 and 2. Delving into this relationship a bit closer involves looking at the mean values for each distribution, which can be achieved by placing the different qualities in separate buckets and finding their average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_alcalinity = df['quality'].groupby(df['alcalinity_of_ash']).mean()\n",
    "mean_alcalinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine quality counts for each value of 'alcalinity_of_ash'\n",
    "m_a = df.groupby(df['quality'])['alcalinity_of_ash'].value_counts().unstack(fill_value=0)\n",
    "df_counts = pd.DataFrame(m_a)\n",
    "\n",
    "# print count frequency for alcalinity of ash values v quality\n",
    "print(df_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a total of only 63 different values, or variations in 'Alcalinity of Ash'. 10 values fell under quality=0, 13 values fell under quality=1 and a further 10 values under quality=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcalinity_of_ash'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean values for each grade or quality gives:\n",
    "mean_quality = df.groupby(['quality'])['alcalinity_of_ash'].mean()\n",
    "print(mean_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, now I have the 3 mean values for quality 0, 1 and 2 I will check to see if the average of all 3 corresponds to the mean value for alcalinity of ash above in the describe( ) method for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (17.037288 + 20.238028 + 21.416667) / 3\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.494944 is the original mean value so there is a slight discrepancy but reason I calculated the mean values for 'alacalinity of ash' for each grade or 'quality' of wine shows how it increases slightly. We can see this information displayed in the plot above. \n",
    "\n",
    "To display the correlation matrix of features in a plot I have decided to assign the color-mapping parameter 'cmap' in the imshow() function. This helps me to understand the relationship between the predictor variables in a more visually pleasing manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the width and height of the figure\n",
    "plt.figure(figsize=(8, 8))\n",
    "# Select the corr() function on the dataframe and assign it to a 'correlation' variable\n",
    "correlation = df.corr()\n",
    "plt.imshow(correlation, cmap = 'summer', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of columns or features is 14 (0 through 13). The lighter green color represents a stronger positive correlation; the darker green colors are strongly negatively correlated with each other.\n",
    "\n",
    "A better way to show the correlation matrix is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cax = ax.matshow(correlation, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(df.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "\n",
    "ax.set_xticklabels(df.columns)\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "ax.set_yticklabels(df.columns)\n",
    "ax.set_yticks(ticks)\n",
    "\n",
    "# print the correlation factor\n",
    "for i in range(df.shape[1]):\n",
    "    for j in range(14):\n",
    "        text = ax.text(j, i, round(correlation.iloc[i][j],2), ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the darker red color represents a higher, positive correlation. The cooler blue color represents a higher, negative correlation. The lighter shades of red and blue are less correlated features, so overall I can determine the best relationships among the different features and utilize them for a better machine learning model.\n",
    "\n",
    "Key associations occur between 'flavanoids' and 'total_phenols' (0.86) indicating a fairly high, positive, correlation between these two variables. This may contribute to a better grade or quality of wine also. Let's present this positive relationship in another visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for plot showing relationship between 'flavanoids', 'total_phenols' and 'quality' in wine data\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x = df['flavanoids']\n",
    "y = df['total_phenols'] \n",
    "z = df['quality']\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z, linewidths=1, alpha=.7, edgecolor='k', s = 200, c=z)\n",
    "plt.title('Correlation between Flavanoids, Total Phenols and the Quality of Wine')\n",
    "plt.xlabel('Flavanoids')\n",
    "plt.ylabel('Total Phenols')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to describe this visualization I have chosen a 3-D graph in the form of a scatterplot. Essentially we can see there are 3 main qualities of wine labeled 0 (purple), 1 (turquoise) and 2 (yellow). Now if we look at the interaction between Flavanoids and Total Phenols it shows how the distribution of data lies between these two features. \n",
    "\n",
    "At quality 2, I can safely say that Flavanoids and Total Phenols all reside in a fairly consistent, lower range of values which are tightly grouped together. Where the quality of wine equals 1, the range of values appear to be much larger over these two features and show some linearity. Quality equals 0 appears to have slightly higher values for both Flavanoids and Total Phenols, which are not only more tightly grouped but also more linear in their relationship.\n",
    "\n",
    "In conclusion I would say that better quality wines should exhibit a much lower concentration of Flavanoids relative to Total Phenols.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['flavanoids']\n",
    "y = df['total_phenols']\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flavanoids and Total Phenols are strongly associated with wine quality and antioxidant properties which are important constituents and appear to exhibit a positive, almost linear relationship with each other. Attributes of wine quality include color, flavor and taste. It's also important to understand the ecosystem involved in wine production which relies heavily on soil, climate (and atmospheric conditions), altitude and grape lineage. \n",
    "\n",
    "A more detailed model would probably look into some of this data in causal analysis and may provide a better, more accurate model for classification purposes but the main point to remember is that it's important to understand the dataset's origins and the quality of information provided, otherwise the 'garbage in - garbage out' problem ensues.\n",
    "\n",
    "## Making a Prediction\n",
    "So the root node splits using the 'Proline' feature which is the most abundant amino acid in grapes. The next layer at depth 1 has two different splits, one using the 'od280/od315_of_diluted_wines' Protein concentration (111 values) and another using 'flavonoids' which represent high color content (67 values), before finally moving on to layer 2 which is the max_depth specified in this case.\n",
    "\n",
    "I can try and classify a wine based on it's features (all 13) and the path defined by each decision boundary until we reach the end. In order to use the predict_proba() function I would have to input values for each of the 13 features in order to classify the target prediction as follows:\n",
    "\n",
    "Calculating the probabilities of each class occurring is as follows (given a max_depth of 2 layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X = wine.data[:, 0:13]\n",
    "y = wine.target\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(max_depth=None)\n",
    "dtc = dtc.fit(X, y)\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "        dtc, \n",
    "        out_file=\"wine.dot\",\n",
    "        feature_names=wine.feature_names[0:13],\n",
    "        class_names=wine.target_names,\n",
    "        rounded=True,\n",
    "        special_characters=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "# choose all the features or attributes for prediction, placing them in an (m x n) matrix\n",
    "dtc.predict_proba([[13.0, 1.90, 2.38, 16.8, 110, 3.0, 2.94, 0.3, 2.0, 4.9, 1.05, 3.12, 840]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the results are split into three possible outcomes or classes, where wine quality equals 0, 1 or 2. Each class specified or predicted will show the percentage likelihood of occurrence. My output prediction shows a 100% likelihood of wine quality falling under the '0' class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris Dataset\n",
    "This process can be repeated using another dataset from scikit-learn's databases, the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "        tree_clf, \n",
    "        out_file=\"iris_tree.dot\",\n",
    "        feature_names=iris.feature_names[2:],\n",
    "        class_names=iris.target_names,\n",
    "        rounded=True,\n",
    "        special_characters=True,\n",
    "        filled=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng iris_tree.dot -o iris_tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model Selection\n",
    "The following example will continue with the price prediction theme for Bitcoin crypto-currency with relatively fewer features than the classification example. Next, it's time to apply a Decision Tree Regression model to the entire dataset before seeking further improvement in prediction accuracy and lowering variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# select data for modeling\n",
    "bitcoin = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "#load data into dataframe\n",
    "df = pd.DataFrame(bitcoin).dropna(axis=0)\n",
    "# select features and target data\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset into Train and Test Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and fit the decision tree model\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = tree_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model (first 5 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model (based on training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_reg.predict(X_train)\n",
    "lin_mse = mean_squared_error(y_train, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "    \n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This definitely appears to be overfitting with perfect scores for both RMSE and r-squared. Let's see if there is a different outcome for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "    \n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears unlikely also. In order to establish a more likely outcome I will try dividing the dataframe into several smaller training and validation sets and perform the decision tree analysis on each. This is done using K-Fold Cross Validation.\n",
    "\n",
    "## Cross Validation\n",
    "This method will evaluate the Decsion Tree model by splitting the training set into several smaller training and validation sets for training and evaluation separately. This is achieved by using the K-fold cross validation technique and I have split the data into 10 separate folds, cv=10 (which can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "                         \n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean\", scores.mean())\n",
    "    print(\"Standard Deviation\", scores.std())\n",
    "    print(\"R-Squared:\", r2_test)\n",
    "          \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the scores from cross validation to those from the linear regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# fit model\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "lin_scores = cross_val_score(lin_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "The linear regression model appears to reduce the Standard Error but the accuracy for the estimates is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle file to go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Dependencies\n",
    "Dependences are fundamental to record the **computational environment**.   \n",
    "\n",
    "- Use [watermark](https://github.com/rasbt/watermark) to print version of python, ipython, and packages, and characteristics of the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p wget,pandas,numpy,watermark,tarfile,urllib3,matplotlib,seaborn,sklearn \n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c26972402dce5166fbc873f625c08651cf8cab8ad67af055bc25543d79ffa73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
