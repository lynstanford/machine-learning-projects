{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89502158",
   "metadata": {},
   "source": [
    "# Classification Problem\n",
    "Next I will develop a Logistic Regression model to predict different classes. More specifically Logistic Regression is used to estimate the probability that an instance, element or observation belongs to a certain class. The use of one of the most popular collections of information for the purpose of classification is the Titanic dataset and the model I have developed will be submitted to Kaggle's 'Titanic' competition.\n",
    "\n",
    "The purpose of this model is to identify if these passengers 'Survived' or 'Not' which will involve creating a target output column populated with simple binary results of '1' or '0'.\n",
    "\n",
    "## Import the Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863215b",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c645fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/titanic_data.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89cd1b",
   "metadata": {},
   "source": [
    "So I can determine there are a total of 183 entries in this dataset. Initial thoughts are that it might be worth using a more comprehensive dataset, one which might contain the full list of passengers (1309) rather than just a subset (183). This is the most comprehensive list available for the purpose of this exercise that I can find, although estimates for the total number of passengers and crew members are thought to be in the region of 2220. The most comprehensive datasets might be Encyclopedia Titanica and Wikipedia, both of which can be found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a793085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing once again\n",
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/titanic.csv',\n",
    "                     header=0,\n",
    "                     names = ['PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin',\n",
    "                              'Embarked','WikiId','Name_wiki','Age_wiki','Hometown','Boarded','Destination','Lifeboat','Body',\n",
    "                              'Class'])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4cab9",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "Removing unwanted columns and rows and feature engineering is the next important step. Straight away I can see the second dataset I have imported from Kaggle which I have named 'titanic.csv' has a more comprehensive number of entries but also contains 21 columns as opposed to just 12 in the first set. Time to establish which of these columns will be kept or removed using some dimensionality reduction and combination, before establishing what is to be included in a Pandas DataFrame table and target Series.\n",
    "\n",
    "I can remove 'PassengerId', 'Name', 'Age', 'Ticket', 'Fare', 'Embarked', 'WikiId', 'Name_wiki', 'Hometown', 'Destination', 'Lifeboat', 'Body' and 'Class' which will significantly reduce clutter in my table as these features provide no causal relationship with passenger Survival, some of which also represent duplicated information such as passenger class 'Pclass' and 'Class'. This initial step of reductionality helps provide a much more useful dataset overall.\n",
    "\n",
    "Next, let's determine the index and column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0088fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600adfc",
   "metadata": {},
   "source": [
    "So the index starts at 0 and ends at 1309, a total of 1310 passengers (not including crew members)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c715dcb",
   "metadata": {},
   "source": [
    "Creating a variable to store the dropped columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['PassengerId','Name','Age','Ticket','Fare','Embarked','WikiId','Name_wiki','Hometown','Destination','Lifeboat','Body',\n",
    "             'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838ec81",
   "metadata": {},
   "source": [
    "I am using 'Age_wiki' which appears to be a much more comprehensive set of ages from the Wikipedia web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing those columns (axis=1) from the titanic dataset inplace (without copying df)\n",
    "titanic.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95088b36",
   "metadata": {},
   "source": [
    "Which columns or features are left now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2fd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d01436",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "Next it's really important to remove or impute any Null or missing values. This depends on any row values which are missing and also on the data type for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict\n",
    "titanic = pd.DataFrame({\n",
    "    'Survived': pd.Series(titanic['Survived']),\n",
    "    'Pclass': pd.Series(titanic['Pclass']),\n",
    "    'Sex': pd.Series(titanic['Sex']),\n",
    "    'SibSp': pd.Series(titanic['SibSp']),\n",
    "    'Parch': pd.Series(titanic['Parch']),\n",
    "    'Cabin': pd.Series(titanic['Cabin']),\n",
    "    'Age_wiki': pd.Series(titanic['Age_wiki']),\n",
    "    'Boarded': pd.Series(titanic['Boarded'])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6347df1",
   "metadata": {},
   "source": [
    "Calculating the total number of missing or Null values across the 'titanic' dataframe gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_missing = pd.isnull(titanic).sum()\n",
    "print(titanic_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a98e4e",
   "metadata": {},
   "source": [
    "Assessing this output I can determine that the null values in 'Cabin' simply represent tboarding location recorded.hose who did not have a cabin for sleeping quarters. These passengers would have traveled in other areas of the ship so it's important not to drop these values as they represent important data.\n",
    "\n",
    "There are five null values for the 'Boarded' column so for whatever reason these passengers did not have their boarding locations recorded. It's impossible to really know where these individuals boarded the Titanic so I can either leave the values as Null, or remove each of these five entries.\n",
    "\n",
    "Finding the complete set of Null values for the entire titanic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_null = titanic[titanic.isnull().any(axis=1)]\n",
    "print(titanic_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae186e",
   "metadata": {},
   "source": [
    "Taking a look at the total number of Null or missing values for the 'Age_wiki' column only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_age_null = titanic['Age_wiki'].isnull().sum()\n",
    "print(num_age_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa7427",
   "metadata": {},
   "source": [
    "And identifying each row in the dataframe which contains a null value for 'Age_wiki' can be achieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84040cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['Age_wiki'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4422755",
   "metadata": {},
   "source": [
    "Storing these null values in a variable called age_null as I may need to use these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_null = titanic[titanic['Age_wiki'].isnull()]\n",
    "print(age_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831c69a",
   "metadata": {},
   "source": [
    "I can make a decision whether to include these 7 passengers and merely impute some average age for their respective 'Sex', impute an average based on the overall 'Age_wiki', or remove them completely. Seeing as the majority of information for each of these passengers (roughly 4/7ths to 5/7ths) is present I would prefer to keep these entries, so imputing mean values for age based on the individuals sex may be a reasonably accurate average.\n",
    "\n",
    "To find the overall average age only for those null 'Age_wiki' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eadf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(titanic['Age_wiki'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30320c8",
   "metadata": {},
   "source": [
    "This overall mean or average may not be as accurate as calculating the average age for both male and female passengers and imputing them into the 7 missing values.\n",
    "\n",
    "Checking the Null values for the 'Boarded' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['Boarded'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeacd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(titanic['Boarded'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb8773",
   "metadata": {},
   "source": [
    "### Calculate Average Age\n",
    "Calculating the average age for male and female passengers in the table can be done by summing each individual age (by sex) and dividing by the total number of male or female passengers respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91befada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number or count of each unique value in the Sex column\n",
    "titanic['Sex'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974af40a",
   "metadata": {},
   "source": [
    "Having looked at the source data file it hasn't been split into training or test data yet. The csv file contains labeled data entries up to passenger number 891 but no further. Predicted outcomes need to be applied to the unlabeled passengers from 892 up to 1309 inclusive, so the total above is incorrect. \n",
    "\n",
    "This will need to be fixed later on once the data is split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "titanic.Survived[titanic.Sex == 'male'].value_counts().plot(kind='bar', alpha=0.5)\n",
    "plt.title(\"Male Survival\")\n",
    "# create style\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Survived[titanic.Sex == 'female'].value_counts().plot(kind='bar', alpha=0.5)\n",
    "plt.title(\"Female Survival\")\n",
    "# create style\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9dafa",
   "metadata": {},
   "source": [
    "So having determined the unique classes within the 'Sex' column I can further identify the number of Males and Females who survived or not. By taking the 'Survived' column and sub-dividing it according to gender it displays how women were far more likely to have survived the Titanic disaster based on the predictor variables included with this dataset.\n",
    "\n",
    "Next I want to group each category of male and female and store them in a variable called 'gender'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = titanic.groupby(titanic['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0f27d",
   "metadata": {},
   "source": [
    "Checking the first few entries for both sexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Countplot\n",
    "sns.catplot(x =\"Sex\", hue =\"Survived\",\n",
    "kind =\"count\", data = titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774499a",
   "metadata": {},
   "source": [
    "Now there are two variables, one with all the male and one with all the female passengers in the Titanic dataset. There are a total of 843 male and 466 female passengers.\n",
    "\n",
    "The next step is to add these totals together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_total = 843\n",
    "female_total = 466\n",
    "gender_total = male_total + female_total\n",
    "gender_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e27187",
   "metadata": {},
   "source": [
    "Summing the total of all ages for all the passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65692b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = titanic['Age_wiki'].sum()\n",
    "print(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f4be7",
   "metadata": {},
   "source": [
    "And dividing by the total number of passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ave = age / gender_total\n",
    "age_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b254b64",
   "metadata": {},
   "source": [
    "So the overall average age for all passengers calculates to just over 29 years old. Using the describe method to check this gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82928d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315be455",
   "metadata": {},
   "source": [
    "So the first item to notice is that only numeric data appears to have been captured which will need to be fixed soon, but the answer I was looking for now, the mean age found under the 'Age-wiki' column is 29.415829 which is close to the value just calculated of 29.258525, but not identical.\n",
    "\n",
    "Next, to see the average ages for both male and female classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(by='Sex')['Age_wiki'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f630df",
   "metadata": {},
   "source": [
    "So this produces the mean Age by Sex. What if I wanted to find an average age just for the missing values? I could create a sub-group of null values in the age column and apply the mean method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(titanic['Age_wiki'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = gender.get_group('male')\n",
    "male.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = gender.get_group('female')\n",
    "female.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc7d1b",
   "metadata": {},
   "source": [
    "I can see that all the variables are numeric except for the 'Boarded' column which is populated with categorical values. I will change these categorical values into numeric values using 'one-hot encoding'.\n",
    "\n",
    "Viewing the total number of Male passengers who didn't survive (0.0), or did survive (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e855c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic.Sex == 'male']['Survived'].value_counts().plot(kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582412c",
   "metadata": {},
   "source": [
    "The total number of Female passengers who didn't survive (0.0), or did survive (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic.Sex == 'female']['Survived'].value_counts().plot(kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_num = {'male': 0, 'female': 1}\n",
    "\n",
    "titanic['Sex'] = titanic['Sex'].map(gender_num)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50c3d4",
   "metadata": {},
   "source": [
    "The next question is 'What do I do with these average ages?' Because there are only 7 values missing for 'Age' I believe imputing the missing values will be more beneficial than simply deleting the entries altogether. \n",
    "\n",
    "I will use the fillna() method to replace any Null values with imputed values for the average age for both men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age_wiki'].fillna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe959bf",
   "metadata": {},
   "source": [
    "What about the string and categorical variables in the dataset? An important consideration to make when using visualizations would be the data types involved. For example, information can be split into numeric (quantitative) data and categorical (qualitative) data. Categorical data values could be Binomial (such as the target outcome 'Survived', or 'Sex'), Nominal (such as 'Cabin', or 'Boarded'), perhaps even Ordinal (such as 'Pclass'). 'Age_wiki' contains continuous values and the rest such as 'SibSp' (number of Siblings or Spouse) and 'Parch' (number of Children accompanied by Parents) would be discrete values.\n",
    "\n",
    "When it comes to visualizing these different types of data it is generally better to use scatter and line plots for numeric data, but for categorical data, frequency distributions, bar charts and histograms may be a better approach for viewing different classes or sub-sets of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15239937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54d235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aeeefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4057318",
   "metadata": {},
   "source": [
    "## Grouping Data Together\n",
    "Taking a look at the average values for each feature based on their survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9749e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Survived').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072399aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23f772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa48cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4a906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e825ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "men = titanic.loc[titanic.Sex == 'male']['Survived']\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "women = titanic.loc[titanic.Sex == 'female']['Survived']\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a91c2b",
   "metadata": {},
   "source": [
    "## Predictor and Target Variables\n",
    "Now I've established which features are to be included in the whole dataset, it's important to conduct a separation of the predictor variables contained in a dataframe and the target series. This will also lay a foundation for further splitting the labeled data into training and test sets later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the 'Survived' column from the predictors DataFrame variable X\n",
    "X = titanic.drop(pd.Series(titanic['Survived'], axis=1, inplace=True)\n",
    "# assigning this dropped column to the target Series variable y\n",
    "y = pd.Series(titanic['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389aeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ab906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e332dd3",
   "metadata": {},
   "source": [
    "## Nature of the Data\n",
    "Of the remaining data 'Survived' is a float which needs to be changed to int. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Survived'] = titanic['Survived'].astype('int8', copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9616b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968e265",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "titanic.Survived.value_counts(normalize=True).plot(kind=\"bar\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3b6b7",
   "metadata": {},
   "source": [
    "Looking into relationships between the different columns can provide more insight, for example between 'Age', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Boarded' and their 'Survived' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80135351",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.hist(bins=50, figsize(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2549b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a52d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0d84699",
   "metadata": {},
   "source": [
    "The question is \"How do I prepare the dataset with the correct number of total labeled entries?\". I can either change the data at source and slice it using Excel, or alternatively slice the data in Python to only include the first 891 passengers. The reason this needs to be done is because of the risk of feeding inaccurate and unlabeled data back into the model. I believe using test data will introduce bias into the classification results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993db830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda046b3-8829-4d9f-92ed-55d1b1d20904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae754d-cab6-4c26-9edc-902ac6957649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3119d-ce4e-43e5-acf9-333ba30e91ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08099cd8-472c-46c1-b869-e07f1dd73ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d27f7f-686a-4f43-8cda-3e3f5607a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c9d16-05dc-4a23-8a39-8f724f4ce4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(iris['data'], iris['target'])\n",
    "model.predict(iris['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573208d-f179-4455-a553-d1ab15a3b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all categorical features\n",
    "cat_feat = ['PassengerId', 'Name', 'Ticket', 'Sex', 'Cabin', 'Embarked']\n",
    "titanic.drop(cat_feat, axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf5901-41a7-4a27-a324-183c6ec68d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all continuous features\n",
    "cont_feat = ['PassengerId', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "titanic.drop(cont_feat, axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81ee63-f0fa-4f13-85c8-abba69f24464",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Survived').mean()\n",
    "titanic.groupby(titanic['Age'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa091c-5664-4944-b065-96411b2b9519",
   "metadata": {},
   "source": [
    "## Plot Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cb21d-3e8c-4303-90d4-5f74176b037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Age', 'Fare']:\n",
    "    died = list(titanic[titanic['Survived'] == 0][i].dropna())\n",
    "    survived = list(titanic[titanic['Survived'] == 1][i].dropna())\n",
    "    xmin = min(min(died), min(survived))\n",
    "    xmax = max(max(died), max(survived))\n",
    "    width = (xmax - xmin) / 40\n",
    "    sns.distplot(died, color='r', kde=False, bins=np.arange(xmin, xmax, width))\n",
    "    sns.distplot(survived, color='g', kde=False, bins=np.arange(xmin, xmax, width))\n",
    "    plt.legend(['Did not survive', 'Survived'])\n",
    "    plt.title('Overlaid histogram for {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e8da2-a973-46ac-b094-4317df91dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Pclass', 'SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa457705-c9b9-489b-b77a-608d6aaa325f",
   "metadata": {},
   "source": [
    "## Combine SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6016e7-09ea-4bdb-ab19-998b062cc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042b704-d1f3-4a6e-9f5b-b5369e73dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family_cnt'] = titanic['SibSp'] + titanic['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae725c2-870e-4f9d-859e-8255d388a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['family_cnt'] = titanic['SibSp'] + titanic['Parch']\n",
    "sns.catplot(x='family_cnt', y='Survived', data=titanic, kind='point', aspect=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651fd4b-f024-42cb-b7eb-2ca0e87046de",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family_cnt'] = titanic['SibSp'] + titanic['Parch']\n",
    "titanic.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bb51c-896b-4b13-9f50-caad968a974a",
   "metadata": {},
   "source": [
    "## Plot Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f6cb3-21b7-49a9-b4f8-f792c65cf562",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Cabin_ind', 'Sex', 'Embarked']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67009eca-a380-4b4c-b27f-befda45093e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(titanic['Cabin'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4a0ed-22f5-4a8a-8b29-232787f625ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(), 0, 1)\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bca0c-ed07-41ea-bca0-6209df47ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table('Survived', index='Sex', columns='Embarked', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a36d06-d8fb-4706-b2d4-7b46ed25d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table('Survived', index='Cabin_ind', columns='Embarked', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b90fb-dae3-4e76-8a65-d248f22e03bb",
   "metadata": {},
   "source": [
    "## Create indicator for Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08337c6c-b9e7-41a2-ac81-22c4fcbe273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(), 0, 1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c343b27-696f-48f4-9c04-7bc3e97448f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sex to numeric values\n",
    "gender_num = {'male': 0, 'female': 1}\n",
    "\n",
    "titanic['Sex'] = titanic['Sex'].map(gender_num)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5d1d5-ba87-4c7b-8022-995fbd83be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cabin and Boarded\n",
    "titanic.drop(['Cabin', 'Boarded'], axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676f2cd-8427-41d6-8e18-dc6736d09948",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8147817-4550-4ae8-9355-6b68a1458af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1881871-f210-49d9-86e9-9ad6d82ab3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa56d88-aa15-48c5-bb96-97390d318bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv', index=False)\n",
    "X_val.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_features.csv', index=False)\n",
    "X_test.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', index=False)\n",
    "y_val.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_labels.csv', index=False)\n",
    "y_test.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dba65b-54ba-4043-b9f8-91fb324ed17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels), len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7065c1f-4776-40a4-a823-f33977a1399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out cleaned data\n",
    "titanic.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/titanic_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de99ac7-40b5-4103-95f8-58afc11aac20",
   "metadata": {},
   "source": [
    "## Fit and evaluate a basic model using 5-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56395a-de5f-4c9d-94e5-42cd15f7b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "tr_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv')\n",
    "tr_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d038036-8cc6-4c53-b27a-503ce73d2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rf, tr_features, tr_labels.values.ravel(), cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268177b6-5393-4d07-bc9e-5f95f9aa1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aa756-80c6-4102-8830-34f03c0f0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 100],\n",
    "    'max_depth': [2, 10, 20, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6c8af-1d64-4902-bcbf-d6735fa3f51f",
   "metadata": {},
   "source": [
    "## Pipeline: Evaluate results on validation set\n",
    "Using the Titanic dataset from this Kaggle competition.\n",
    "\n",
    "In this section, we will use what we learned in last section to fit the best few models on the full training set and then evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0e800-f383-43e2-92fc-8969ace1d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "tr_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv')\n",
    "tr_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', header=None)\n",
    "\n",
    "val_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_features.csv')\n",
    "val_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_labels.csv', header=None)\n",
    "\n",
    "te_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_features.csv')\n",
    "te_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd697c-e9d6-40e1-b261-754b8a3aba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=5, max_depth=10)\n",
    "rf1.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rf2.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "rf3.fit(tr_features, tr_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc87d7-5416-4d3d-9be7-0cc38b4912ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in [rf1, rf2, rf3]:\n",
    "    y_pred = mdl.predict(val_features)\n",
    "    accuracy = round(accuracy_score(val_labels, y_pred), 3)\n",
    "    precision = round(precision_score(val_labels, y_pred), 3)\n",
    "    recall = round(recall_score(val_labels, y_pred), 3)\n",
    "    print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(mdl.max_depth,\n",
    "                                                                         mdl.n_estimators,\n",
    "                                                                         accuracy,\n",
    "                                                                         precision,\n",
    "                                                                         recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9632a-92a1-4015-9355-38eb3c2035fe",
   "metadata": {},
   "source": [
    "1. Explore and clean the data\n",
    "2. Split data into train / validation / test\n",
    "3. Fit an initial model and evaluate\n",
    "4. Tune hyper parameters\n",
    "5. Evaluate on validation set\n",
    "6. Final model selection and evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6802853-f217-4000-84a7-c22f04e83499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf2.predict(te_features)\n",
    "accuracy = round(accuracy_score(te_labels, y_pred), 3)\n",
    "precision = round(precision_score(te_labels, y_pred), 3)\n",
    "recall = round(recall_score(te_labels, y_pred), 3)\n",
    "print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(rf2.max_depth,\n",
    "                                                                     rf2.n_estimators,\n",
    "                                                                     accuracy,\n",
    "                                                                     precision,\n",
    "                                                                     recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c26972402dce5166fbc873f625c08651cf8cab8ad67af055bc25543d79ffa73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
