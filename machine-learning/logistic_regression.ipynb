{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89502158",
   "metadata": {},
   "source": [
    "# Classification Problem\n",
    "Next I will develop a Logistic Regression model to predict different classes. More specifically Logistic Regression is used to estimate the probability that an instance, element or observation belongs to a certain class. The use of one of the most popular collections of information for the purpose of classification is the Titanic dataset and the model I have developed will be submitted to Kaggle's 'Titanic - Machine Learning from Disaster' competition.\n",
    "\n",
    "The purpose of this model is to identify if these passengers 'Survived' or 'Not' which will involve creating a target output column populated with simple binary results of '1' or '0'.\n",
    "\n",
    "## Import the Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad4046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863215b",
   "metadata": {},
   "source": [
    "## Ingest the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c645fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived  Pclass  \\\n",
       "0           1            2         1       1   \n",
       "1           3            4         1       1   \n",
       "2           6            7         0       1   \n",
       "3          10           11         1       3   \n",
       "4          11           12         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "2                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "3                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "4                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "\n",
       "   Parch    Ticket     Fare Cabin Embarked  \n",
       "0      0  PC 17599  71.2833   C85        C  \n",
       "1      0    113803  53.1000  C123        S  \n",
       "2      0     17463  51.8625   E46        S  \n",
       "3      1   PP 9549  16.7000    G6        S  \n",
       "4      0    113783  26.5500  C103        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/titanic_data.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ba7f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183 entries, 0 to 182\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   183 non-null    int64  \n",
      " 1   PassengerId  183 non-null    int64  \n",
      " 2   Survived     183 non-null    int64  \n",
      " 3   Pclass       183 non-null    int64  \n",
      " 4   Name         183 non-null    object \n",
      " 5   Sex          183 non-null    object \n",
      " 6   Age          183 non-null    float64\n",
      " 7   SibSp        183 non-null    int64  \n",
      " 8   Parch        183 non-null    int64  \n",
      " 9   Ticket       183 non-null    object \n",
      " 10  Fare         183 non-null    float64\n",
      " 11  Cabin        183 non-null    object \n",
      " 12  Embarked     183 non-null    object \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 18.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89cd1b",
   "metadata": {},
   "source": [
    "So I can determine there are a total of 183 entries in this dataset. Initial thoughts are that it might be worth using a more comprehensive dataset, one which might contain the full list of passengers (1310) rather than just a subset (183). This is the most comprehensive list available for the purpose of this exercise that I can find, although estimates for the total number of passengers and crew members are thought to be in the region of 2220. The most comprehensive datasets might be Encyclopedia Titanica and Wikipedia, both of which can be found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a793085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>WikiId</th>\n",
       "      <th>Name_wiki</th>\n",
       "      <th>Age_wiki</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Boarded</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Lifeboat</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>691.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bridgerule, Devon, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Qu'Appelle Valley, Saskatchewan, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Cumings, Mrs. Florence Briggs (née Thayer)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>865.0</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Jyväskylä, Finland</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>14?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Futrelle, Mrs. Lily May (née Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>627.0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Birmingham, West Midlands, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare  ... Embarked WikiId  \\\n",
       "0      0         A/5 21171   7.2500  ...        S  691.0   \n",
       "1      0          PC 17599  71.2833  ...        C   90.0   \n",
       "2      0  STON/O2. 3101282   7.9250  ...        S  865.0   \n",
       "3      0            113803  53.1000  ...        S  127.0   \n",
       "4      0            373450   8.0500  ...        S  627.0   \n",
       "\n",
       "                                    Name_wiki Age_wiki  \\\n",
       "0                     Braund, Mr. Owen Harris     22.0   \n",
       "1  Cumings, Mrs. Florence Briggs (née Thayer)     35.0   \n",
       "2                       Heikkinen, Miss Laina     26.0   \n",
       "3          Futrelle, Mrs. Lily May (née Peel)     35.0   \n",
       "4                    Allen, Mr. William Henry     35.0   \n",
       "\n",
       "                             Hometown      Boarded  \\\n",
       "0          Bridgerule, Devon, England  Southampton   \n",
       "1              New York, New York, US    Cherbourg   \n",
       "2                  Jyväskylä, Finland  Southampton   \n",
       "3         Scituate, Massachusetts, US  Southampton   \n",
       "4  Birmingham, West Midlands, England  Southampton   \n",
       "\n",
       "                               Destination Lifeboat Body Class  \n",
       "0  Qu'Appelle Valley, Saskatchewan, Canada      NaN  NaN   3.0  \n",
       "1                   New York, New York, US        4  NaN   1.0  \n",
       "2                            New York City      14?  NaN   3.0  \n",
       "3              Scituate, Massachusetts, US        D  NaN   1.0  \n",
       "4                            New York City      NaN  NaN   3.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing once again\n",
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/titanic.csv',\n",
    "                     header=0,\n",
    "                     names = ['PassengerId','Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin',\n",
    "                              'Embarked','WikiId','Name_wiki','Age_wiki','Hometown','Boarded','Destination','Lifeboat','Body',\n",
    "                              'Class'])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e00b52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      " 12  WikiId       1304 non-null   float64\n",
      " 13  Name_wiki    1304 non-null   object \n",
      " 14  Age_wiki     1302 non-null   float64\n",
      " 15  Hometown     1304 non-null   object \n",
      " 16  Boarded      1304 non-null   object \n",
      " 17  Destination  1304 non-null   object \n",
      " 18  Lifeboat     502 non-null    object \n",
      " 19  Body         130 non-null    object \n",
      " 20  Class        1304 non-null   float64\n",
      "dtypes: float64(6), int64(4), object(11)\n",
      "memory usage: 214.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c429c6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4cab9",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "Removing unwanted columns and rows and feature engineering is the next important step. Straight away I can see the second dataset I have imported from Kaggle which I have named 'titanic.csv' has a more comprehensive number of entries but also contains 21 columns as opposed to just 12 in the first set. Time to establish which of these columns will be kept or removed using some dimensionality reduction and combination, before establishing what is to be included in a Pandas DataFrame table and target Series.\n",
    "\n",
    "I can remove 'PassengerId', 'Name', 'Age', 'Ticket', 'Fare', 'Embarked', 'WikiId', 'Name_wiki', 'Hometown', 'Destination', 'Lifeboat', 'Body' and 'Class' which will significantly reduce clutter in my table as these features provide no causal relationship with passenger Survival, some of which also represent duplicated information such as passenger class 'Pclass' and 'Class'. This initial step of reductionality helps provide a much more useful dataset overall.\n",
    "\n",
    "### Feature Selection\n",
    "Next, let's determine the index and column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa0088fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1309, step=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600adfc",
   "metadata": {},
   "source": [
    "So the index starts at 0 and ends at 1309, a total of 1310 passengers (not including crew members), but in terms of the data entries in this table only 891 are labeled with target predictions, 419 are unlabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335f6ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'WikiId', 'Name_wiki',\n",
       "       'Age_wiki', 'Hometown', 'Boarded', 'Destination', 'Lifeboat', 'Body',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d93e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict\n",
    "titanic = pd.DataFrame({\n",
    "    'PassengerId': pd.Series(titanic['PassengerId']),\n",
    "    'Survived': pd.Series(titanic['Survived']),\n",
    "    'Pclass': pd.Series(titanic['Pclass']),\n",
    "    'Name': pd.Series(titanic['Name']),\n",
    "    'Sex': pd.Series(titanic['Sex']),\n",
    "    'Age': pd.Series(titanic['Age']),\n",
    "    'SibSp': pd.Series(titanic['SibSp']),\n",
    "    'Parch': pd.Series(titanic['Parch']),\n",
    "    'Ticket': pd.Series(titanic['Ticket']),\n",
    "    'Fare': pd.Series(titanic['Fare']),\n",
    "    'Cabin': pd.Series(titanic['Cabin']),\n",
    "    'Embarked': pd.Series(titanic['Embarked']),\n",
    "    'WikiId': pd.Series(titanic['WikiId']),\n",
    "    'Name_wiki': pd.Series(titanic['Name_wiki']),\n",
    "    'Age_wiki': pd.Series(titanic['Age_wiki']),\n",
    "    'Hometown': pd.Series(titanic['Hometown']),\n",
    "    'Boarded': pd.Series(titanic['Boarded']),\n",
    "    'Destination': pd.Series(titanic['Destination']),\n",
    "    'Lifeboat': pd.Series(titanic['Lifeboat']),\n",
    "    'Body': pd.Series(titanic['Body']),\n",
    "    'Class': pd.Series(titanic['Class']),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f3f23-04f8-48aa-9260-f6bccfca79f4",
   "metadata": {},
   "source": [
    "### Dropping Columns\n",
    "Now a dictionary type has been created to store the information in the dataframe object, the columns to be removed can be assigned to a 'drop_cols' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c34bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Survived', 'PassengerId','Name','Age','Ticket','Fare','Embarked','WikiId','Name_wiki','Hometown','Destination','Lifeboat','Body','Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838ec81",
   "metadata": {},
   "source": [
    "I am using 'Age_wiki' which appears to be a much more comprehensive set of ages from the Wikipedia web site. The 'Boarded' column has nominal data which I will endeavour to convert to numeric values so each port a passenger embarks from will be represented by a number instead. This will help provide more uniform data types. 'Sex' can also be converted to 0's or 1's for the purpose of this exercise and the 'SibSp' and 'Parch' columns can be combined using feature extraction to concatenate the size of families into a new series. \n",
    "\n",
    "Reducing the number of features is called dimensionality reduction and is an important technique used to achieve comparable results in a much faster time frame (with little benefit to performance accuracy), but generally works better with much larger datasets. The removal of all the unwanted columns contained in the 'drop_cols' variable helps speed the model up. The 'Cabin' data will be converted to boolean, or binary values and the 'Pclass' observations are already denoted as integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d7d563-7538-4ccb-bf94-5d0a608b4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing those columns (axis=1) from the titanic dataset inplace (without copying df)\n",
    "# X, y = titanic.drop(drop_cols, axis=1, inplace=True), titanic['Survived']\n",
    "X = titanic.drop(columns=['Survived','PassengerId','Name','Age','Ticket','Fare','Embarked','WikiId','Name_wiki','Hometown','Destination','Lifeboat','Body','Class'][0:891])\n",
    "y = titanic['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95088b36",
   "metadata": {},
   "source": [
    "Which columns or features are left now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2fd0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Age_wiki', 'Boarded'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23416c21-b123-45d6-ab00-0e961677cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Age_wiki</th>\n",
       "      <th>Boarded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C123</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>E46</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex  SibSp  Parch Cabin  Age_wiki      Boarded\n",
       "0       3    male      1      0   NaN      22.0  Southampton\n",
       "1       1  female      1      0   C85      35.0    Cherbourg\n",
       "2       3  female      0      0   NaN      26.0  Southampton\n",
       "3       1  female      1      0  C123      35.0  Southampton\n",
       "4       3    male      0      0   NaN      35.0  Southampton\n",
       "5       3    male      0      0   NaN      22.0   Queenstown\n",
       "6       1    male      0      0   E46      54.0  Southampton\n",
       "7       3    male      3      1   NaN       2.0  Southampton\n",
       "8       3  female      0      2   NaN      26.0  Southampton\n",
       "9       2  female      1      0   NaN      14.0    Cherbourg"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd4b6a3-f17b-4168-adbf-9bd81c917205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "5    0.0\n",
       "6    0.0\n",
       "7    0.0\n",
       "8    1.0\n",
       "9    1.0\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d01436",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "Next it's really important to remove or impute any Null or missing values. This depends on any row values which are missing and also on the data type for each column. Calculating the total number of missing or Null values across the 'titanic' dataframe gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8853e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "Survived        418\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "WikiId            5\n",
      "Name_wiki         5\n",
      "Age_wiki          7\n",
      "Hometown          5\n",
      "Boarded           5\n",
      "Destination       5\n",
      "Lifeboat        807\n",
      "Body           1179\n",
      "Class             5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic_missing = pd.isnull(titanic).sum()\n",
    "print(titanic_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a98e4e",
   "metadata": {},
   "source": [
    "More specifically, to narrow my workable dataset down and find the total number of missing values from the training set of predictor variables, X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257b4661-3a16-4ef4-8982-64fea16148cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass         0\n",
      "Sex            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Cabin       1014\n",
      "Age_wiki       7\n",
      "Boarded        5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_missing = pd.isnull(X).sum()\n",
    "print(X_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae186e",
   "metadata": {},
   "source": [
    "Assessing this output I can determine that the null values in 'Cabin' simply represent those who did not have a cabin for sleeping quarters. These passengers would have traveled in other areas of the ship so it's important not to drop these values as they represent important data and account for over three quarters of the overall number of passengers in this particular set. \n",
    "\n",
    "There are also five null values for the 'Boarded' column so for whatever reason these passengers did not have their boarding locations recorded. It's impossible to really know which port location these individuals departed from so I can either leave the values as Null, or remove each of these five entries. \n",
    "\n",
    "The 'Age-wiki' feature records the ages provided by passengers when purchasing their tickets but it's importTaking a look at the total number of Null or missing values for the 'Age_wiki' column first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_age_null = X['Age_wiki'].isnull().sum()\n",
    "print(num_age_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa7427",
   "metadata": {},
   "source": [
    "And identifying each row in the dataframe which contains a null value for 'Age_wiki' can be achieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84040cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Age_wiki'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4422755",
   "metadata": {},
   "source": [
    "Storing these null values in a variable called age_null as I may need to use these later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_null = X[X['Age_wiki'].isnull()]\n",
    "print(age_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831c69a",
   "metadata": {},
   "source": [
    "I can make a decision whether to include these 7 passengers and merely impute some average age for their respective 'Sex', impute an average based on the overall 'Age_wiki', or remove them completely. Seeing as the majority of information for each of these passengers (roughly 4/7ths to 5/7ths) is present I would prefer to keep these entries, so imputing mean values for age based on the individuals sex may be a reasonably accurate average.\n",
    "\n",
    "To find the overall average age only for those null 'Age_wiki' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eadf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby(X['Age_wiki'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30320c8",
   "metadata": {},
   "source": [
    "This overall mean or average may not be as accurate as calculating the average age for both male and female passengers and imputing them into the 7 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79905797-211a-402a-b039-738dea7c6c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904fa8e-2c36-4acb-af47-1987707f0da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e0e40-03e3-402d-a5f9-35eb2216d3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ebb8773",
   "metadata": {},
   "source": [
    "### Calculate Average Age\n",
    "Calculating the average age for male and female passengers in the table can be done by summing each individual age (by sex) and dividing by the total number of male or female passengers respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91befada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the total count of each of the two unique values in the Sex column\n",
    "X['Sex'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974af40a",
   "metadata": {},
   "source": [
    "Having looked at the source data file it hasn't been split into training or test data yet. The csv file contains labeled data entries up to passenger number 891 but no further. Predicted outcomes need to be applied to the unlabeled passengers from 892 up to 1309 inclusive, so the total above is incorrect. \n",
    "\n",
    "This will need to be fixed later on once the data is split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "titanic.Survived[titanic.Sex == 'male'].value_counts().plot(kind='bar', alpha=0.5)\n",
    "plt.title(\"Male Survival\")\n",
    "# create style\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Survived[titanic.Sex == 'female'].value_counts().plot(kind='bar', alpha=0.5)\n",
    "plt.title(\"Female Survival\")\n",
    "# create style\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9dafa",
   "metadata": {},
   "source": [
    "So having determined the unique classes within the 'Sex' column I can further identify the number of Males and Females who survived or not. By taking the 'Survived' column and sub-dividing it according to gender it displays how women were far more likely to have survived the Titanic disaster based on the predictor variables included with this dataset.\n",
    "\n",
    "Next I want to group each category of male and female and store them in a variable called 'gender'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = X.groupby(X['Sex'])\n",
    "gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0f27d",
   "metadata": {},
   "source": [
    "Checking the first few entries for both sexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Countplot\n",
    "sns.catplot(x =\"Sex\", hue =\"Survived\",\n",
    "kind =\"count\", data = titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0774499a",
   "metadata": {},
   "source": [
    "Now there are two variables, one with all the male and one with all the female passengers in the Titanic dataset. There are a total of 843 male and 466 female passengers.\n",
    "\n",
    "The next step is to add these totals together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_total = 843\n",
    "female_total = 466\n",
    "gender_total = male_total + female_total\n",
    "gender_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e27187",
   "metadata": {},
   "source": [
    "Summing the total of all ages for all the passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65692b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = titanic['Age_wiki'].sum()\n",
    "print(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f4be7",
   "metadata": {},
   "source": [
    "And dividing by the total number of passengers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ave = age / gender_total\n",
    "age_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b254b64",
   "metadata": {},
   "source": [
    "So the overall average age for all passengers calculates to just over 29 years old. Using the describe method to check this gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82928d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315be455",
   "metadata": {},
   "source": [
    "So the first item to notice is that only numeric data appears to have been captured which will need to be fixed soon, but the answer I was looking for now, the mean age found under the 'Age-wiki' column is 29.415829 which is close to the value just calculated of 29.258525, but not identical.\n",
    "\n",
    "Next, to see the average ages for both male and female classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(by='Sex')['Age_wiki'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f630df",
   "metadata": {},
   "source": [
    "So this produces the mean Age by Sex. What if I wanted to find an average age just for the missing values? I could create a sub-group of null values in the age column and apply the mean method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(titanic['Age_wiki'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = gender.get_group('male')\n",
    "male.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "female = gender.get_group('female')\n",
    "female.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc7d1b",
   "metadata": {},
   "source": [
    "I can see that all the variables are numeric except for the 'Boarded' column which is populated with categorical values. I will change these categorical values into numeric values using 'one-hot encoding'.\n",
    "\n",
    "Viewing the total number of Male passengers who didn't survive (0.0), or did survive (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e855c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic.Sex == 'male']['Survived'].value_counts().plot(kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582412c",
   "metadata": {},
   "source": [
    "The total number of Female passengers who didn't survive (0.0), or did survive (1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic.Sex == 'female']['Survived'].value_counts().plot(kind='bar', figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_num = {'male': 0, 'female': 1}\n",
    "\n",
    "titanic['Sex'] = titanic['Sex'].map(gender_num)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50c3d4",
   "metadata": {},
   "source": [
    "The next question is 'What do I do with these average ages?' Because there are only 7 values missing for 'Age' I believe imputing the missing values will be more beneficial than simply deleting the entries altogether. \n",
    "\n",
    "I will use the fillna() method to replace any Null values with imputed values for the average age for both men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Age_wiki'].fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff0f3d-1c60-4ac4-bfce-b2a6cf14a379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0799f7-6426-4e07-9102-18d83d200ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c055eb-ffdf-44c3-a785-6a34e53e3dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "694f2336-d098-4b01-b6b9-a679e56d7afb",
   "metadata": {},
   "source": [
    "Next, checking the total sum of Null values for the 'Boarded' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ada43-ff87-4913-b434-bd063028d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boarded = X['Boarded'].isnull().sum()\n",
    "print(num_boarded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X['Boarded'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0409d9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeacd39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.groupby(X['Boarded'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f7626-2bbd-4fb3-8789-875882592e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25732580-9a32-4057-ad13-840a7d6320f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe959bf",
   "metadata": {},
   "source": [
    "What about the string and categorical variables in the dataset? An important consideration to make when using visualizations would be the data types involved. For example, information can be split into numeric (quantitative) data and categorical (qualitative) data. Categorical data values could be Binomial (such as the target outcome 'Survived', or 'Sex'), Nominal (such as 'Cabin', or 'Boarded'), perhaps even Ordinal (such as 'Pclass'). 'Age_wiki' contains continuous values and the rest such as 'SibSp' (number of Siblings or Spouse) and 'Parch' (number of Children accompanied by Parents) are discrete integer values.\n",
    "\n",
    "When it comes to visualizing these different types of data it is generally better to use scatter and line plots for numeric data, but for categorical data, frequency distributions, bar charts and histograms may be a better approach for viewing different classes or sub-sets of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15239937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6e35190-f305-4136-bb7d-7d331b1c3143",
   "metadata": {},
   "source": [
    "## Row Selection\n",
    "At this stage it's best to employ the use of a Train, Test, Split algorithm using the labeled data (rows 1 to 891) which contains values for the target feature entitled 'Survived'. The model will fit to and learn from this data, then I can evaluate the efficiency of the chosen model against the unseen (un-labeled) data, rows 892 to 1309 which don't contain target values for the 'Survived' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aeeefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4057318",
   "metadata": {},
   "source": [
    "## Grouping Data Together\n",
    "Taking a look at the average values for each feature based on their survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9749e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Survived').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072399aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23f772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa48cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4a906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e825ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "men = titanic.loc[titanic.Sex == 'male']['Survived']\n",
    "rate_men = sum(men)/len(men)\n",
    "\n",
    "print(\"% of men who survived:\", rate_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "women = titanic.loc[titanic.Sex == 'female']['Survived']\n",
    "rate_women = sum(women)/len(women)\n",
    "\n",
    "print(\"% of women who survived:\", rate_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a91c2b",
   "metadata": {},
   "source": [
    "## Predictor and Target Variables\n",
    "Now I've established which features are to be included in the whole dataset, it's important to conduct a separation of the predictor variables contained in a dataframe and the target series. This will also lay a foundation for further splitting the labeled data into training and test sets later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615e807-bc5d-48b7-95d4-5e1487d940ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(titanic[0:890], cols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the 'Survived' column from the predictors DataFrame variable X\n",
    "X = titanic.drop(pd.Series(titanic['Survived'], axis=1, inplace=True)\n",
    "# assigning this dropped column to the target Series variable y\n",
    "y = pd.Series(titanic['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389aeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ab906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e332dd3",
   "metadata": {},
   "source": [
    "## Nature of the Data\n",
    "Of the remaining data 'Survived' is a float which needs to be changed to int. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Survived'] = titanic['Survived'].astype('int8', copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9616b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968e265",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "titanic.Survived.value_counts(normalize=True).plot(kind=\"bar\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3b6b7",
   "metadata": {},
   "source": [
    "Looking into relationships between the different columns can provide more insight, for example between 'Age', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Boarded' and their 'Survived' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80135351",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.hist(bins=50, figsize(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2549b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a52d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0d84699",
   "metadata": {},
   "source": [
    "The question is \"How do I prepare the dataset with the correct number of total labeled entries?\". I can either change the data at source and slice it using Excel, or alternatively slice the data in Python to only include the first 891 passengers. The reason this needs to be done is because of the risk of feeding inaccurate and unlabeled data back into the model. I believe using test data will introduce bias into the classification results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993db830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda046b3-8829-4d9f-92ed-55d1b1d20904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae754d-cab6-4c26-9edc-902ac6957649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3119d-ce4e-43e5-acf9-333ba30e91ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08099cd8-472c-46c1-b869-e07f1dd73ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d27f7f-686a-4f43-8cda-3e3f5607a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c9d16-05dc-4a23-8a39-8f724f4ce4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(iris['data'], iris['target'])\n",
    "model.predict(iris['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573208d-f179-4455-a553-d1ab15a3b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all categorical features\n",
    "cat_feat = ['PassengerId', 'Name', 'Ticket', 'Sex', 'Cabin', 'Embarked']\n",
    "titanic.drop(cat_feat, axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf5901-41a7-4a27-a324-183c6ec68d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all continuous features\n",
    "cont_feat = ['PassengerId', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "titanic.drop(cont_feat, axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81ee63-f0fa-4f13-85c8-abba69f24464",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('Survived').mean()\n",
    "titanic.groupby(titanic['Age'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa091c-5664-4944-b065-96411b2b9519",
   "metadata": {},
   "source": [
    "## Plot Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cb21d-3e8c-4303-90d4-5f74176b037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Age', 'Fare']:\n",
    "    died = list(titanic[titanic['Survived'] == 0][i].dropna())\n",
    "    survived = list(titanic[titanic['Survived'] == 1][i].dropna())\n",
    "    xmin = min(min(died), min(survived))\n",
    "    xmax = max(max(died), max(survived))\n",
    "    width = (xmax - xmin) / 40\n",
    "    sns.distplot(died, color='r', kde=False, bins=np.arange(xmin, xmax, width))\n",
    "    sns.distplot(survived, color='g', kde=False, bins=np.arange(xmin, xmax, width))\n",
    "    plt.legend(['Did not survive', 'Survived'])\n",
    "    plt.title('Overlaid histogram for {}'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e8da2-a973-46ac-b094-4317df91dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Pclass', 'SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa457705-c9b9-489b-b77a-608d6aaa325f",
   "metadata": {},
   "source": [
    "## Combine SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6016e7-09ea-4bdb-ab19-998b062cc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['SibSp', 'Parch']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042b704-d1f3-4a6e-9f5b-b5369e73dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family_cnt'] = titanic['SibSp'] + titanic['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae725c2-870e-4f9d-859e-8255d388a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['family_cnt'] = titanic['SibSp'] + titanic['Parch']\n",
    "sns.catplot(x='family_cnt', y='Survived', data=titanic, kind='point', aspect=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651fd4b-f024-42cb-b7eb-2ca0e87046de",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family_cnt'] = titanic['SibSp'] + titanic['Parch']\n",
    "titanic.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bb51c-896b-4b13-9f50-caad968a974a",
   "metadata": {},
   "source": [
    "## Plot Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f6cb3-21b7-49a9-b4f8-f792c65cf562",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['Cabin_ind', 'Sex', 'Embarked']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='Survived', data=titanic, kind='point', aspect=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67009eca-a380-4b4c-b27f-befda45093e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(titanic['Cabin'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4a0ed-22f5-4a8a-8b29-232787f625ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(), 0, 1)\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bca0c-ed07-41ea-bca0-6209df47ca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table('Survived', index='Sex', columns='Embarked', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a36d06-d8fb-4706-b2d4-7b46ed25d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pivot_table('Survived', index='Cabin_ind', columns='Embarked', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b90fb-dae3-4e76-8a65-d248f22e03bb",
   "metadata": {},
   "source": [
    "## Create indicator for Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08337c6c-b9e7-41a2-ac81-22c4fcbe273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(), 0, 1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c343b27-696f-48f4-9c04-7bc3e97448f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sex to numeric values\n",
    "gender_num = {'male': 0, 'female': 1}\n",
    "\n",
    "titanic['Sex'] = titanic['Sex'].map(gender_num)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5d1d5-ba87-4c7b-8022-995fbd83be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cabin and Boarded\n",
    "titanic.drop(['Cabin', 'Boarded'], axis=1, inplace=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676f2cd-8427-41d6-8e18-dc6736d09948",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8147817-4550-4ae8-9355-6b68a1458af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1881871-f210-49d9-86e9-9ad6d82ab3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [y_train, y_val, y_test]:\n",
    "    print(round(len(dataset) / len(labels), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa56d88-aa15-48c5-bb96-97390d318bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv', index=False)\n",
    "X_val.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_features.csv', index=False)\n",
    "X_test.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', index=False)\n",
    "y_val.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_labels.csv', index=False)\n",
    "y_test.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dba65b-54ba-4043-b9f8-91fb324ed17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels), len(y_train), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7065c1f-4776-40a4-a823-f33977a1399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out cleaned data\n",
    "titanic.to_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/titanic_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de99ac7-40b5-4103-95f8-58afc11aac20",
   "metadata": {},
   "source": [
    "## Fit and evaluate a basic model using 5-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56395a-de5f-4c9d-94e5-42cd15f7b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "tr_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv')\n",
    "tr_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d038036-8cc6-4c53-b27a-503ce73d2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rf, tr_features, tr_labels.values.ravel(), cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268177b6-5393-4d07-bc9e-5f95f9aa1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aa756-80c6-4102-8830-34f03c0f0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 100],\n",
    "    'max_depth': [2, 10, 20, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6c8af-1d64-4902-bcbf-d6735fa3f51f",
   "metadata": {},
   "source": [
    "## Pipeline: Evaluate results on validation set\n",
    "Using the Titanic dataset from this Kaggle competition.\n",
    "\n",
    "In this section, we will use what we learned in last section to fit the best few models on the full training set and then evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0e800-f383-43e2-92fc-8969ace1d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "tr_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_features.csv')\n",
    "tr_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/train_labels.csv', header=None)\n",
    "\n",
    "val_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_features.csv')\n",
    "val_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/val_labels.csv', header=None)\n",
    "\n",
    "te_features = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_features.csv')\n",
    "te_labels = pd.read_csv('C:/Users/lynst/Documents/Python Scripts/Ex_Files_Applied_Machine_Learning/Exercise Files/test_labels.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd697c-e9d6-40e1-b261-754b8a3aba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=5, max_depth=10)\n",
    "rf1.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "rf2.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "rf3.fit(tr_features, tr_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc87d7-5416-4d3d-9be7-0cc38b4912ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in [rf1, rf2, rf3]:\n",
    "    y_pred = mdl.predict(val_features)\n",
    "    accuracy = round(accuracy_score(val_labels, y_pred), 3)\n",
    "    precision = round(precision_score(val_labels, y_pred), 3)\n",
    "    recall = round(recall_score(val_labels, y_pred), 3)\n",
    "    print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(mdl.max_depth,\n",
    "                                                                         mdl.n_estimators,\n",
    "                                                                         accuracy,\n",
    "                                                                         precision,\n",
    "                                                                         recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9632a-92a1-4015-9355-38eb3c2035fe",
   "metadata": {},
   "source": [
    "1. Explore and clean the data\n",
    "2. Split data into train / validation / test\n",
    "3. Fit an initial model and evaluate\n",
    "4. Tune hyper parameters\n",
    "5. Evaluate on validation set\n",
    "6. Final model selection and evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6802853-f217-4000-84a7-c22f04e83499",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf2.predict(te_features)\n",
    "accuracy = round(accuracy_score(te_labels, y_pred), 3)\n",
    "precision = round(precision_score(te_labels, y_pred), 3)\n",
    "recall = round(recall_score(te_labels, y_pred), 3)\n",
    "print('MAX DEPTH: {} / # OF EST: {} -- A: {} / P: {} / R: {}'.format(rf2.max_depth,\n",
    "                                                                     rf2.n_estimators,\n",
    "                                                                     accuracy,\n",
    "                                                                     precision,\n",
    "                                                                     recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08247c-6081-4914-b26d-34d8fb6f5955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f9ccf-524d-4339-9815-25fd6a8189dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fce98a-ea68-40cf-9abe-8fdd5dfcf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.DataFrame({\n",
    "    'Pclass': pd.Series(titanic['Pclass']),\n",
    "    'Sex': pd.Series(titanic['Sex']),\n",
    "    'SibSp': pd.Series(titanic['SibSp']),\n",
    "    'Parch': pd.Series(titanic['Parch']),\n",
    "    'Cabin': pd.Series(titanic['Cabin']),\n",
    "    'Age_wiki': pd.Series(titanic['Age_wiki']),\n",
    "    'Boarded': pd.Series(titanic['Boarded'])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0898438",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p wget,pandas,numpy,watermark,matplotlib,seaborn,sklearn,warnings\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c26972402dce5166fbc873f625c08651cf8cab8ad67af055bc25543d79ffa73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
