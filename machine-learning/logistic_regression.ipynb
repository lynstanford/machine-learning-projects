{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89502158",
   "metadata": {},
   "source": [
    "# Classification Problem\n",
    "Next I will develop a Logistic Regression model to predict different classes. More specifically Logistic Regression is used to estimate the probability that an instance/element/observation belongs to a certain class. The use of one the most popular collections of information for the purpose of classification is the Titanic dataset and the model I will develop is the one I have initially chosen to submit to Kaggle's 'Titanic' competition.\n",
    "\n",
    "The purpose of this model is to identify if these passengers 'Survived' or 'Not' which will involve creating a target output column populated with simple binary results of '1' or '0'.\n",
    "\n",
    "## Import the Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863215b",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c645fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/titanic_data.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855eca79",
   "metadata": {},
   "source": [
    "I need to determine from the beginning if the dataset I'm using for the purpose of this model already contains the 'predictions' and 'labeled' data, in which case I can divide it into a 'training' set and 'target' set which implies the use of a supervised learning technique.\n",
    "Now because I am utilizing an algorithm to perform this task of learning from examples I can predict or classify future examples from unknown data.\n",
    "\n",
    "Identifying the different data types associated with the entire set is a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89cd1b",
   "metadata": {},
   "source": [
    "So I can determine there are a total of 183 entries in this dataset. Initial thoughts are that it might be worth using a more comprehensive dataset, one which might contain the full list of passengers (1309) rather than just a subset (183). This is the most comprehensive list available for the purpose of this exercise that I can find, although estimates for the total number of passengers and crew members are thought to be in the region of 2220."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a793085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing once again\n",
    "titanic = pd.read_csv('C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names and data types\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508f351",
   "metadata": {},
   "source": [
    "So initially I can see there are some integer, float and string object columns at first glance which means I'll be working with numeric and text entries. In theory I could set up the 'Survived' column as a boolean type returning a True or False value. \n",
    "\n",
    "The next phase will be to select those columns which are integral 'predictors' to the model and of the features remaining I will begin to pre-process them by establishing counts and data distribution, standardizing values, identify missing values, correlations and duplicates or simply change the datatypes they're stored in by reducing the memory allocated to their values. This can help reduce overall latency and disk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a30285",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4cab9",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "Removing unwanted columns and rows and feature engineering is the next important step. Straight away I can see the second dataset I have imported from Kaggle which I have named 'titanic.csv' has a more comprehensive number of entries but also contains 21 columns as opposed to just 12 in the first set I had imported. Time to establish which of these columns will be kept or removed using some dimensionality reduction and combination, before establishing what is to be included in a Pandas DataFrame table and target Series.\n",
    "\n",
    "I can remove 'PassengerId', 'Name', 'Ticket', 'Fare', 'Embarked', 'WikiId', 'Name_wiki', 'Hometown', 'Destination', 'Lifeboat', 'Body' and 'Class' which will significantly reduce clutter in my table as these features provide no causal relationship with passenger Survival, some of which are duplicated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0088fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f6ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9616b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9968e265",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,6))\n",
    "titanic.Survived.value_counts(normalize=True).plot(kind=\"bar\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3b6b7",
   "metadata": {},
   "source": [
    "Looking into relationships between the different columns can provide more insight, for example between 'Age', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Boarded' and their 'Survived' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80135351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c26972402dce5166fbc873f625c08651cf8cab8ad67af055bc25543d79ffa73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
