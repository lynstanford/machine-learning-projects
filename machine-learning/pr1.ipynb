{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import data\n",
    "bitcoin = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "df = pd.DataFrame(bitcoin).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Adj Close    float64\n",
       "Volume       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all column data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Model Selection\n",
    "Assign the (dependant) y variable and (independent) X variables for the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data for modeling\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "Using this data for the Polynomial Features model and splitting it into training and test sets with a 70-30 split. Make a copy of the dataframe first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The following method is one way for training and testing the polynomial function, but first import the relevant libraries and instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for the training set\n",
      "-------------------------------------------\n",
      "RMSE of training set is 3087.952436065907\n",
      "R2 score of training set is 0.9809084277817212\n",
      "\n",
      "\n",
      "The model performance for the test set\n",
      "-------------------------------------------\n",
      "RMSE of test set is 2941.2771767095246\n",
      "R2 score of test set is 0.9789579480392447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#def create_polynomial_regression_model(degree):\n",
    "#\"Creates a polynomial regression model for the given degree\"\n",
    "  \n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "  \n",
    "# transforms the existing features to higher degree features.\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "  \n",
    "# fit the transformed features to Linear Regression\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "  \n",
    "# predicting on training data-set\n",
    "y_train_pred = poly_model.predict(X_train_poly)\n",
    "  \n",
    "# predicting on test data-set\n",
    "y_test_pred = poly_model.predict(poly_features.fit_transform(X_test))\n",
    "  \n",
    "# evaluating the model on training dataset\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "  \n",
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "  \n",
    "print(\"The model performance for the training set\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))\n",
    "  \n",
    "print(\"\\n\")\n",
    "  \n",
    "print(\"The model performance for the test set\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next method involves placing the expanded polynomial features and linear regression of these within a pipeline which can be trained and used to predict the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14451.8497609  23645.4431646  43301.74970473 30554.99600358\n",
      " 15029.58660573 60042.6849235  68522.7234905  70031.13742336\n",
      " 12498.2880599   9939.39361695 13657.77434716 11749.97202266\n",
      " 43800.25035275 76050.50530402 24758.5564535  45121.02936203\n",
      " 13818.00130113 68906.63435158 46736.12879176 36745.01394664\n",
      " 12467.52975303 74031.13180218 12375.78903863 43236.84905855\n",
      " 14784.26699683 12410.68817201 23710.75823537 22451.13791809\n",
      " 78792.37811112 60853.4173909  72334.44551747 15544.24736262\n",
      " 12988.90680838 71691.97288227 62558.40694316 12321.08862602\n",
      " 13270.73561795 73851.90407614 14015.30226863 27043.84261296\n",
      " 13345.17751371 49408.93141789 73175.32006717 59976.02708372\n",
      " 65084.18982501 13787.60716279 49952.71031336 15063.04015456\n",
      " 14231.86121981 14136.57949379 13380.78833418 46467.65757751\n",
      " 14988.0839077  29755.92348715 35289.7715675  12190.98039995\n",
      " 24786.27773596 24183.61320924 23619.1359942  23957.79504429\n",
      " 13112.54649684 76766.97433793 15125.13946685 12746.8912965\n",
      " 16082.55847323 14182.73188852 31551.97745281 24580.0800544\n",
      " 13705.20613771 41529.19476119 12547.81552201 19878.63371064\n",
      " 12517.39938705 25142.329573   66689.18697223 71515.66288443\n",
      " 78941.49763198 14546.35624356 34038.07309611 14514.37669939\n",
      " 12549.04150053 17947.57251857 70540.74373431 16162.33104179\n",
      " 21029.97309661 24312.93387234 70675.87052838 15636.44167066\n",
      " 14459.16881198 14284.68859153 14378.7335072  13573.1222617\n",
      " 24859.36012585 12173.88298974 15768.99467429 60321.08165174\n",
      " 21113.73989042 35034.73014599 13201.69917152 78600.20074274\n",
      " 10677.51979314 13308.22750617 42915.16988201 12720.63678574\n",
      " 12343.44029904 48463.27127965 18506.01105739 13993.17548399\n",
      " 25255.26941608 75894.60729054 29189.12273961 69217.33246454\n",
      " 13072.83892524 15118.35688985 12425.20497339 15679.14366284\n",
      " 41104.73993435 10587.17408206 59016.61362072 15532.9641695\n",
      " 13355.44886006 12609.67448049 12471.82841257 17922.56287149\n",
      " 17337.84064698 69159.56018363 43980.19077715 74694.4621488\n",
      " 12436.8552032  60435.77289778 63477.75466725 16987.86165202\n",
      " 70951.79640012 12429.99246499 12768.27698545 10303.73211193\n",
      " 12788.49489251 15258.75272786 44842.6008331  12300.68705562\n",
      " 12523.70267843 12536.16461829 73648.98079842 12687.57551084\n",
      " 13456.49457565 12681.69337231 13814.81319002 13163.44679974\n",
      " 23458.13135573 70775.31823058 45365.92357585 61742.8908693\n",
      " 15281.29414255 24610.71351157 12957.00053664 40913.13815899\n",
      " 15146.40201643 17654.39025813 13598.38185778 12942.7766025\n",
      "  9763.13796947 20793.74726821 62785.24174955 14535.07444909\n",
      " 15407.80042468 41423.53045958 12757.31368259 70023.73241426\n",
      " 12943.59473076 61259.54145859 14176.38946087 12441.57924085\n",
      " 12999.65424966 23011.92869242 39859.49029491 24739.83820405\n",
      " 14449.57275126 13584.81282738 16960.51320689 15330.60013784\n",
      " 70727.88075937 69764.16252876 44725.15710169 21568.4218748\n",
      " 12530.15437871 15699.01777396 56909.39110706 71711.44296225\n",
      " 12553.98578686 12554.58832782 46991.06241963 15971.64938241\n",
      " 58850.94550216 12675.29063281 45291.78300256 70586.51532473\n",
      " 12962.4747692  15114.59991934 40662.74377864 64812.39952816\n",
      " 13016.39254315 12779.42718387 61319.87283826 14850.62541613\n",
      " 58816.78943779 13521.28942754 17273.15796748 14151.3138484\n",
      " 14665.02642752 30270.810001   21220.36218298 12826.09348835\n",
      " 12916.48964372 15095.47426069 17352.91938122 65331.01611844\n",
      " 51207.93339905 70694.50414155 14317.75531234 47356.16419736\n",
      " 74199.06276817 15164.84565871 14946.57243283 19411.39101648\n",
      " 30155.37813122 16000.99526935 49552.77134783 12296.11023478\n",
      " 69152.97122158 13354.01672965 14086.25848818 70520.89478045\n",
      " 73328.47124904 15204.44005325 72807.31318242 13198.72265469\n",
      " 18111.41225568 62738.2674014  12408.68271008 12443.39457938\n",
      " 12369.52870404 57294.024991   30295.26685835 40538.80996297\n",
      " 24799.83723208 12605.1319679  20206.08571318 36886.64766673\n",
      " 76000.76834894 17929.19819415 15724.34196841 12830.2820835\n",
      " 15011.56490132]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "print(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of training set is 600.3385643743142\n",
      "R2 score of training set is 0.9992784058980032\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model on training dataset\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "print(y_train_pred)\n",
    "\n",
    "# evaluating the model on training dataset\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"RMSE of training set is {}\".format(rmse_train))\n",
    "print(\"R2 score of training set is {}\".format(r2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_test, y_test)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('reg', LinearRegression(normalize=True))\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_test, y_test)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "print(y_test_pred)\n",
    "\n",
    "# evaluating the model on test dataset\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# print the RMSE metric and R2 accuracy score\n",
    "print(\"RMSE of test set is {}\".format(rmse_test))\n",
    "print(\"R2 score of test set is {}\".format(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# initialize model\n",
    "poly_model = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# fit the model to the training set\n",
    "X_train_poly = poly_model.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using indexation to return any value in X, say the 1st value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note here is I am not training the entire dataframe of X, so it might be more accurate to display the first row of X_train. The main point here is there are only 4 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has taken the first value from row 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeating for the data contained in the 'X_train_poly' set and we can see that there are 14 values returned so it has created an array with 10 new features for a total of 14 features. This includes element-wise dot product values and some squared values (without going into to much detail). Both the original feature values for 'X1' to 'Xn' and the feature squared value from 'X_poly' are returned in this example. Now this new data matrix containing the additional features with the squared values has been created by expanding the number of features and the parameter weights (or coefficients), the linear regression model can be applied again to this new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the linear regression library first\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# initialize the model\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# fit the model but using the X_train_poly dataframe this time\n",
    "linear_regression.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the bias term (intercept) and coefficients are both attributes of the LinearRegression() model so I can examine these from the independent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression.intercept_\n",
    "linear_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "Here are some predictions using the test set data, before measuring their degree of variance and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred = linear_regression.predict(X_train_poly)\n",
    "print(\"Price Predictions: \", linear_regression.predict(X_train_poly.iloc[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting price based on Open = C$35,000, High = C$40,000, Low = C$32,000 and Volume = 100bn\n",
    "# linear_regression.predict([[35000, 40000, 32000, 100000000000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating the polynomial regression function with X and y training data and an attribute of 'degree=2' can be achieved using a mean squared error score and r-squared accuracy measure as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# model evaluation\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly_model.fit_transform(X_test)\n",
    "print(\"R-squared: \", linear_regression.score(X_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I can see the R-squared value is not as good as the previous score after trying polynomial regression with 'degree=2' squared terms. Having applied the Polynomial Features model and fitted it to the training set I have decided to save the data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/X_poly.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I change the parameter affecting the degree to which terms are multiplied to 'degree=3' in the polynomial equation?\n",
    "\n",
    "## Training the model\n",
    "Import the library and instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "poly_model = PolynomialFeatures(degree=3, include_bias=False)\n",
    "\n",
    "# fit the model to the training set\n",
    "X_train_poly = poly_model.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the linear model once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the linear regression library first\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# initialize the model\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "# fit the model but using the X_poly dataframe this time\n",
    "linear_regression.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intercept and coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression.intercept_\n",
    "linear_regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "This time for 'degree=3' terms the rmse score and r-squared measure based on the test sets give:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred = linear_regression.predict(X_test)\n",
    "print(\"Price Predictions: \", linear_regression.predict(X_test.iloc[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly_model.fit_transform(X_test)\n",
    "print(\"R-squared: \", linear_regression.score(X_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This causes a significant drop in the R-squared value or the degree of fit to the line, so may not be the most accurate model to use. I have decided to see if I can improve the model's predictive power by electing to use a Decision Tree Regression model: \"https://github.com/lynstanford/machine-learning-projects/tree/master/machine-learning/decision_tree.ipynb\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
