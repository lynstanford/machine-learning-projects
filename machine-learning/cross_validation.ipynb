{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf64d447",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Generally speaking cross validation is used to compare the cost functions and accuracy scores between a variety of models before choosing the best performer.\n",
    "\n",
    "This function can now be used to evaluate the Ridge Regression model I have used by splitting the training set into several smaller training and validation sets for training and evaluation separately. This is achieved by using the K-fold cross validation technique and I have split the data into 10 separate folds, cv=10 (which can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16457a4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12688/4133741308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mridge_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mridge_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import data from filepath\n",
    "btc_cad = pd.read_csv(\"C:/Users/lynst/Documents/GitHub/machine-learning-projects/machine-learning/BTC_CAD.csv\")\n",
    "\n",
    "# storing dataset from filepath into new dataframe\n",
    "df = pd.DataFrame(btc_cad).dropna(axis=0)\n",
    "\n",
    "# select data for modeling\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close\"]\n",
    "\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "ridge_reg = linear_model.Ridge(alpha=0.1, solver=\"auto\")\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "print(cross_val_score(ridge_reg, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c326b71",
   "metadata": {},
   "source": [
    "The range of R-squared scores ranges from 0.8797 to 0.9953. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63898767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the shape of the train and test sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# predict\n",
    "y_pred = cross_val_score(ridge_reg, X, y, cv=10)\n",
    "y_pred = ridge_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ddbd2",
   "metadata": {},
   "source": [
    "Now trying a prediction on the working linear model (first 5 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397541e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bab6e4",
   "metadata": {},
   "source": [
    "Measuring the RMSE and r-squared score for the linear model (based on training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_reg.predict(X_train)\n",
    "ridge_mse = mean_squared_error(y_train, y_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "print(ridge_rmse)\n",
    "    \n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9180e",
   "metadata": {},
   "source": [
    "This definitely appears to have reduced the Root Mean Squared Error for this particular sample of observations. We can say the Standard Deviation is distilled from the 'Standard Error' (which is the sum of the squared errors) and is a standardized term derived from the square root of the Standard Error. The predictions (Target Values) are compared to the actual observations (from the Training Set Values). \n",
    "\n",
    "Next, I compare the RMSE and r-squared for the Test Set to determine how well the model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65123d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_reg.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, y_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "print(ridge_rmse)\n",
    "    \n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c61717",
   "metadata": {},
   "source": [
    "The Loss function (RMSE) has been reduced and the r-squared (accuracy) has improved slightly which implies the ridge regression (Regularization algorithm) which has been applied to the model, seems to translate fairly well in real world data.\n",
    "\n",
    "Next, I want to apply a different scoring parameter, 'Negative Mean Squared Error' displaying the results from 10 separate cross folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac72be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(ridge_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "ridge_rmse_scores = np.sqrt(-scores)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "                         \n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"\\n\")\n",
    "    print(\"Mean\", scores.mean())\n",
    "    print(\"\\n\")\n",
    "    print(\"Standard Deviation\", scores.std())\n",
    "    print(\"\\n\")\n",
    "    print(\"R-Squared:\", r2_test)\n",
    "    print(\"\\n\")\n",
    "          \n",
    "display_scores(ridge_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86aedc",
   "metadata": {},
   "source": [
    "The lowest possible score achieved in 10 separate sub folds is 389.29477471. The average of these scores would be 705.1488929437664 which means the score I achieved to measure overall loss above is much better at 472.2805639459104. The Standard Deviation is just the squared root of the Negative Mean Squared Error values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_rmse_scores / 10\n",
    "print(ridge_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac249c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lin_reg, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598070c6",
   "metadata": {},
   "source": [
    "Using the 10 different r-squared values from the Ridge Regression above gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862dda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score = (0.97503778 + 0.87973022 + 0.98669072 + 0.96474476 + 0.98429722 + 0.99525415 + 0.99115778 + 0.89504007 + 0.94847447 + 0.90033073) / 10\n",
    "print(X_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(ridge_reg, X_poly, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250633df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_score = (0.97006818 + 0.85076677 + 0.99061033 + 0.97345638 + 0.98865061 + 0.99535352 + 0.99329041 + 0.79100498 + 0.79524206 + 0.87280349) / 10\n",
    "print(X_poly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cd997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(ridge_reg, X_train, y_train, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76000e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_score = (0.99859545 + 0.9982508 + 0.99873121 + 0.99971355 + 0.97387001 + 0.99905469 + 0.99721033 + 0.99879823 + 0.99922155 + 0.99974627) / 10\n",
    "print(X_train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a1abb",
   "metadata": {},
   "source": [
    "The first important detail to note is that the average cross-validation score is higher for the training set than the entire dataset from ridge regression, or the polynomial dataset.\n",
    "\n",
    "Trying a different scoring parameter called 'Explained Variance' provides consistently accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff169cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "mse = mean_squared_error(y_test, ridge_reg.predict(X_test), squared=True)\n",
    "mse_scores = cross_val_score(ridge_reg, X_train, y_train, scoring=\"explained_variance\", cv=10)\n",
    "mse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mse = (0.99859549 + 0.99826071 + 0.99876091 + 0.9997251 + 0.97460254 + 0.99909548 + 0.99725663 + 0.99898202 + 0.99922302 + 0.99974633) / 10\n",
    "print(average_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f62ef8",
   "metadata": {},
   "source": [
    "And for the root mean squared error values, finding the average rmse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3abc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rmse = (0.9992975 + 0.99912998 + 0.99938027 + 0.99986254 + 0.9872196 + 0.99954764 + 0.99862737 + 0.99949088 + 0.99961143 + 0.99987316) / 10\n",
    "print(average_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8a4c5",
   "metadata": {},
   "source": [
    "Now to evaluate the r-squared scoring parameter and cross-validating ten different sub-samples or folds once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07dd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_scores_train = cross_val_score(ridge_reg, X_train, y_train, scoring=\"r2\", cv=10)\n",
    "r2_scores_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3e7a2",
   "metadata": {},
   "source": [
    "Using the results from r-squared scores first I can determine the average r2 value from 10 different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e45010",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_r2_train = (0.99859545 + 0.9982508 + 0.99873121 + 0.99971355 + 0.97387 + 0.99905469 + 0.99721033 + 0.99879823 + 0.99922155 + 0.99974627) / 10\n",
    "print(average_r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365d21e",
   "metadata": {},
   "source": [
    "To see how this model generalizes to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d68a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_test = cross_val_score(ridge_reg, X_test, y_test, scoring=\"r2\", cv=10)\n",
    "r2_scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f8e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_r2_test = (0.99984803 + 0.99985311 + 0.99813416 + 0.99927484 + 0.99985759 + 0.99957481 + 0.99982543 + 0.99799085 + 0.96522031 + 0.99736867) / 10\n",
    "print(average_r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e09d6c",
   "metadata": {},
   "source": [
    "The scores seem to drop slightly for the test data but are approximately the same which is a good sign for the model because it means the fit, training and prediction phases will translate well to unseen data (generally) with at least 99.57% accuracy.\n",
    "\n",
    "Another thing to notice is how the 'explained_variance_score' score between the X training values and y training values are similar to the 'r-squared' scores.\n",
    "\n",
    "This particular 'cross_val_predict' metric is actually derived from the 'model_selection' model validation API and then, using indexing to return the first 5 values I get the following predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(ridge_reg, X, y, cv=10)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560218b",
   "metadata": {},
   "source": [
    "Cross validation is meant to determine the performance of different machine learning algorithms so they can be compared and contrasted. It's not meant for training a model, but for checking different models. I will apply the cross-validation on the dataset with all 4 different features (Open, High, Low and Volume) and a target column (Close). Starting from the beginning I will attempt to find the optimal value for K, or that which provides the highest accuracy, or the lowest MSE score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
