{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50f1d16",
   "metadata": {},
   "source": [
    "# ETL Using Python\n",
    "\n",
    "We will be ingesting data from the Microsoft AdventureWorks Sample Databases: https://learn.microsoft.com/en-us/sql/samples/adventureworks-install-configure?view=sql-server-ver16&tabs=ssms.\n",
    "\n",
    "We can choose from either the OLTP, Data Warehouse or Lightweight '.bak' files. The Source is a database from SQL Server which is then processed using Extract-Load-Transform before reaching it's Destination as a PostgreSQL database.\n",
    "\n",
    "So, we're using SQL Server 'AdventureWorksDW2019.bak' as the database source, before loading it into PostgreSQL using Python:\n",
    "\n",
    "1. ELT is a fundamental workflow used in data engineering\n",
    "2. The data source can be an API, a db or a flatfile.\n",
    "3. The source data is extracted into a 'Staging Area', transformed into a product ready to be loaded into it's destination or target database (stored in a Data Lake or Data Warehouse).\n",
    "4. We'll use Python (Pandas library) to build the ETL pipelines.\n",
    "\n",
    "Extract: get data from a source.\n",
    "Transform: structure, format or clean the data.\n",
    "Load: write the data to an external target / destination.\n",
    "\n",
    "## Sources\n",
    "### Databases\n",
    "RDBMS / NoSQL\n",
    "### Files\n",
    "csv / json / xml\n",
    "### SaaS Applications\n",
    "REST API's\n",
    "### Application Events\n",
    "Webhook\n",
    "\n",
    "It's Extracted into the Staging Area where it's Transformed before being Loaded into a Data Warehouse to be Analyzed for BI, ML, Data Science and Analytics end products.\n",
    "\n",
    "Another important point to note is that there are several different formats, database drivers and types of structure which need to be learned.\n",
    "\n",
    "## PostgreSQL Set Up\n",
    "### SQL Query\n",
    "This query is in the pgAdmin4 (PostgreSQL db driver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Database: AdventureWorks\n",
    "\n",
    "-- DROP DATABASE \"AdventureWorks\";\n",
    "\n",
    "CREATE DATABASE \"AdventureWorks\"\n",
    "    WITH\n",
    "    OWNER = postgres\n",
    "    ENCODING = 'UTF8'\n",
    "    LC_COLLATE = 'English_United States.1252'\n",
    "    TABLESPACE = pg_default\n",
    "    CONNECTION LIMIT = -1;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5087e",
   "metadata": {},
   "source": [
    "This creates a database in PostgreSQL. \n",
    "* Refresh the databases file manager on the left hand side, open the 'Databases' folder to see the 'AdventureWorks' db.\n",
    "\n",
    "### Create a New ETL User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- create etl user\n",
    "CREATE USER etl WITH PASSWORD 'demopass';\n",
    "-- grant connect\n",
    "GRANT CONNECT ON DATABASE \"AdventureWorks\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205c01c",
   "metadata": {},
   "source": [
    "'sqlalchemy' is the module used to interact with PostgreSQL. 'pyodbc' is the module used to query SQL Server. 'pandas' is the module used to perform the data extraction / loading. 'os' is the module used to retrieve the username and passwordwhich in this case is stored separately in the 'System -> Environment Variables -> System Variables (Lower window section)'. \n",
    "\n",
    "## Authentication\n",
    "There are some important points to note here regarding authentication access to the database drivers.\n",
    "The user's credentials could be stored in a '.sh' , '.ps' or an '.xml' file.\n",
    "\n",
    "Grab the password from the environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get password from environment var\n",
    "pwd = os.environ['PGPASS']\n",
    "uid = os.environ['PGUID']\n",
    "#sql db details\n",
    "driver = \"{SQL Server Native Client 11.0}\"\n",
    "server = \"haq-PC\"\n",
    "database = \"AdventureWorksDW2019;\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434fa22",
   "metadata": {},
   "source": [
    "Define a variable to store the SQL Server driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745de89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data from sql server\n",
    "def extract():\n",
    "    try:\n",
    "        src_conn = pyodbc.connect('DRIVER=' + driver + ';SERVER=' + server + '\\SQLEXPRESS' + ';DATABASE=' + database + ';UID=' + uid + ';PWD=' + pwd)\n",
    "        src_cursor = src_conn.cursor()\n",
    "        # execute query\n",
    "        src_cursor.execute(\"\"\" select  t.name as table_name\n",
    "        from sys.tables t where t.name in ('DimProduct','DimProductSubcategory','DimProductSubcategory','DimProductCategory','DimSalesTerritory','FactInternetSales') \"\"\")\n",
    "        src_tables = src_cursor.fetchall()\n",
    "        for tbl in src_tables:\n",
    "            #query and load save data to dataframe\n",
    "            df = pd.read_sql_query(f'select * FROM {tbl[0]}', src_conn)\n",
    "            load(df, tbl[0])\n",
    "    except Exception as e:\n",
    "        print(\"Data extract error: \" + str(e))\n",
    "    finally:\n",
    "        src_conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e958c1",
   "metadata": {},
   "source": [
    "## Transform\n",
    "This is the phase where I need to check for missing values and generally clean the data by exploring the type of information present and determining the scale or units of measurement to produce a snapshot which can be used in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data to postgres\n",
    "def load(df, tbl):\n",
    "    try:\n",
    "        rows_imported = 0\n",
    "        engine = create_engine(f'postgresql://{uid}:{pwd}@{server}:5432/AdventureWorks')\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len(df)}... for table {tbl}')\n",
    "        # save df to postgres\n",
    "        df.to_sql(f'stg_{tbl}', engine, if_exists='replace', index=False)\n",
    "        rows_imported += len(df)\n",
    "        # add elapsed time to final print out\n",
    "        print(\"Data imported successful\")\n",
    "    except Exception as e:\n",
    "        print(\"Data load error: \" + str(e))\n",
    "\n",
    "try:\n",
    "    #call extract function\n",
    "    extract()\n",
    "except Exception as e:\n",
    "    print(\"Error while extracting data: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7642a4a4",
   "metadata": {},
   "source": [
    "May need to provide a list of dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df96c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6dc316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21520db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
